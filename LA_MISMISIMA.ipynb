{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "INDICACIONES INICIALES:\n",
        "\n",
        "- Correr en GPU\n",
        "- Las carpetas deben subirse en zip\n",
        "- Si se entrena el entorno, debe descargarse best. pt usando bloque 17, luego volver a subirlo usando bloque 3"
      ],
      "metadata": {
        "id": "nrKfcy4piTYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "$$\\textbf{Entrenamiento del modelo}$$"
      ],
      "metadata": {
        "id": "ljEWDgvkBNV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 1 ‚Äî Preparaci√≥n del entorno:}\n",
        "\\\\ \\text{Crea la estructura de carpetas del proyecto en Colab (inputs, temporales, dataset, runs y resultados) e instala librer√≠as.}$$\n"
      ],
      "metadata": {
        "id": "q3SamIJjmwHo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OTTeIyAmeIw",
        "outputId": "b85b082f-31ff-4925-e01d-f02bdb4a1e83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Carpetas listas:\n",
            "IN: /content/in\n",
            "WORK: /content/work\n",
            "DATASET: /content/dataset\n",
            "RUNS: /content/runs\n",
            "OUT: /content/out\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "‚úÖ Ultralytics (YOLO) instalado y disponible\n"
          ]
        }
      ],
      "source": [
        "# Importa herramientas para manejar rutas, archivos, comandos y datos\n",
        "from pathlib import Path                  # Permite trabajar con rutas de carpetas/archivos de forma simple\n",
        "import shutil                             # Sirve para copiar/mover/borrar archivos y carpetas\n",
        "import zipfile                            # Sirve para descomprimir/comprimir archivos .zip\n",
        "import subprocess                         # Sirve para ejecutar comandos del sistema (ffmpeg, etc.)\n",
        "import os                                 # Utilidades del sistema (rutas, variables, etc.)\n",
        "import glob                               # Buscar archivos con patrones (ej: *.jpg)\n",
        "import re                                 # Manejo de texto con patrones (regex)\n",
        "import pandas as pd                       # Para crear/guardar tablas (CSV)\n",
        "\n",
        "BASE = Path(\"/content\")                   # Define la carpeta ra√≠z del entorno Colab\n",
        "DIR_IN = BASE/\"in\"                        # Carpeta para archivos que t√∫ subes (video/zip)\n",
        "DIR_WORK = BASE/\"work\"                    # Carpeta para trabajo temporal (frames, raw, etc.)\n",
        "DIR_DATASET = BASE/\"dataset\"              # Carpeta del dataset final en formato YOLO\n",
        "DIR_RUNS = BASE/\"runs\"                    # Carpeta donde YOLO guarda entrenamientos/predicciones\n",
        "DIR_OUT = BASE/\"out\"                      # Carpeta para resultados finales listos para descargar\n",
        "\n",
        "for d in [DIR_IN, DIR_WORK, DIR_DATASET, DIR_RUNS, DIR_OUT]:  # Recorre cada carpeta necesaria\n",
        "    d.mkdir(parents=True, exist_ok=True)                      # Crea la carpeta si no existe\n",
        "\n",
        "print(\"‚úÖ Carpetas listas:\")              # Muestra confirmaci√≥n\n",
        "print(\"IN:\", DIR_IN)                     # Imprime ruta de inputs\n",
        "print(\"WORK:\", DIR_WORK)                 # Imprime ruta de temporales\n",
        "print(\"DATASET:\", DIR_DATASET)           # Imprime ruta del dataset final\n",
        "print(\"RUNS:\", DIR_RUNS)                 # Imprime ruta de salidas de YOLO\n",
        "print(\"OUT:\", DIR_OUT)                   # Imprime ruta de resultados descargables\n",
        "\n",
        "# Instala la librer√≠a Ultralytics (YOLO) en el entorno de Colab\n",
        "!pip -q install ultralytics\n",
        "\n",
        "# Importa YOLO para confirmar que la instalaci√≥n qued√≥ OK\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Muestra la versi√≥n de FFmpeg para verificar que est√° instalado\n",
        "!ffmpeg -version | head -n 2\n",
        "\n",
        "# Lista la GPU disponible (si hay) para confirmar aceleraci√≥n por hardware\n",
        "!nvidia-smi -L || true\n",
        "\n",
        "# Imprime confirmaci√≥n de que Ultralytics qued√≥ listo\n",
        "print(\"‚úÖ Ultralytics (YOLO) instalado y disponible\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 4 ‚Äî Exploraci√≥n y control de espacio:} \\\n",
        "\\\\\\ \\text{Te muestra qu√© hay dentro de las carpetas del proyecto  y deja listas las carpetas de trabajo para frames y dataset crudo.}$$\n"
      ],
      "metadata": {
        "id": "tqVlN1oVsqqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define una funci√≥n simple para listar contenido de una carpeta sin tirar error\n",
        "def listar_carpeta(ruta, max_items=50):                  # Crea una funci√≥n para listar archivos/carpetas\n",
        "    ruta = Path(ruta)                                    # Convierte la ruta a formato Path\n",
        "    print(\"\\nüìÅ\", ruta)                                   # Imprime la carpeta que se est√° revisando\n",
        "    if not ruta.exists():                                # Si la carpeta no existe\n",
        "        print(\"‚ö†Ô∏è No existe todav√≠a.\")                    # Avisa sin romper el notebook\n",
        "        return                                            # Termina la funci√≥n\n",
        "\n",
        "    items = sorted(list(ruta.iterdir()), key=lambda p: (p.is_file(), p.name.lower()))  # Ordena primero carpetas\n",
        "    if len(items) == 0:                                  # Si no hay nada dentro\n",
        "        print(\"‚ö†Ô∏è Est√° vac√≠a.\")                           # Avisa sin romper el notebook\n",
        "        return                                            # Termina la funci√≥n\n",
        "\n",
        "    for p in items[:max_items]:                          # Recorre hasta max_items elementos\n",
        "        tipo = \"DIR \" if p.is_dir() else \"FILE\"          # Marca si es carpeta o archivo\n",
        "        print(f\" - {tipo} {p.name}\")                     # Imprime el nombre\n",
        "\n",
        "    if len(items) > max_items:                           # Si hay m√°s de max_items\n",
        "        print(f\" ... y {len(items)-max_items} m√°s\")      # Avisa cu√°ntos faltan por mostrar\n",
        "\n",
        "# Lista las carpetas principales del proyecto para ver el estado general\n",
        "print(\"‚úÖ Listado r√°pido de carpetas del proyecto:\")      # Mensaje de inicio\n",
        "listar_carpeta(\"/content\")                               # Muestra lo que hay en /content\n",
        "listar_carpeta(DIR_IN)                                   # Muestra lo que hay en /content/in\n",
        "listar_carpeta(DIR_WORK)                                 # Muestra lo que hay en /content/work\n",
        "listar_carpeta(DIR_DATASET)                              # Muestra lo que hay en /content/dataset\n",
        "listar_carpeta(DIR_RUNS)                                 # Muestra lo que hay en /content/runs\n",
        "listar_carpeta(DIR_OUT)                                  # Muestra lo que hay en /content/out\n",
        "\n",
        "# Muestra el espacio total del disco del entorno (si el comando est√° disponible)\n",
        "print(\"\\n‚úÖ Espacio total del entorno (df -h):\")           # T√≠tulo del chequeo\n",
        "try:\n",
        "    subprocess.run([\"df\", \"-h\"], check=False)            # Ejecuta df sin romper si falla\n",
        "except Exception:\n",
        "    print(\"‚ö†Ô∏è No pude ejecutar df -h en este entorno.\")   # Aviso si no se pudo\n",
        "\n",
        "# Muestra cu√°nto pesa cada carpeta dentro de /content (para detectar qu√© est√° llenando)\n",
        "print(\"\\n‚úÖ Peso por carpeta dentro de /content (du -h):\") # T√≠tulo del chequeo\n",
        "try:\n",
        "    subprocess.run([\"bash\", \"-lc\", \"du -h --max-depth=1 /content | sort -h\"], check=False)  # Ejecuta du ordenado\n",
        "except Exception:\n",
        "    print(\"‚ö†Ô∏è No pude ejecutar du en este entorno.\")      # Aviso si no se pudo\n",
        "\n",
        "# Detecta autom√°ticamente qu√© tipo de archivo tienes en /content/in (sin tirar error si no hay nada)\n",
        "in_files = list(DIR_IN.iterdir())                               # Lee todo lo que hay dentro de /content/in\n",
        "\n",
        "# Busca un video por extensi√≥n com√∫n (si existe)\n",
        "video = next((p for p in in_files if p.suffix.lower() in [\".mp4\", \".mov\", \".avi\", \".mkv\"]), None)  # Encuentra el primer video\n",
        "\n",
        "# Busca un zip que se llame images.zip (si existe)\n",
        "zip_images = next((p for p in in_files if p.name.lower() == \"images.zip\"), None)  # Encuentra images.zip\n",
        "\n",
        "# Busca un zip que parezca export de CVAT (si existe)\n",
        "zip_cvat = next((p for p in in_files if p.suffix.lower() == \".zip\" and \"cvat\" in p.name.lower()), None)  # Encuentra zip CVAT\n",
        "\n",
        "# Define carpetas de trabajo est√°ndar (frames y dataset_raw)\n",
        "FRAMES_DIR = DIR_WORK/\"frames\"                                  # Carpeta donde se guardan frames extra√≠dos del video\n",
        "RAW_DIR = DIR_WORK/\"dataset_raw\"                                # Carpeta donde se descomprime el export de CVAT\n",
        "\n",
        "# Crea las carpetas si no existen\n",
        "FRAMES_DIR.mkdir(parents=True, exist_ok=True)                   # Crea /content/work/frames si no existe\n",
        "RAW_DIR.mkdir(parents=True, exist_ok=True)                      # Crea /content/work/dataset_raw si no existe\n",
        "\n",
        "# Imprime un resumen claro de lo que se detect√≥\n",
        "print(\"‚úÖ Detecci√≥n de inputs en /content/in:\")                  # T√≠tulo del resumen\n",
        "print(\" - Video:\", video.name if video else \"No detectado\")      # Informa si hay video\n",
        "print(\" - images.zip:\", zip_images.name if zip_images else \"No detectado\")  # Informa si hay zip de im√°genes\n",
        "print(\" - zip CVAT:\", zip_cvat.name if zip_cvat else \"No detectado\")        # Informa si hay export CVAT\n",
        "\n",
        "# Imprime rutas de trabajo listas\n",
        "print(\"\\n‚úÖ Rutas de trabajo listas:\")                           # T√≠tulo para rutas\n",
        "print(\" - FRAMES_DIR:\", FRAMES_DIR)                              # Ruta donde ir√°n los frames\n",
        "print(\" - RAW_DIR:\", RAW_DIR)                                    # Ruta donde ir√° el dataset crudo\n",
        "\n",
        "# Mensaje gu√≠a para tu siguiente decisi√≥n (sin obligarte a nada)\n",
        "print(\"\\n‚ÑπÔ∏è Pr√≥ximo paso sugerido:\")                              # Gu√≠a de flujo\n",
        "if video:\n",
        "    print(\" - Tienes video: puedes extraer frames (Bloque 6).\")   # Recomienda ruta A\n",
        "elif zip_cvat:\n",
        "    print(\" - Tienes export CVAT: puedes descomprimir y normalizar dataset (Bloques 8+).\")  # Recomienda ruta CVAT\n",
        "elif zip_images:\n",
        "    print(\" - Tienes images.zip: puedes descomprimir para etiquetar (si lo necesitas).\")    # Recomienda ruta B\n",
        "else:\n",
        "    print(\" - A√∫n no hay inputs: puedes seguir armando notebook igual y subir despu√©s.\")    # Recomienda seguir sin datos\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TuGy7isGsswg",
        "outputId": "bc8b1399-b1bb-4122-8c0f-3b36ea7b4105"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Listado r√°pido de carpetas del proyecto:\n",
            "\n",
            "üìÅ /content\n",
            " - DIR  .config\n",
            " - DIR  .ipynb_checkpoints\n",
            " - DIR  dataset\n",
            " - DIR  in\n",
            " - DIR  out\n",
            " - DIR  runs\n",
            " - DIR  sample_data\n",
            " - DIR  train\n",
            " - DIR  work\n",
            " - FILE data.yaml\n",
            "\n",
            "üìÅ /content/in\n",
            " - DIR  .ipynb_checkpoints\n",
            " - FILE cvat t1p2 t10 y t3p2.zip\n",
            "\n",
            "üìÅ /content/work\n",
            " - DIR  dataset_raw\n",
            " - DIR  frames\n",
            "\n",
            "üìÅ /content/dataset\n",
            " - DIR  images\n",
            " - DIR  masks\n",
            "\n",
            "üìÅ /content/runs\n",
            " - DIR  predict_val\n",
            " - DIR  train_unet\n",
            "\n",
            "üìÅ /content/out\n",
            " - FILE dataset_summary.txt\n",
            " - FILE val_predictions.zip\n",
            "\n",
            "‚úÖ Espacio total del entorno (df -h):\n",
            "\n",
            "‚úÖ Peso por carpeta dentro de /content (du -h):\n",
            "‚úÖ Detecci√≥n de inputs en /content/in:\n",
            " - Video: No detectado\n",
            " - images.zip: No detectado\n",
            " - zip CVAT: cvat t1p2 t10 y t3p2.zip\n",
            "\n",
            "‚úÖ Rutas de trabajo listas:\n",
            " - FRAMES_DIR: /content/work/frames\n",
            " - RAW_DIR: /content/work/dataset_raw\n",
            "\n",
            "‚ÑπÔ∏è Pr√≥ximo paso sugerido:\n",
            " - Tienes export CVAT: puedes descomprimir y normalizar dataset (Bloques 8+).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 8 ‚Äî Importar export de CVAT:} \\\n",
        "\\\\\\ \\text{Si hay zip de CVAT (BLOQUE 3), lo descomprime en /content #/work/dataset_raw. Si no tiene cvat revisar bloque 6.}$$\n"
      ],
      "metadata": {
        "id": "mIDh0gV0vizd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descomprime el export de CVAT (si existe) en /content/work/dataset_raw (si no existe, no falla: avisa)\n",
        "# Nota: Este zip suele llamarse algo como \"cvat_yolo_export.zip\" (el nombre puede variar)\n",
        "\n",
        "# Vuelve a buscar un zip que parezca de CVAT por si lo subiste reci√©n\n",
        "in_files = list(DIR_IN.iterdir())                                              # Lee archivos en /content/in\n",
        "zip_cvat = next((p for p in in_files if p.suffix.lower() == \".zip\" and \"cvat\" in p.name.lower()), None)  # Busca zip con \"cvat\" en el nombre\n",
        "\n",
        "# Si no encontramos zip CVAT, avisamos y seguimos sin error\n",
        "if zip_cvat is None:                                                           # Revisa si existe export de CVAT\n",
        "    print(\"‚ö†Ô∏è No detect√© ning√∫n .zip de CVAT en /content/in (debe tener 'cvat' en el nombre).\")           # Aviso\n",
        "    print(\"‚ÑπÔ∏è Cuando lo tengas, s√∫belo y vuelve a correr este bloque.\")         # Gu√≠a\n",
        "else:\n",
        "    # Limpia dataset_raw anterior para evitar mezclar versiones\n",
        "    if RAW_DIR.exists():                                                       # Revisa si ya existe dataset_raw\n",
        "        shutil.rmtree(RAW_DIR)                                                 # Borra dataset_raw anterior completo\n",
        "    RAW_DIR.mkdir(parents=True, exist_ok=True)                                 # Crea dataset_raw limpio\n",
        "\n",
        "    # Descomprime el zip de CVAT dentro de dataset_raw\n",
        "    with zipfile.ZipFile(zip_cvat, \"r\") as z:                                  # Abre el zip de CVAT\n",
        "        z.extractall(RAW_DIR)                                                  # Extrae todo su contenido en RAW_DIR\n",
        "\n",
        "    # Lista contenido para confirmar que se extrajo algo\n",
        "    extracted_any = any(RAW_DIR.rglob(\"*\"))                                     # Verifica si hay archivos extra√≠dos\n",
        "    if not extracted_any:                                                      # Si no se extrajo nada\n",
        "        print(\"‚ö†Ô∏è El zip se descomprimi√≥, pero no veo archivos dentro. Revisa si el zip est√° correcto.\")  # Aviso\n",
        "    else:\n",
        "        print(\"‚úÖ Export CVAT descomprimido en:\", RAW_DIR)                      # Confirmaci√≥n\n",
        "        # Muestra un vistazo r√°pido de archivos/carpetas extra√≠das\n",
        "        top_items = sorted(list(RAW_DIR.iterdir()))                             # Lista el primer nivel de dataset_raw\n",
        "        print(\"‚úÖ Primer nivel dentro de dataset_raw:\")                         # T√≠tulo del listado\n",
        "        for p in top_items[:30]:                                                # Muestra hasta 30 √≠tems\n",
        "            tag = \"DIR \" if p.is_dir() else \"FILE\"                              # Marca si es carpeta o archivo\n",
        "            print(\" -\", tag, p.name)                                            # Imprime nombre\n",
        "        if len(top_items) > 30:                                                 # Si hay muchos √≠tems\n",
        "            print(f\" ... y {len(top_items)-30} m√°s\")                            # Indica que hay m√°s\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SG3g9wUyvyuC",
        "outputId": "5bd10457-d19c-443a-b91b-0545191fa00c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Export CVAT descomprimido en: /content/work/dataset_raw\n",
            "‚úÖ Primer nivel dentro de dataset_raw:\n",
            " - DIR  cvat t1p2 t10 y t3p2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 9 ‚Äî Detectar (CVAT) + Normalizar YOLO + Split:} \\\n",
        "\\\\\\ \\text{Busca autom√°ticamente im√°genes y labels dentro de #dataset\\_raw, y construye el split en #/content/dataset.}$$\n"
      ],
      "metadata": {
        "id": "figIDZiWv9MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detecta im√°genes/labels en dataset_raw y construye dataset YOLO final (train/val) creando .txt vac√≠os para negativos\n",
        "import random                                                    # Sirve para mezclar antes del split\n",
        "\n",
        "img_exts = {\".jpg\", \".jpeg\", \".png\"}                             # Extensiones v√°lidas de im√°genes\n",
        "train_ratio = 0.8                                                # Proporci√≥n train/val\n",
        "seed = 42                                                        # Semilla para split repetible\n",
        "\n",
        "# Define rutas YOLO est√°ndar de salida\n",
        "IMG_TRAIN = DIR_DATASET/\"images/train\"                           # Im√°genes train\n",
        "IMG_VAL   = DIR_DATASET/\"images/val\"                             # Im√°genes val\n",
        "LBL_TRAIN = DIR_DATASET/\"labels/train\"                           # Labels train\n",
        "LBL_VAL   = DIR_DATASET/\"labels/val\"                             # Labels val\n",
        "\n",
        "# Crea carpetas de salida\n",
        "for d in [IMG_TRAIN, IMG_VAL, LBL_TRAIN, LBL_VAL]:               # Recorre carpetas YOLO\n",
        "    d.mkdir(parents=True, exist_ok=True)                         # Crea si falta\n",
        "\n",
        "# Verifica que exista dataset_raw\n",
        "if not RAW_DIR.exists():                                         # Si no existe dataset_raw\n",
        "    print(\"‚ö†Ô∏è No existe /content/work/dataset_raw todav√≠a. Corre el Bloque 8 (descomprimir CVAT) primero.\")  # Aviso\n",
        "else:\n",
        "    # Busca im√°genes y txt dentro de dataset_raw (recursivo)\n",
        "    all_imgs = [p for p in RAW_DIR.rglob(\"*\") if p.suffix.lower() in img_exts]   # Todas las im√°genes\n",
        "    all_txt  = [p for p in RAW_DIR.rglob(\"*.txt\")]                               # Todos los txt\n",
        "\n",
        "    print(\"‚úÖ Archivos encontrados dentro de dataset_raw:\")       # Resumen inicial\n",
        "    print(\" - Im√°genes:\", len(all_imgs))                         # Cantidad im√°genes\n",
        "    print(\" - TXT:\", len(all_txt))                               # Cantidad txt\n",
        "\n",
        "    # Si falta algo, avisa pero no rompe\n",
        "    if len(all_imgs) == 0:\n",
        "        print(\"‚ö†Ô∏è No encontr√© im√°genes dentro de dataset_raw. Revisa estructura del export (o tu zip).\")  # Aviso\n",
        "    if len(all_txt) == 0:\n",
        "        print(\"‚ö†Ô∏è No encontr√© labels (.txt) dentro de dataset_raw. Ojo: CVAT solo exporta txt con anotaciones.\")  # Aviso\n",
        "\n",
        "    # Detecta carpeta con m√°s im√°genes y carpeta con m√°s txt (candidatas principales)\n",
        "    img_dir = None                                               # Carpeta candidata de im√°genes\n",
        "    lbl_dir = None                                               # Carpeta candidata de labels\n",
        "\n",
        "    if len(all_imgs) > 0:                                        # Si hay im√°genes\n",
        "        counts_img_parent = {}                                   # Conteo por carpeta\n",
        "        for p in all_imgs:                                       # Recorre im√°genes\n",
        "            counts_img_parent[p.parent] = counts_img_parent.get(p.parent, 0) + 1  # Cuenta\n",
        "        img_dir = max(counts_img_parent, key=counts_img_parent.get)              # Elige mayor\n",
        "\n",
        "    if len(all_txt) > 0:                                         # Si hay txt\n",
        "        counts_lbl_parent = {}                                   # Conteo por carpeta\n",
        "        for p in all_txt:                                        # Recorre txt\n",
        "            counts_lbl_parent[p.parent] = counts_lbl_parent.get(p.parent, 0) + 1  # Cuenta\n",
        "        lbl_dir = max(counts_lbl_parent, key=counts_lbl_parent.get)              # Elige mayor\n",
        "\n",
        "    print(\"\\n‚úÖ Rutas detectadas (candidatas principales):\")      # Imprime rutas\n",
        "    print(\" - img_dir:\", str(img_dir) if img_dir else \"No detectado\")  # Carpeta im√°genes\n",
        "    print(\" - lbl_dir:\", str(lbl_dir) if lbl_dir else \"No detectado\")  # Carpeta labels\n",
        "\n",
        "    # Si no se detectaron rutas, termina sin error\n",
        "    if (img_dir is None) or (lbl_dir is None):\n",
        "        print(\"‚ö†Ô∏è No pude detectar img_dir y/o lbl_dir. Revisa qu√© hay dentro de dataset_raw (Bloque 4 listar carpetas).\")  # Aviso\n",
        "    else:\n",
        "        # Crea mapas por stem para hacer match imagen <-> label\n",
        "        img_map = {}                                             # stem -> ruta imagen\n",
        "        for p in img_dir.iterdir():                              # Recorre archivos en img_dir\n",
        "            if p.suffix.lower() in img_exts:                     # Si es imagen\n",
        "                img_map[p.stem] = p                              # Guarda\n",
        "\n",
        "        lbl_map = {}                                             # stem -> ruta label\n",
        "        for p in lbl_dir.iterdir():                              # Recorre archivos en lbl_dir\n",
        "            if p.suffix.lower() == \".txt\":                       # Si es txt\n",
        "                lbl_map[p.stem] = p                              # Guarda\n",
        "\n",
        "        # Diagn√≥stico de matching\n",
        "        all_stems = sorted(img_map.keys())                       # Todas las im√°genes (incluye negativos)\n",
        "        paired = sorted(set(img_map.keys()) & set(lbl_map.keys()))            # Con label\n",
        "        missing_lbl = sorted(set(img_map.keys()) - set(lbl_map.keys()))      # Sin label (negativos)\n",
        "        missing_img = sorted(set(lbl_map.keys()) - set(img_map.keys()))      # Txt sin imagen\n",
        "\n",
        "        print(\"\\n‚úÖ Matching imagen + label (incluyendo negativos):\")  # Reporte matching\n",
        "        print(\" - Total im√°genes:\", len(all_stems))              # Total\n",
        "        print(\" - Con label (.txt):\", len(paired))               # Con txt\n",
        "        print(\" - Sin label (se crear√° .txt vac√≠o):\", len(missing_lbl))  # Negativos\n",
        "        print(\" - Txt sin imagen (se ignoran):\", len(missing_img))       # Hu√©rfanos\n",
        "\n",
        "        # Si no hay im√°genes, no se puede construir dataset\n",
        "        if len(all_stems) == 0:\n",
        "            print(\"‚ö†Ô∏è No hay im√°genes v√°lidas para construir dataset. Revisa nombres/extensiones.\")  # Aviso\n",
        "        else:\n",
        "            # Limpia salidas anteriores\n",
        "            for d in [IMG_TRAIN, IMG_VAL, LBL_TRAIN, LBL_VAL]:   # Recorre carpetas de salida\n",
        "                for f in d.glob(\"*\"):                            # Recorre archivos dentro\n",
        "                    f.unlink()                                   # Borra\n",
        "\n",
        "            # Split train/val sobre TODAS las im√°genes\n",
        "            random.seed(seed)                                    # Semilla\n",
        "            random.shuffle(all_stems)                             # Mezcla\n",
        "            cut = int(len(all_stems) * train_ratio)              # Corte\n",
        "            train_ids = all_stems[:cut]                          # Train stems\n",
        "            val_ids = all_stems[cut:]                            # Val stems\n",
        "\n",
        "            # Copia imagen y label (o crea vac√≠o si falta)\n",
        "            def copy_img_and_label(stem, img_dst, lbl_dst):      # Funci√≥n copiar + label\n",
        "                img_src = img_map[stem]                          # Imagen fuente\n",
        "                shutil.copy2(img_src, img_dst / img_src.name)    # Copia imagen\n",
        "\n",
        "                lbl_out = lbl_dst / f\"{stem}.txt\"                # Label destino\n",
        "                if stem in lbl_map:                              # Si existe label real\n",
        "                    shutil.copy2(lbl_map[stem], lbl_out)         # Copia label\n",
        "                else:\n",
        "                    lbl_out.write_text(\"\", encoding=\"utf-8\")     # Crea label vac√≠o (negativo)\n",
        "\n",
        "            # Copia a train\n",
        "            for s in train_ids:                                  # Recorre train\n",
        "                copy_img_and_label(s, IMG_TRAIN, LBL_TRAIN)      # Copia\n",
        "\n",
        "            # Copia a val\n",
        "            for s in val_ids:                                    # Recorre val\n",
        "                copy_img_and_label(s, IMG_VAL, LBL_VAL)          # Copia\n",
        "\n",
        "            # Resumen final\n",
        "            n_train_img = len(list(IMG_TRAIN.glob(\"*\")))         # Cuenta imgs train\n",
        "            n_train_lbl = len(list(LBL_TRAIN.glob(\"*.txt\")))     # Cuenta labels train\n",
        "            n_val_img = len(list(IMG_VAL.glob(\"*\")))             # Cuenta imgs val\n",
        "            n_val_lbl = len(list(LBL_VAL.glob(\"*.txt\")))         # Cuenta labels val\n",
        "\n",
        "            print(\"\\n‚úÖ Dataset YOLO final creado en:\", DIR_DATASET)  # Confirma creaci√≥n\n",
        "            print(\" - Train: imgs =\", n_train_img, \"| lbls =\", n_train_lbl)  # Resumen train\n",
        "            print(\" - Val:   imgs =\", n_val_img,   \"| lbls =\", n_val_lbl)    # Resumen val\n",
        "\n",
        "            # Chequeo 1 txt por imagen (ideal)\n",
        "            if n_train_img != n_train_lbl:\n",
        "                print(\"‚ö†Ô∏è Ojo: TRAIN imgs != txt (deber√≠an ser iguales).\")  # Aviso\n",
        "            if n_val_img != n_val_lbl:\n",
        "                print(\"‚ö†Ô∏è Ojo: VAL imgs != txt (deber√≠an ser iguales).\")    # Aviso\n",
        "\n",
        "            # Guarda resumen para trazabilidad\n",
        "            summary_path = DIR_OUT/\"dataset_summary.txt\"         # Archivo resumen\n",
        "            summary_text = (\n",
        "                f\"total_imgs={len(all_stems)}\\n\"\n",
        "                f\"imgs_with_lbl={len(paired)}\\n\"\n",
        "                f\"imgs_without_lbl_created_empty={len(missing_lbl)}\\n\"\n",
        "                f\"txt_without_img_ignored={len(missing_img)}\\n\"\n",
        "                f\"train_ratio={train_ratio}\\n\"\n",
        "                f\"train_imgs={n_train_img}\\ntrain_lbls={n_train_lbl}\\n\"\n",
        "                f\"val_imgs={n_val_img}\\nval_lbls={n_val_lbl}\\n\"\n",
        "            )\n",
        "            summary_path.write_text(summary_text, encoding=\"utf-8\")  # Escribe resumen\n",
        "            print(\"‚úÖ Resumen guardado en:\", summary_path)        # Confirma guardado\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLR3oILLIfCr",
        "outputId": "e348ccb2-6ee5-4e63-e9a6-e0db8f7a2ec1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Archivos encontrados dentro de dataset_raw:\n",
            " - Im√°genes: 885\n",
            " - TXT: 321\n",
            "\n",
            "‚úÖ Rutas detectadas (candidatas principales):\n",
            " - img_dir: /content/work/dataset_raw/cvat t1p2 t10 y t3p2/images\n",
            " - lbl_dir: /content/work/dataset_raw/cvat t1p2 t10 y t3p2/labels\n",
            "\n",
            "‚úÖ Matching imagen + label (incluyendo negativos):\n",
            " - Total im√°genes: 885\n",
            " - Con label (.txt): 321\n",
            " - Sin label (se crear√° .txt vac√≠o): 564\n",
            " - Txt sin imagen (se ignoran): 0\n",
            "\n",
            "‚úÖ Dataset YOLO final creado en: /content/dataset\n",
            " - Train: imgs = 708 | lbls = 708\n",
            " - Val:   imgs = 177 | lbls = 177\n",
            "‚úÖ Resumen guardado en: /content/out/dataset_summary.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 11 ‚Äî Crear data.yaml (receta del dataset):} \\\n",
        "\\\\\\ \\text{Genera el archivo data.yaml que le dice a YOLO d√≥nde est√° tu dataset (train/val) y se crean manualmente las clases.}$$\n"
      ],
      "metadata": {
        "id": "ZSu_Gog4w7m9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea el archivo data.yaml para YOLO (si no hay dataset a√∫n, no falla: avisa)\n",
        "yaml_path = BASE/\"data.yaml\"                                    # Define la ruta donde se guardar√° el YAML\n",
        "\n",
        "# Define aqu√≠ tus clases EXACTAS y en el MISMO orden que usaste en CVAT - OJO DEBE HACERSE MANUAL\n",
        "classes = [\n",
        "    \"falla junta paramento izquierdo\",\n",
        "    \"falla junta paramento derecho\",\n",
        "    \"falla junta losa fondo\",\n",
        "    \"estr√≠a lado izquierdo\",\n",
        "    \"estr√≠a lado derecho\",\n",
        "    \"estr√≠a centro\",\n",
        "    \"da√±o paramento\",\n",
        "    \"da√±o losa fondo\",\n",
        "]                                                               # Lista de nombres de clases (ed√≠tala t√∫)\n",
        "\n",
        "# Verifica que existan carpetas train/val para evitar un YAML apuntando a nada\n",
        "train_dir_ok = (DIR_DATASET/\"images/train\").exists()            # Revisa si existe la carpeta de im√°genes train\n",
        "val_dir_ok = (DIR_DATASET/\"images/val\").exists()                # Revisa si existe la carpeta de im√°genes val\n",
        "\n",
        "# Si no hay estructura dataset, avisa y no rompe el notebook\n",
        "if not (train_dir_ok and val_dir_ok):                           # Si faltan carpetas b√°sicas del dataset\n",
        "    print(\"‚ö†Ô∏è No detecto la estructura de dataset en /content/dataset/images/train y /val.\")  # Aviso\n",
        "    print(\"‚ÑπÔ∏è Corre el Bloque 10 (normalizaci√≥n + split) antes de crear el data.yaml.\")       # Gu√≠a\n",
        "else:\n",
        "    # Si no definiste clases, avisa para que no entrenes con un YAML incompleto\n",
        "    if len(classes) == 0:                                       # Si la lista de clases est√° vac√≠a\n",
        "        print(\"‚ö†Ô∏è La lista 'classes' est√° vac√≠a. Agrega tus clases en el orden de CVAT antes de entrenar.\")  # Aviso\n",
        "        print(\"‚ÑπÔ∏è Igual crear√© el data.yaml, pero NO deber√≠as entrenar hasta completar 'classes'.\")          # Gu√≠a\n",
        "\n",
        "    # Construye el contenido del YAML que YOLO necesita\n",
        "    yaml_text = f\"\"\"path: {DIR_DATASET}\n",
        "train: images/train\n",
        "val: images/val\n",
        "names:\n",
        "\"\"\"                                                             # Texto base del YAML (path + rutas train/val)\n",
        "\n",
        "    # Agrega las clases con su √≠ndice (0,1,2...) en el orden correcto\n",
        "    for i, c in enumerate(classes):                              # Recorre clases con √≠ndice\n",
        "        yaml_text += f\"  {i}: {c}\\n\"                              # Agrega cada clase al YAML\n",
        "\n",
        "    # Guarda el archivo data.yaml\n",
        "    yaml_path.write_text(yaml_text, encoding=\"utf-8\")            # Escribe el YAML en disco\n",
        "\n",
        "    # Prints de confirmaci√≥n + vista r√°pida del contenido\n",
        "    print(\"‚úÖ data.yaml creado en:\", yaml_path)                   # Confirma ruta del archivo creado\n",
        "    print(\"‚úÖ Contenido de data.yaml:\")                           # T√≠tulo del contenido\n",
        "    print(yaml_text)                                              # Muestra el texto completo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxDl25huxK9B",
        "outputId": "b7eef472-2866-465a-d260-23456d991673"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ data.yaml creado en: /content/data.yaml\n",
            "‚úÖ Contenido de data.yaml:\n",
            "path: /content/dataset\n",
            "train: images/train\n",
            "val: images/val\n",
            "names:\n",
            "  0: falla junta paramento izquierdo\n",
            "  1: falla junta paramento derecho\n",
            "  2: falla junta losa fondo\n",
            "  3: estr√≠a lado izquierdo\n",
            "  4: estr√≠a lado derecho\n",
            "  5: estr√≠a centro\n",
            "  6: da√±o paramento\n",
            "  7: da√±o losa fondo\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 12 ‚Äî Entrenamiento YOLO:} \\\n",
        "\\\\\\ \\text{Entrena un modelo YOLO usando data.yaml y guarda los pesos (best.pt/last.pt) y m√©tricas dentro de #/content/runs/train.}$$\n"
      ],
      "metadata": {
        "id": "miS4L2gWxXUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloque 12 ‚Äî Entrenamiento YOLO (Optimizado para aprendizaje continuo)\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import shutil\n",
        "\n",
        "# 1. Configuraci√≥n de par√°metros\n",
        "data_yaml = \"/content/data.yaml\"\n",
        "batch_size = 16  # Si Colab te da error de \"Out of Memory\", baja esto a 8 o 4, si no, mant√©n en 16\n",
        "epochs = 50\n",
        "img_size = 640\n",
        "output_dir = \"/content/runs\" # Ajustado para que Ultralytics maneje la estructura interna\n",
        "best_pt_path = \"/content/in/best.pt\"\n",
        "\n",
        "# 2. L√≥gica de carga de modelo (Transfer Learning)\n",
        "if Path(best_pt_path).exists():\n",
        "    print(f\"‚úÖ Conocimiento previo detectado. Cargando: {best_pt_path}\")\n",
        "    model = YOLO(best_pt_path)\n",
        "    # Recomendaci√≥n: Si retomas, bajamos un poco la tasa de aprendizaje inicial (lr0)\n",
        "    # para que no olvide lo anterior bruscamente.\n",
        "    lr_inicial = 0.001\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Iniciando desde cero con YOLOv8 Nano.\")\n",
        "    model = YOLO(\"yolov8n.pt\")\n",
        "    lr_inicial = 0.01 # Tasa est√°ndar para modelos nuevos\n",
        "\n",
        "# 3. Entrenamiento\n",
        "print(\"üöÄ Iniciando entrenamiento con el dataset de 1300 im√°genes...\")\n",
        "results = model.train(\n",
        "    data=data_yaml,\n",
        "    epochs=epochs,\n",
        "    imgsz=img_size,\n",
        "    batch=batch_size,\n",
        "    project=output_dir,\n",
        "    name=\"train_experiment\",\n",
        "    exist_ok=True,\n",
        "    # --- Mejoras de estabilidad ---\n",
        "    lr0=lr_inicial,    # Tasa de aprendizaje ajustada seg√∫n el origen\n",
        "    patience=30,       # Si en 30 √©pocas no mejora, para solo (ahorra tiempo)\n",
        "    save=True,\n",
        "    pretrained=True    # Asegura que use los pesos cargados\n",
        ")\n",
        "\n",
        "# 4. Gesti√≥n de archivos finales\n",
        "print(\"‚úÖ Entrenamiento finalizado.\")\n",
        "\n",
        "# Definir la ruta donde YOLO dej√≥ el mejor archivo\n",
        "new_best_path = Path(output_dir) / \"train_experiment\" / \"weights\" / \"best.pt\"\n",
        "\n",
        "if new_best_path.exists():\n",
        "    # Aseguramos que la carpeta destino exista\n",
        "    Path(\"/content/in\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Copiamos el nuevo modelo al destino\n",
        "    shutil.copy2(new_best_path, best_pt_path)\n",
        "    print(f\"‚≠ê El nuevo 'best.pt' ha sido actualizado en: {best_pt_path}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Error: No se encontr√≥ el archivo best.pt generado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAa4XjvWxtr1",
        "outputId": "cc204d7d-9b73-43bf-dc5a-69933ce6e410",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ÑπÔ∏è Iniciando desde cero con YOLOv8 Nano.\n",
            "üöÄ Iniciando entrenamiento con el dataset de 1300 im√°genes...\n",
            "Ultralytics 8.4.9 üöÄ Python-3.12.12 torch-2.9.0+cpu CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train_experiment, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/train_experiment, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752872  ultralytics.nn.modules.head.Detect           [8, 16, None, [64, 128, 256]] \n",
            "Model summary: 130 layers, 3,012,408 parameters, 3,012,392 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 837.5¬±282.7 MB/s, size: 34.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train.cache... 708 images, 455 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 708/708 135.0Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 925.1¬±310.4 MB/s, size: 35.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val.cache... 177 images, 109 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 177/177 41.2Mit/s 0.0s\n",
            "Plotting labels to /content/runs/train_experiment/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/train_experiment\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50         0G      2.425      6.434       2.12         29        640: 31% ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 14/45 13.1s/it 3:13<6:45"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 13 ‚Äî Validaci√≥n visual en im√°genes (val):} \\\n",
        "\\\\\\ \\text{Usa best.pt para predecir sobre images/val y guarda im√°genes con cajas dibujadas y las descarga.}$$\n"
      ],
      "metadata": {
        "id": "nPW6lHvex422"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Genera predicciones sobre val y descarga un ZIP con los resultados (si falta algo, no falla: avisa)\n",
        "run_name = \"train\"                                               # Nombre del entrenamiento (debe coincidir con Bloque 12)\n",
        "pred_name = \"predict_val\"                                        # Nombre de carpeta de predicciones para val\n",
        "\n",
        "best_path = DIR_RUNS/run_name/\"weights/best.pt\"                  # Ruta esperada del modelo best.pt\n",
        "val_images_dir = DIR_DATASET/\"images/val\"                        # Ruta esperada del set de validaci√≥n\n",
        "\n",
        "# Revisa prerequisitos antes de predecir\n",
        "if not best_path.exists():                                       # Si no existe best.pt\n",
        "    print(\"‚ö†Ô∏è No encuentro best.pt todav√≠a en:\", best_path)      # Aviso\n",
        "    print(\"‚ÑπÔ∏è Corre el Bloque 12 (entrenamiento) y aseg√∫rate que termine bien.\")  # Gu√≠a\n",
        "elif not val_images_dir.exists():                                # Si no existe la carpeta val\n",
        "    print(\"‚ö†Ô∏è No encuentro images/val en:\", val_images_dir)      # Aviso\n",
        "    print(\"‚ÑπÔ∏è Corre el Bloque 10 (normalizaci√≥n + split) para crear el dataset.\")  # Gu√≠a\n",
        "else:\n",
        "    # Intenta ejecutar predicci√≥n sobre im√°genes de validaci√≥n\n",
        "    try:\n",
        "        print(\"‚úÖ Iniciando predicci√≥n sobre val:\")              # Mensaje de inicio\n",
        "        print(\" - Modelo:\", best_path)                           # Muestra el modelo que se usar√°\n",
        "        print(\" - Fuente (val):\", val_images_dir)                # Muestra la carpeta fuente\n",
        "        print(\" - Salida:\", DIR_RUNS/pred_name)                  # Muestra la carpeta de salida\n",
        "\n",
        "        model = YOLO(str(best_path))                             # Carga el modelo entrenado\n",
        "        model.predict(                                           # Ejecuta predicci√≥n sobre val\n",
        "            source=str(val_images_dir),                          # Fuente: im√°genes val\n",
        "            save=True,                                           # Guarda im√°genes con cajas dibujadas\n",
        "            project=str(DIR_RUNS),                               # Carpeta base de salida\n",
        "            name=pred_name,                                      # Nombre de la carpeta de predicci√≥n\n",
        "            exist_ok=True                                        # Reutiliza carpeta si ya existe\n",
        "        )\n",
        "\n",
        "        print(\"‚úÖ Predicciones val guardadas en:\", DIR_RUNS/pred_name)  # Confirmaci√≥n final\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è Fall√≥ la predicci√≥n en val por un error:\")      # Aviso de error\n",
        "        print(\"   \", str(e)[:400])                                # Muestra parte del error\n",
        "        print(\"‚ÑπÔ∏è Tip t√≠pico: revisa rutas, nombres o si hay im√°genes corruptas.\")  # Gu√≠a r√°pida\n",
        "\n",
        "    # Chequeo de outputs + creaci√≥n de ZIP para descargar\n",
        "    out_dir = DIR_RUNS/pred_name                                  # Carpeta de salida\n",
        "    if not out_dir.exists():                                      # Si no existe salida\n",
        "        print(\"‚ö†Ô∏è No existe la carpeta de salida:\", out_dir)      # Aviso\n",
        "    else:\n",
        "        # Lista im√°genes generadas\n",
        "        out_imgs = sorted([p for p in out_dir.iterdir() if p.suffix.lower() in [\".jpg\",\".png\"]])  # Im√°genes salida\n",
        "        print(\"‚úÖ Cantidad de im√°genes generadas:\", len(out_imgs)) # Cuenta\n",
        "        if out_imgs:\n",
        "            print(\"‚úÖ Ejemplo:\", out_imgs[0].name)                 # Muestra 1 ejemplo\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è No veo im√°genes generadas en predict_val (puede ser que YOLO no haya guardado o que no haya detecciones).\")  # Aviso\n",
        "\n",
        "        # Crea ZIP descargable con todo el contenido de predict_val\n",
        "        zip_path = DIR_OUT/\"val_predictions.zip\"                   # Ruta del zip final\n",
        "        if zip_path.exists():                                      # Si ya exist√≠a\n",
        "            zip_path.unlink()                                      # Borra el zip anterior\n",
        "\n",
        "        with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:  # Crea zip\n",
        "            for p in sorted(out_dir.rglob(\"*\")):                   # Recorre todo dentro de predict_val\n",
        "                if p.is_file():                                    # Solo archivos\n",
        "                    z.write(p, arcname=str(p.relative_to(out_dir)))  # Agrega con ruta relativa\n",
        "\n",
        "        print(\"‚úÖ ZIP de validaci√≥n creado en:\", zip_path)          # Confirma zip\n",
        "\n",
        "        # Descarga autom√°tica\n",
        "        try:\n",
        "            from google.colab import files                         # Importa descarga\n",
        "            files.download(str(zip_path))                          # Descarga zip\n",
        "            print(\"‚úÖ Descarga iniciada: val_predictions.zip\")      # Confirmaci√≥n\n",
        "        except Exception:\n",
        "            print(\"‚ö†Ô∏è No pude iniciar descarga autom√°tica, pero el zip qued√≥ en /content/out.\")  # Aviso\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juhQ5HwnyOiv",
        "outputId": "22059361-ee33-4921-9727-1a90715c8e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Iniciando predicci√≥n sobre val:\n",
            " - Modelo: /content/runs/train/weights/best.pt\n",
            " - Fuente (val): /content/dataset/images/val\n",
            " - Salida: /content/runs/predict_val\n",
            "\n",
            "image 1/49 /content/dataset/images/val/000002.jpg: 384x640 (no detections), 46.6ms\n",
            "image 2/49 /content/dataset/images/val/000007.jpg: 384x640 (no detections), 7.4ms\n",
            "image 3/49 /content/dataset/images/val/000008.jpg: 384x640 (no detections), 7.0ms\n",
            "image 4/49 /content/dataset/images/val/000009.jpg: 384x640 (no detections), 7.0ms\n",
            "image 5/49 /content/dataset/images/val/000023.jpg: 384x640 2 Estrias, 7.1ms\n",
            "image 6/49 /content/dataset/images/val/000024.jpg: 384x640 2 Estrias, 7.3ms\n",
            "image 7/49 /content/dataset/images/val/000027.jpg: 384x640 2 Estrias, 9.1ms\n",
            "image 8/49 /content/dataset/images/val/000029.jpg: 384x640 2 Estrias, 10.0ms\n",
            "image 9/49 /content/dataset/images/val/000036.jpg: 384x640 2 Estrias, 7.0ms\n",
            "image 10/49 /content/dataset/images/val/000040.jpg: 384x640 2 Estrias, 7.0ms\n",
            "image 11/49 /content/dataset/images/val/000041.jpg: 384x640 2 Estrias, 6.8ms\n",
            "image 12/49 /content/dataset/images/val/000051.jpg: 384x640 1 Estria, 7.0ms\n",
            "image 13/49 /content/dataset/images/val/000056.jpg: 384x640 2 Estrias, 7.2ms\n",
            "image 14/49 /content/dataset/images/val/000057.jpg: 384x640 1 Estria, 7.1ms\n",
            "image 15/49 /content/dataset/images/val/000058.jpg: 384x640 2 Estrias, 7.3ms\n",
            "image 16/49 /content/dataset/images/val/000060.jpg: 384x640 1 Estria, 7.1ms\n",
            "image 17/49 /content/dataset/images/val/000063.jpg: 384x640 (no detections), 7.5ms\n",
            "image 18/49 /content/dataset/images/val/000071.jpg: 384x640 (no detections), 7.2ms\n",
            "image 19/49 /content/dataset/images/val/000072.jpg: 384x640 (no detections), 7.3ms\n",
            "image 20/49 /content/dataset/images/val/000087.jpg: 384x640 (no detections), 9.1ms\n",
            "image 21/49 /content/dataset/images/val/000088.jpg: 384x640 (no detections), 7.4ms\n",
            "image 22/49 /content/dataset/images/val/000108.jpg: 384x640 2 Estrias, 7.3ms\n",
            "image 23/49 /content/dataset/images/val/000109.jpg: 384x640 1 Estria, 7.5ms\n",
            "image 24/49 /content/dataset/images/val/000115.jpg: 384x640 1 Estria, 7.6ms\n",
            "image 25/49 /content/dataset/images/val/000130.jpg: 384x640 (no detections), 12.6ms\n",
            "image 26/49 /content/dataset/images/val/000140.jpg: 384x640 (no detections), 7.3ms\n",
            "image 27/49 /content/dataset/images/val/000144.jpg: 384x640 (no detections), 7.2ms\n",
            "image 28/49 /content/dataset/images/val/000151.jpg: 384x640 (no detections), 7.7ms\n",
            "image 29/49 /content/dataset/images/val/000152.jpg: 384x640 (no detections), 7.5ms\n",
            "image 30/49 /content/dataset/images/val/000155.jpg: 384x640 (no detections), 7.2ms\n",
            "image 31/49 /content/dataset/images/val/000164.jpg: 384x640 (no detections), 7.0ms\n",
            "image 32/49 /content/dataset/images/val/000167.jpg: 384x640 (no detections), 7.1ms\n",
            "image 33/49 /content/dataset/images/val/000174.jpg: 384x640 (no detections), 7.4ms\n",
            "image 34/49 /content/dataset/images/val/000179.jpg: 384x640 (no detections), 7.4ms\n",
            "image 35/49 /content/dataset/images/val/000180.jpg: 384x640 (no detections), 9.4ms\n",
            "image 36/49 /content/dataset/images/val/000184.jpg: 384x640 (no detections), 7.4ms\n",
            "image 37/49 /content/dataset/images/val/000189.jpg: 384x640 (no detections), 7.0ms\n",
            "image 38/49 /content/dataset/images/val/000190.jpg: 384x640 (no detections), 7.3ms\n",
            "image 39/49 /content/dataset/images/val/000195.jpg: 384x640 (no detections), 8.5ms\n",
            "image 40/49 /content/dataset/images/val/000196.jpg: 384x640 (no detections), 7.6ms\n",
            "image 41/49 /content/dataset/images/val/000207.jpg: 384x640 (no detections), 7.4ms\n",
            "image 42/49 /content/dataset/images/val/000222.jpg: 384x640 (no detections), 7.0ms\n",
            "image 43/49 /content/dataset/images/val/000223.jpg: 384x640 (no detections), 7.9ms\n",
            "image 44/49 /content/dataset/images/val/000226.jpg: 384x640 (no detections), 6.9ms\n",
            "image 45/49 /content/dataset/images/val/000229.jpg: 384x640 (no detections), 7.1ms\n",
            "image 46/49 /content/dataset/images/val/000230.jpg: 384x640 (no detections), 7.2ms\n",
            "image 47/49 /content/dataset/images/val/000233.jpg: 384x640 (no detections), 6.7ms\n",
            "image 48/49 /content/dataset/images/val/000239.jpg: 384x640 (no detections), 6.7ms\n",
            "image 49/49 /content/dataset/images/val/000240.jpg: 384x640 (no detections), 6.8ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/runs/predict_val\u001b[0m\n",
            "‚úÖ Predicciones val guardadas en: /content/runs/predict_val\n",
            "‚úÖ Cantidad de im√°genes generadas: 49\n",
            "‚úÖ Ejemplo: 000002.jpg\n",
            "‚úÖ ZIP de validaci√≥n creado en: /content/out/val_predictions.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_680f3c80-4504-4e5e-99e6-53638c1c9683\", \"val_predictions.zip\", 3603725)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Descarga iniciada: val_predictions.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "$$\\textbf{Modelo DAICH}$$"
      ],
      "metadata": {
        "id": "l4RsxO8_BmlU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 14 ‚Äî Predicci√≥n en VIDEO (salida anotada + labels):} \\\n",
        "\\\\\\ \\text{Usa best.pt para predecir sobre un video y guarda: (1) video anotado y (2) archivos .txt por frame con detecciones (para luego armar CSVs).}$$\n"
      ],
      "metadata": {
        "id": "QYfLnicVyVd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Corre predicci√≥n sobre un video usando best.pt y guarda resultados (si falta algo, no falla: avisa)\n",
        "run_name = \"train\"                                                # Define el nombre del entrenamiento (igual que antes)\n",
        "pred_video_name = \"predict_video\"                                 # Define el nombre de la carpeta de salida para video\n",
        "\n",
        "best_path = DIR_RUNS/run_name/\"weights/best.pt\"                   # Ruta esperada del modelo entrenado best.pt\n",
        "video_path = next((p for p in DIR_IN.iterdir() if p.suffix.lower() in [\".mp4\", \".mov\", \".avi\", \".mkv\"]), None)  # Busca un video en /content/in\n",
        "\n",
        "# Chequea prerequisitos sin tirar error\n",
        "if not best_path.exists():                                        # Si no existe best.pt\n",
        "    print(\"‚ö†Ô∏è No encuentro best.pt en:\", best_path)               # Aviso\n",
        "    print(\"‚ÑπÔ∏è Corre el Bloque 12 (entrenamiento) antes de este bloque.\")  # Gu√≠a\n",
        "elif video_path is None:                                          # Si no hay video subido\n",
        "    print(\"‚ö†Ô∏è No detecto ning√∫n video en /content/in.\")           # Aviso\n",
        "    print(\"‚ÑπÔ∏è Sube un video (mp4/mov/avi/mkv) y vuelve a correr este bloque.\")  # Gu√≠a\n",
        "else:\n",
        "    # Intenta correr la predicci√≥n de YOLO sobre el video\n",
        "    try:\n",
        "        print(\"‚úÖ Iniciando predicci√≥n en video:\")                # Mensaje de inicio\n",
        "        print(\" - Modelo:\", best_path)                            # Muestra el modelo usado\n",
        "        print(\" - Video:\", video_path.name)                       # Muestra el video usado\n",
        "        print(\" - Salida:\", DIR_RUNS/pred_video_name)             # Muestra la carpeta de salida\n",
        "\n",
        "        model = YOLO(str(best_path))                              # Carga el modelo entrenado\n",
        "        model.predict(                                            # Ejecuta predicci√≥n\n",
        "            source=str(video_path),                               # Fuente: video\n",
        "            save=True,                                            # Guarda el video/frames con cajas dibujadas\n",
        "            save_txt=True,                                        # Guarda detecciones en .txt (por frame)\n",
        "            save_conf=True,                                       # Incluye confidence en esos .txt\n",
        "            project=str(DIR_RUNS),                                # Carpeta base de salida\n",
        "            name=pred_video_name,                                 # Nombre del run de predicci√≥n\n",
        "            exist_ok=True                                         # Reutiliza carpeta si ya existe\n",
        "        )\n",
        "\n",
        "        print(\"‚úÖ Predicci√≥n completada en:\", DIR_RUNS/pred_video_name)  # Confirmaci√≥n\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è Fall√≥ la predicci√≥n en video por un error:\")    # Aviso de error\n",
        "        print(\"   \", str(e)[:400])                                # Muestra parte del error\n",
        "        print(\"‚ÑπÔ∏è Tip t√≠pico: revisa que el video no est√© corrupto o que best.pt exista.\")  # Gu√≠a\n",
        "\n",
        "    # Chequea outputs esperados (sin romper)\n",
        "    out_dir = DIR_RUNS/pred_video_name                            # Carpeta de salida del predict\n",
        "    labels_dir = out_dir/\"labels\"                                 # Carpeta donde deber√≠an quedar los .txt\n",
        "\n",
        "    print(\"\\n‚úÖ Chequeo de outputs:\")                              # T√≠tulo del chequeo\n",
        "    if out_dir.exists():                                          # Si existe la carpeta de salida\n",
        "        print(\" - Carpeta salida OK:\", out_dir)                   # Confirma\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No existe la carpeta de salida:\", out_dir)      # Aviso\n",
        "\n",
        "    if labels_dir.exists():                                       # Si existe la carpeta labels\n",
        "        n_txt = len(list(labels_dir.glob(\"*.txt\")))               # Cuenta cuantos txt hay\n",
        "        print(\" - Labels (.txt) OK:\", labels_dir, \"| cantidad:\", n_txt)  # Confirma cantidad\n",
        "        if n_txt == 0:                                            # Si no hay txt\n",
        "            print(\"‚ö†Ô∏è labels/ existe pero no tiene .txt (puede ser que no detect√≥ nada o fall√≥ el guardado).\")  # Aviso\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No encontr√© carpeta labels/ en:\", labels_dir)   # Aviso\n",
        "        print(\"‚ÑπÔ∏è Si no existe, revisa que predict se ejecut√≥ con save_txt=True.\")  # Gu√≠a\n",
        "\n",
        "    # Intenta encontrar el video anotado generado y reportarlo\n",
        "    annotated_candidates = []                                     # Lista para candidatos de video anotado\n",
        "    for ext in [\".mp4\", \".mov\", \".avi\", \".mkv\"]:                  # Revisa extensiones comunes\n",
        "        annotated_candidates += list(out_dir.glob(f\"*{ext}\"))     # Agrega coincidencias\n",
        "\n",
        "    if annotated_candidates:                                      # Si hay alg√∫n candidato\n",
        "        annotated_video = annotated_candidates[0]                 # Toma el primero\n",
        "        print(\" - Video anotado detectado:\", annotated_video.name)  # Confirma nombre\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No pude detectar un video anotado en la carpeta de salida (a veces YOLO guarda frames en vez de video).\")  # Aviso\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "yt_ivSbyyly5",
        "outputId": "9746413a-f0a8-4248-9406-84c656e73739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'DIR_RUNS' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3816604416.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred_video_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"predict_video\"\u001b[0m                                 \u001b[0;31m# Define el nombre de la carpeta de salida para video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDIR_RUNS\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"weights/best.pt\"\u001b[0m                   \u001b[0;31m# Ruta esperada del modelo entrenado best.pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDIR_IN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\".mp4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".mov\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".avi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".mkv\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Busca un video en /content/in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DIR_RUNS' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 15 ‚Äî Construir detections.csv (detecciones por frame/tiempo):} \\\n",
        "\\\\\\ \\text{Lee los .txt generados por YOLO en labels/ y crea una tabla (CSV) con frame, tiempo, clase, confianza y caja (x,y,w,h).}$$\n"
      ],
      "metadata": {
        "id": "_W6gCFpMywBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea detections.csv desde los .txt de /content/runs/predict_video/labels (si falta algo, no falla: avisa)\n",
        "import json                                                     # Sirve para leer salida JSON de ffprobe (fps del video)\n",
        "import math                                                     # Utilidades matem√°ticas (por si se necesita)\n",
        "\n",
        "pred_video_name = \"predict_video\"                               # Debe coincidir con el nombre usado en el Bloque 14\n",
        "out_dir = DIR_RUNS/pred_video_name                              # Carpeta de salida de la predicci√≥n de video\n",
        "labels_dir = out_dir/\"labels\"                                   # Carpeta donde YOLO deja los .txt por frame\n",
        "det_csv_path = DIR_OUT/\"detections.csv\"                         # Ruta final del CSV de detecciones\n",
        "\n",
        "# Intenta detectar el video en /content/in (para calcular tiempo real con fps)\n",
        "video_path = next((p for p in DIR_IN.iterdir() if p.suffix.lower() in [\".mp4\", \".mov\", \".avi\", \".mkv\"]), None)  # Busca video subido\n",
        "\n",
        "# Funci√≥n para obtener FPS real del video usando ffprobe (si falla, devuelve None)\n",
        "def get_video_fps(path):                                        # Define funci√≥n para leer fps del video\n",
        "    try:\n",
        "        cmd = f'ffprobe -v error -select_streams v:0 -show_entries stream=r_frame_rate -of json \"{path}\"'  # Comando ffprobe\n",
        "        r = subprocess.run(cmd, shell=True, capture_output=True, text=True)  # Ejecuta ffprobe\n",
        "        data = json.loads(r.stdout)                              # Parsea JSON\n",
        "        rate = data[\"streams\"][0][\"r_frame_rate\"]                # Lee r_frame_rate (ej: \"30000/1001\")\n",
        "        num, den = rate.split(\"/\")                               # Separa numerador/denominador\n",
        "        return float(num) / float(den)                           # Calcula fps como n√∫mero\n",
        "    except Exception:\n",
        "        return None                                              # Si algo falla, retorna None\n",
        "\n",
        "# Chequea prerequisitos sin romper el notebook\n",
        "if not out_dir.exists():                                        # Si no existe carpeta de predicci√≥n de video\n",
        "    print(\"‚ö†Ô∏è No existe la carpeta de predicci√≥n:\", out_dir)     # Aviso\n",
        "    print(\"‚ÑπÔ∏è Corre el Bloque 14 (predicci√≥n en video) antes de este bloque.\")  # Gu√≠a\n",
        "elif not labels_dir.exists():                                    # Si no existe labels/\n",
        "    print(\"‚ö†Ô∏è No existe la carpeta labels/:\", labels_dir)        # Aviso\n",
        "    print(\"‚ÑπÔ∏è Aseg√∫rate de correr el Bloque 14 con save_txt=True y save_conf=True.\")  # Gu√≠a\n",
        "else:\n",
        "    # Obtiene fps del video (si no hay video o falla, usa fps=1 como fallback)\n",
        "    fps = get_video_fps(video_path) if video_path else None      # Calcula fps real si hay video\n",
        "    if fps is None:                                              # Si no se pudo obtener fps\n",
        "        fps = 1.0                                                # Fallback para no romper el flujo\n",
        "        print(\"‚ö†Ô∏è No pude obtener FPS del video; usar√© fps=1.0 como aproximaci√≥n para time_s.\")  # Aviso\n",
        "    else:\n",
        "        print(\"‚úÖ FPS detectado del video:\", fps)                 # Confirma fps real\n",
        "\n",
        "    # Lee todos los .txt de labels/ ordenados por nombre\n",
        "    txt_files = sorted(labels_dir.glob(\"*.txt\"))                 # Lista txt en labels/\n",
        "    if len(txt_files) == 0:                                      # Si no hay txt\n",
        "        print(\"‚ö†Ô∏è labels/ existe pero no tiene .txt. Puede que no haya detecciones o algo fall√≥.\")  # Aviso\n",
        "    else:\n",
        "        rows = []                                                # Lista para acumular filas del CSV\n",
        "\n",
        "        # Recorre cada archivo .txt (cada uno representa un frame/imagen)\n",
        "        for lf in txt_files:                                     # Recorre cada archivo de detecci√≥n\n",
        "            stem = lf.stem                                       # Nombre sin extensi√≥n (ej: \"000001\")\n",
        "            digits = re.sub(r\"\\D\", \"\", stem)                     # Extrae solo n√∫meros del nombre\n",
        "            if digits == \"\":                                     # Si no hay n√∫meros, salta\n",
        "                continue                                         # Evita errores de conversi√≥n\n",
        "\n",
        "            frame_idx = int(digits)                              # Convierte a √≠ndice de frame\n",
        "            time_s = frame_idx / fps                             # Convierte frame a tiempo en segundos (aprox)\n",
        "\n",
        "            # Lee cada detecci√≥n dentro del txt (una l√≠nea por detecci√≥n)\n",
        "            content = lf.read_text(encoding=\"utf-8\").strip()     # Lee el contenido del archivo\n",
        "            if content == \"\":                                    # Si est√° vac√≠o, no hay detecciones en ese frame\n",
        "                continue                                         # Salta\n",
        "\n",
        "            for line in content.splitlines():                    # Recorre cada l√≠nea del txt\n",
        "                parts = line.split()                             # Separa por espacios\n",
        "                if len(parts) < 5:                               # Si no tiene lo m√≠nimo YOLO\n",
        "                    continue                                     # Salta l√≠neas raras\n",
        "\n",
        "                cls_id = int(parts[0])                           # ID de clase (0,1,2...)\n",
        "                x = float(parts[1]); y = float(parts[2])         # Centro x,y normalizado (0-1)\n",
        "                w = float(parts[3]); h = float(parts[4])         # Ancho/alto normalizado (0-1)\n",
        "\n",
        "                # confidence solo existe si guardaste save_conf=True\n",
        "                conf = float(parts[5]) if len(parts) >= 6 else None  # Lee confidence si existe\n",
        "\n",
        "                # Obtiene nombre de clase si existe lista 'classes' (si no, deja el id)\n",
        "                class_name = None                                # Inicializa nombre de clase\n",
        "                if \"classes\" in globals() and isinstance(classes, list) and cls_id < len(classes):  # Si existe lista classes\n",
        "                    class_name = classes[cls_id]                 # Traduce id a nombre\n",
        "                else:\n",
        "                    class_name = str(cls_id)                     # Fallback: usa el id como texto\n",
        "\n",
        "                # Agrega una fila a la tabla\n",
        "                rows.append({                                    # Crea un dict por detecci√≥n\n",
        "                    \"frame\": frame_idx,                          # Frame detectado\n",
        "                    \"time_s\": time_s,                            # Tiempo aproximado en segundos\n",
        "                    \"class_id\": cls_id,                          # ID de clase\n",
        "                    \"class_name\": class_name,                    # Nombre de clase (si est√° definido)\n",
        "                    \"conf\": conf,                                # Confianza (puede ser None)\n",
        "                    \"x\": x, \"y\": y, \"w\": w, \"h\": h               # Caja en formato YOLO normalizado\n",
        "                })\n",
        "\n",
        "        # Convierte a DataFrame y guarda CSV\n",
        "        det_df = pd.DataFrame(rows)                              # Crea tabla con todas las detecciones\n",
        "        if det_df.empty:                                         # Si qued√≥ vac√≠o\n",
        "            print(\"‚ö†Ô∏è No se generaron filas en detections.csv (quiz√°s no hubo detecciones).\")  # Aviso\n",
        "        else:\n",
        "            det_df = det_df.sort_values([\"frame\", \"conf\"], ascending=[True, False])  # Ordena por frame y mejor confianza\n",
        "            det_df.to_csv(det_csv_path, index=False, encoding=\"utf-8\")               # Guarda el CSV\n",
        "\n",
        "            print(\"‚úÖ detections.csv creado en:\", det_csv_path)   # Confirma salida\n",
        "            print(\"‚úÖ Filas:\", len(det_df), \"| Frames √∫nicos:\", det_df[\"frame\"].nunique())  # Resumen r√°pido\n",
        "            print(\"‚úÖ Ejemplo de 5 filas:\")                       # T√≠tulo ejemplo\n",
        "            print(det_df.head(5).to_string(index=False))          # Muestra 5 filas\n"
      ],
      "metadata": {
        "id": "-YtL6dH6zEI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 16 ‚Äî Construir events.csv (intervalos/timeline):} \\\n",
        "\\\\\\ \\text{Convierte detections.csv en ‚Äúeventos‚Äù por clase: agrupa frames cercanos en intervalos (inicio‚Äìfin) para evitar parpadeos y generar un timeline legible.}$$\n"
      ],
      "metadata": {
        "id": "ooUu7Bg8zgsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea events.csv agrupando detecciones por clase en intervalos (si falta detections.csv, no falla: avisa)\n",
        "events_csv_path = DIR_OUT/\"events.csv\"                             # Define d√≥nde se guardar√° el archivo de eventos\n",
        "det_csv_path = DIR_OUT/\"detections.csv\"                            # Ruta esperada del detections.csv\n",
        "\n",
        "# Par√°metros anti-parpadeo (ajustables)\n",
        "min_conf = 0.35                                                     # Umbral m√≠nimo de confianza para considerar detecci√≥n\n",
        "gap_frames = 2                                                      # Permite ‚Äúhuecos‚Äù de hasta N frames dentro de un mismo evento\n",
        "min_len_frames = 3                                                  # Evento m√≠nimo: requiere al menos N frames para existir\n",
        "\n",
        "# Intenta obtener FPS del video para convertir frames a segundos (si falla, usa 1.0)\n",
        "video_path = next((p for p in DIR_IN.iterdir() if p.suffix.lower() in [\".mp4\", \".mov\", \".avi\", \".mkv\"]), None)  # Busca video en /content/in\n",
        "\n",
        "def get_video_fps_safe(path):                                       # Funci√≥n segura para obtener fps del video\n",
        "    try:\n",
        "        import json                                                 # Importa json para parsear ffprobe\n",
        "        cmd = f'ffprobe -v error -select_streams v:0 -show_entries stream=r_frame_rate -of json \"{path}\"'  # Comando ffprobe\n",
        "        r = subprocess.run(cmd, shell=True, capture_output=True, text=True)  # Ejecuta ffprobe\n",
        "        data = json.loads(r.stdout)                                 # Parsea JSON\n",
        "        rate = data[\"streams\"][0][\"r_frame_rate\"]                   # Lee r_frame_rate (ej: \"30000/1001\")\n",
        "        num, den = rate.split(\"/\")                                  # Separa numerador/denominador\n",
        "        return float(num) / float(den)                              # Devuelve fps real\n",
        "    except Exception:\n",
        "        return 1.0                                                  # Fallback si falla\n",
        "\n",
        "fps = get_video_fps_safe(video_path) if video_path else 1.0         # Calcula fps si hay video; si no, usa 1.0\n",
        "print(\"‚úÖ FPS usado para convertir frames‚Üísegundos:\", fps)            # Confirma fps usado\n",
        "\n",
        "# Si no existe detections.csv, avisa y termina sin romper el notebook\n",
        "if not det_csv_path.exists():                                       # Verifica si existe detections.csv\n",
        "    print(\"‚ö†Ô∏è No existe detections.csv en:\", det_csv_path)          # Aviso\n",
        "    print(\"‚ÑπÔ∏è Corre el Bloque 15 (detections.csv) antes de este bloque.\")  # Gu√≠a\n",
        "else:\n",
        "    # Carga detections.csv (si est√° vac√≠o o corrupto, avisa sin romper)\n",
        "    try:\n",
        "        det_df = pd.read_csv(det_csv_path)                          # Lee el CSV de detecciones\n",
        "        print(\"‚úÖ detections.csv cargado | filas:\", len(det_df))     # Confirma carga\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è No pude leer detections.csv por un error:\")       # Aviso\n",
        "        print(\"   \", str(e)[:300])                                   # Muestra parte del error\n",
        "        det_df = pd.DataFrame()                                     # Deja DF vac√≠o para no romper\n",
        "\n",
        "    # Si no hay datos, avisa y termina\n",
        "    if det_df.empty:                                                # Revisa si el DataFrame qued√≥ vac√≠o\n",
        "        print(\"‚ö†Ô∏è detections.csv est√° vac√≠o; no puedo generar events.csv.\")  # Aviso\n",
        "        print(\"‚ÑπÔ∏è Esto puede pasar si el modelo no detect√≥ nada en el video.\")  # Gu√≠a\n",
        "    else:\n",
        "        # Asegura columnas necesarias (si falta alguna, avisa y termina)\n",
        "        needed = {\"frame\", \"class_name\", \"conf\"}                    # Columnas m√≠nimas requeridas\n",
        "        if not needed.issubset(set(det_df.columns)):                # Verifica columnas\n",
        "            print(\"‚ö†Ô∏è detections.csv no tiene las columnas m√≠nimas:\", needed)  # Aviso\n",
        "            print(\"‚ÑπÔ∏è Revisa que el Bloque 15 haya generado frame/class_name/conf.\")  # Gu√≠a\n",
        "        else:\n",
        "            events_rows = []                                        # Lista donde guardaremos eventos (intervalos)\n",
        "\n",
        "            # Recorre cada clase y crea intervalos de frames consecutivos (con tolerancia de gap)\n",
        "            for cname in sorted(det_df[\"class_name\"].dropna().unique()):  # Recorre clases detectadas\n",
        "                sub = det_df[(det_df[\"class_name\"] == cname)]       # Filtra por clase\n",
        "                sub = sub[sub[\"conf\"].fillna(0) >= min_conf]        # Filtra por confianza m√≠nima (maneja NaN)\n",
        "\n",
        "                frames = sorted(sub[\"frame\"].dropna().astype(int).unique())  # Lista frames √∫nicos ordenados\n",
        "                if len(frames) == 0:                                # Si no hay frames para esta clase\n",
        "                    continue                                        # Pasa a la siguiente clase\n",
        "\n",
        "                start = frames[0]                                   # Inicio del evento actual\n",
        "                prev = frames[0]                                    # √öltimo frame visto del evento actual\n",
        "\n",
        "                for fr in frames[1:]:                               # Recorre frames siguientes\n",
        "                    if fr <= prev + 1 + gap_frames:                 # Si est√° cerca (con tolerancia de huecos)\n",
        "                        prev = fr                                   # Extiende el evento actual\n",
        "                    else:\n",
        "                        # Cierra evento anterior si cumple largo m√≠nimo\n",
        "                        if (prev - start + 1) >= min_len_frames:    # Verifica largo m√≠nimo del evento\n",
        "                            events_rows.append([cname, start, prev])  # Guarda evento (clase, inicio, fin)\n",
        "                        start = fr                                  # Abre nuevo evento\n",
        "                        prev = fr                                   # Reinicia √∫ltimo frame\n",
        "\n",
        "                # Cierra el √∫ltimo evento\n",
        "                if (prev - start + 1) >= min_len_frames:            # Verifica largo m√≠nimo final\n",
        "                    events_rows.append([cname, start, prev])         # Guarda √∫ltimo evento\n",
        "\n",
        "            # Si no hubo eventos (por filtros), avisa y termina sin romper\n",
        "            if len(events_rows) == 0:                               # Revisa si se gener√≥ algo\n",
        "                print(\"‚ö†Ô∏è No se generaron eventos con los par√°metros actuales.\")  # Aviso\n",
        "                print(\"‚ÑπÔ∏è Prueba bajar min_conf o min_len_frames si te est√° quedando vac√≠o.\")  # Gu√≠a\n",
        "            else:\n",
        "                # Convierte eventos a DataFrame y calcula tiempos\n",
        "                ev_df = pd.DataFrame(events_rows, columns=[\"class_name\", \"start_frame\", \"end_frame\"])  # Crea tabla de eventos\n",
        "                ev_df[\"start_s\"] = ev_df[\"start_frame\"] / fps       # Convierte inicio a segundos\n",
        "                ev_df[\"end_s\"] = ev_df[\"end_frame\"] / fps           # Convierte fin a segundos\n",
        "                ev_df[\"duration_s\"] = (ev_df[\"end_s\"] - ev_df[\"start_s\"]).clip(lower=0)  # Calcula duraci√≥n no negativa\n",
        "\n",
        "                # Ordena eventos por tiempo de inicio\n",
        "                ev_df = ev_df.sort_values([\"start_s\", \"class_name\"])  # Ordena cronol√≥gicamente\n",
        "\n",
        "                # Guarda events.csv\n",
        "                ev_df.to_csv(events_csv_path, index=False, encoding=\"utf-8\")  # Guarda el CSV final\n",
        "\n",
        "                # Prints de confirmaci√≥n + resumen\n",
        "                print(\"‚úÖ events.csv creado en:\", events_csv_path)   # Confirma salida\n",
        "                print(\"‚úÖ Eventos:\", len(ev_df), \"| Clases:\", ev_df[\"class_name\"].nunique())  # Resumen\n",
        "                print(\"‚úÖ Ejemplo de 10 eventos:\")                   # T√≠tulo ejemplo\n",
        "                print(ev_df.head(10).to_string(index=False))         # Muestra 10 filas\n",
        "\n",
        "                # Guarda los par√°metros usados para trazabilidad\n",
        "                params_path = DIR_OUT/\"events_params.txt\"            # Archivo para guardar par√°metros\n",
        "                params_text = (                                     # Texto de par√°metros\n",
        "                    f\"min_conf={min_conf}\\n\"\n",
        "                    f\"gap_frames={gap_frames}\\n\"\n",
        "                    f\"min_len_frames={min_len_frames}\\n\"\n",
        "                    f\"fps_used={fps}\\n\"\n",
        "                )\n",
        "                params_path.write_text(params_text, encoding=\"utf-8\")  # Escribe par√°metros\n",
        "                print(\"‚úÖ Par√°metros guardados en:\", params_path)     # Confirma guardado\n"
      ],
      "metadata": {
        "id": "EoW-Zt51zkFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "$$\\textbf{Bloques auxiliares}$$"
      ],
      "metadata": {
        "id": "KY4q8VSoB8io"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 3 ‚Äî Subida de archivos (cvat zip, videos, best.pt):} \\\n",
        "\\\\\\ \\text{Permite subir archivos desde tu computador a Colab y los deja guardados en content in para usarlos en el flujo.}$$"
      ],
      "metadata": {
        "id": "0mw1_dD2rcUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Habilita el bot√≥n de subir archivos desde tu PC a Colab\n",
        "from google.colab import files  # Herramienta de Colab para subir archivos manualmente\n",
        "\n",
        "# Abre el selector para subir: video.mp4 o images.zip o cvat_yolo_export.zip\n",
        "uploaded = files.upload()  # Te deja elegir archivos desde tu computador\n",
        "\n",
        "# Mueve cada archivo subido a la carpeta est√°ndar /content/in\n",
        "for fname in uploaded.keys():              # Recorre los nombres de lo que subiste\n",
        "    src = Path(\"/content\")/fname           # Colab lo deja primero en /content\n",
        "    dst = DIR_IN/fname                     # Destino final en /content/in\n",
        "    if src.exists():                       # Confirma que el archivo est√°\n",
        "        shutil.move(str(src), str(dst))    # Lo mueve a /content/in\n",
        "\n",
        "# Muestra lo que qued√≥ en /content/in para confirmar que est√° OK\n",
        "print(\"‚úÖ Archivos guardados en /content/in:\")  # Mensaje de confirmaci√≥n\n",
        "items = list(DIR_IN.iterdir())                 # Lee el contenido de /content/in\n",
        "if items:                                      # Si hay archivos\n",
        "    for p in items:                            # Recorre cada archivo\n",
        "        print(\" -\", p.name, f\"({p.stat().st_size/1e6:.2f} MB)\")  # Nombre y tama√±o\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Carpeta vac√≠a: no se subi√≥ nada a√∫n.\")             # Aviso si no hay archivos\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "ffn9I0vYriUw",
        "outputId": "0233bb3e-0d32-4cf6-ca55-cda0bfcea2a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2047d4e1-6463-4ee7-b1a7-d3e2c45881e8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2047d4e1-6463-4ee7-b1a7-d3e2c45881e8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cvat t1p2 t10 y t3p2.zip to cvat t1p2 t10 y t3p2.zip\n",
            "‚úÖ Archivos guardados en /content/in:\n",
            " - cvat t1p2 t10 y t3p2.zip (28.30 MB)\n",
            " - .ipynb_checkpoints (0.00 MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 6 ‚Äî Video ‚Üí Frames:} \\\n",
        "\\\\\\ \\text{Si hay un video, extrae im√°genes (frames) a una frecuencia definida (fps) y las guarda en #/content/work/frames para etiquetarlas despu√©s.}$$\n"
      ],
      "metadata": {
        "id": "Cqn_85R1t49f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Busca un video por extensi√≥n com√∫n (si existe)\n",
        "video = next((p for p in in_files if p.suffix.lower() in [\".mp4\", \".mov\", \".avi\", \".mkv\"]), None)  # Encuentra el primer video\n",
        "\n",
        "# Extrae frames desde el video detectado (si no hay video, no falla: solo avisa)\n",
        "fps_extract = 1.0                                              # Define cu√°ntas im√°genes por segundo extraer (ej: 1.0 = 1 frame/seg)\n",
        "img_ext = \"jpg\"                                                # Define el formato de imagen de salida (jpg o png)\n",
        "\n",
        "# Si no hay video, no hacemos nada y seguimos\n",
        "if video is None:                                              # Revisa si se detect√≥ un video en /content/in\n",
        "    print(\"‚ö†Ô∏è No hay video detectado en /content/in, as√≠ que no se extraen frames todav√≠a.\")  # Aviso sin romper el flujo\n",
        "else:\n",
        "    # Limpia frames anteriores para no mezclar corridas\n",
        "    old_frames = list(FRAMES_DIR.glob(f\"*.{img_ext}\"))          # Busca frames antiguos en la carpeta de frames\n",
        "    for f in old_frames:                                        # Recorre frames antiguos\n",
        "        f.unlink()                                              # Borra cada frame antiguo\n",
        "\n",
        "    # Define el n√∫mero inicial desde el cual deseas comenzar la numeraci√≥n\n",
        "    start_number = 1  # Puedes poner el n√∫mero que desees\n",
        "\n",
        "    # Define el patr√≥n de nombres con el n√∫mero de inicio\n",
        "    out_pattern = str(FRAMES_DIR / f\"%06d.{img_ext}\")\n",
        "\n",
        "    # Construye y ejecuta el comando ffmpeg para extraer frames\n",
        "    cmd = [\n",
        "    \"ffmpeg\", \"-y\",\n",
        "    \"-i\", str(video),\n",
        "    \"-vf\", f\"fps={fps_extract}\",\n",
        "    \"-start_number\", str(start_number), # <--- ESTO indica d√≥nde empezar\n",
        "    out_pattern]\n",
        "\n",
        "    print(\"‚úÖ Ejecutando FFmpeg para extraer frames:\")          # Mensaje de inicio\n",
        "    print(\"   \", \" \".join(cmd))                                 # Muestra el comando para trazabilidad\n",
        "    subprocess.run(cmd, check=False)                            # Ejecuta sin romper el notebook si ffmpeg devuelve error\n",
        "\n",
        "    # Cuenta y muestra resultados\n",
        "    frames = sorted(FRAMES_DIR.glob(f\"*.{img_ext}\"))            # Busca los frames generados\n",
        "    if len(frames) == 0:                                        # Si no se gener√≥ ning√∫n frame\n",
        "        print(\"‚ö†Ô∏è No se generaron frames (revisa si el video est√° OK o si fps_extract es muy bajo).\")  # Aviso\n",
        "    else:\n",
        "        print(f\"‚úÖ Frames listos: {len(frames)} en {FRAMES_DIR}\")  # Confirma cu√°ntos frames se crearon\n",
        "        print(\"   Ejemplo primero/√∫ltimo:\", frames[0].name, \"|\", frames[-1].name)  # Muestra nombres de ejemplo\n",
        "\n",
        "# Comprime los frames en un ZIP descargable (si no hay frames, no falla: solo avisa)\n",
        "zip_frames_path = DIR_OUT/\"frames.zip\"                         # Define d√≥nde quedar√° el zip final\n",
        "\n",
        "# Busca frames existentes en la carpeta de frames\n",
        "frame_files = sorted(list(FRAMES_DIR.glob(\"*.jpg\")) + list(FRAMES_DIR.glob(\"*.png\")))  # Re√∫ne frames jpg/png\n",
        "\n",
        "# Si no hay frames a√∫n, avisa y termina sin error\n",
        "if len(frame_files) == 0:                                      # Revisa si hay frames para comprimir\n",
        "    print(\"‚ö†Ô∏è No hay frames en /content/work/frames, as√≠ que no se puede crear frames.zip todav√≠a.\")  # Aviso\n",
        "else:\n",
        "    # Si ya exist√≠a un zip antiguo, lo borra para evitar confusiones\n",
        "    if zip_frames_path.exists():                               # Verifica si el zip ya existe\n",
        "        zip_frames_path.unlink()                               # Borra el zip anterior\n",
        "\n",
        "    # Crea el zip con todos los frames\n",
        "    with zipfile.ZipFile(zip_frames_path, \"w\", zipfile.ZIP_DEFLATED) as z:  # Abre un zip en modo escritura\n",
        "        for f in frame_files:                                  # Recorre cada frame\n",
        "            z.write(f, arcname=f.name)                         # Agrega el archivo al zip con su nombre\n",
        "\n",
        "    # Confirma que el zip se cre√≥ correctamente\n",
        "    print(\"‚úÖ ZIP creado para CVAT:\", zip_frames_path)          # Muestra la ruta del zip creado\n",
        "    print(f\"‚úÖ Incluye {len(frame_files)} im√°genes.\")          # Indica cu√°ntas im√°genes quedaron dentro\n",
        "\n",
        "    # Opci√≥n de descarga directa (si quieres)\n",
        "    try:\n",
        "        from google.colab import files                         # Importa herramienta de descarga de Colab\n",
        "        files.download(str(zip_frames_path))                   # Descarga el zip a tu PC\n",
        "        print(\"‚úÖ Descarga iniciada (si tu navegador lo permite).\")  # Confirmaci√≥n\n",
        "    except Exception:\n",
        "        print(\"‚ö†Ô∏è No pude iniciar descarga autom√°tica, pero el zip qued√≥ en /content/out para descargarlo manualmente.\")  # Aviso\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "V_neNeMBuqXH",
        "outputId": "6ca386ac-346e-4d72-e51b-5543e03b9edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Ejecutando FFmpeg para extraer frames:\n",
            "    ffmpeg -y -i /content/in/TRAMO 3 - PARTE 2.mp4 -vf fps=1.0 -start_number 590 /content/work/frames/%06d.jpg\n",
            "‚úÖ Frames listos: 296 en /content/work/frames\n",
            "   Ejemplo primero/√∫ltimo: 000590.jpg | 000885.jpg\n",
            "‚úÖ ZIP creado para CVAT: /content/out/frames.zip\n",
            "‚úÖ Incluye 296 im√°genes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5fde5128-9425-47b5-9a0a-df7539cedd53\", \"frames.zip\", 9302360)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Descarga iniciada (si tu navegador lo permite).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 17 ‚Äî Empaquetar resultados y descargar best pt u otros} \\\n",
        "\\\\\\ \\text{Copia best.pt y los CSV (detections/events) a #/content/out, busca el video anotado si existe, arma un ZIP final y lo descarga.}$$\n"
      ],
      "metadata": {
        "id": "CoyRL1Xuz2wA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Empaqueta outputs finales en /content/out y crea final_report.zip (si falta algo, no falla: avisa)\n",
        "run_name = \"train\"                                                 # Nombre del entrenamiento usado\n",
        "pred_video_name = \"predict_video\"                                  # Nombre de carpeta de predicci√≥n de video\n",
        "\n",
        "best_path = DIR_RUNS/run_name/\"weights/best.pt\"                    # Ruta esperada del best.pt\n",
        "det_csv_path = DIR_OUT/\"detections.csv\"                            # Ruta esperada del detections.csv\n",
        "events_csv_path = DIR_OUT/\"events.csv\"                             # Ruta esperada del events.csv\n",
        "\n",
        "final_zip_path = DIR_OUT/\"final_report.zip\"                        # Ruta del zip final\n",
        "best_out_path = DIR_OUT/\"best.pt\"                                  # Copia final de best.pt en /out\n",
        "\n",
        "pred_dir = DIR_RUNS/pred_video_name                                # Carpeta donde quedaron outputs del predict video\n",
        "annotated_out_path = DIR_OUT/\"annotated.mp4\"                       # Nombre est√°ndar del video anotado en /out\n",
        "\n",
        "# Lista de archivos que intentaremos meter al zip\n",
        "to_zip = []                                                        # Lista de rutas para incluir en el zip\n",
        "\n",
        "print(\"‚úÖ Preparando empaquetado de resultados...\")                 # Mensaje de inicio\n",
        "\n",
        "# Copia best.pt a /out si existe\n",
        "if best_path.exists():                                             # Si existe best.pt\n",
        "    shutil.copy2(best_path, best_out_path)                          # Copia best.pt a /content/out\n",
        "    to_zip.append(best_out_path)                                   # Agrega best.pt a lista para zip\n",
        "    print(\"‚úÖ best.pt listo en:\", best_out_path)                    # Confirma\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No encontr√© best.pt en:\", best_path)                  # Aviso\n",
        "\n",
        "# Agrega detections.csv si existe\n",
        "if det_csv_path.exists():                                          # Si existe detections.csv\n",
        "    to_zip.append(det_csv_path)                                    # Agrega al zip\n",
        "    print(\"‚úÖ detections.csv listo en:\", det_csv_path)              # Confirma\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No encontr√© detections.csv en:\", det_csv_path)        # Aviso\n",
        "\n",
        "# Agrega events.csv si existe\n",
        "if events_csv_path.exists():                                       # Si existe events.csv\n",
        "    to_zip.append(events_csv_path)                                 # Agrega al zip\n",
        "    print(\"‚úÖ events.csv listo en:\", events_csv_path)               # Confirma\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No encontr√© events.csv en:\", events_csv_path)         # Aviso\n",
        "\n",
        "# Intenta detectar un video anotado en la carpeta de predicci√≥n\n",
        "annotated_video = None                                             # Variable para guardar ruta del video anotado\n",
        "if pred_dir.exists():                                              # Si existe carpeta predict_video\n",
        "    candidates = []                                                # Lista de posibles videos generados\n",
        "    for ext in [\".mp4\", \".mov\", \".avi\", \".mkv\"]:                   # Extensiones comunes de video\n",
        "        candidates += list(pred_dir.glob(f\"*{ext}\"))               # Busca archivos de video en la carpeta\n",
        "    if candidates:                                                 # Si encontr√≥ alguno\n",
        "        annotated_video = candidates[0]                            # Toma el primero\n",
        "        shutil.copy2(annotated_video, annotated_out_path)          # Copia a /content/out con nombre est√°ndar\n",
        "        to_zip.append(annotated_out_path)                          # Agrega al zip\n",
        "        print(\"‚úÖ Video anotado listo en:\", annotated_out_path)     # Confirma\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No encontr√© video anotado en:\", pred_dir)         # Aviso\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No existe la carpeta de predicci√≥n de video:\", pred_dir)  # Aviso\n",
        "\n",
        "# Si no hay nada para comprimir, avisa y termina sin error\n",
        "if len(to_zip) == 0:                                               # Revisa si hay archivos en lista\n",
        "    print(\"‚ö†Ô∏è No hay archivos suficientes para crear el zip final todav√≠a.\")  # Aviso\n",
        "    print(\"‚ÑπÔ∏è Corre entrenamiento/predicci√≥n y generaci√≥n de CSV antes de empaquetar.\")  # Gu√≠a\n",
        "else:\n",
        "    # Borra zip anterior si exist√≠a para evitar confusi√≥n\n",
        "    if final_zip_path.exists():                                    # Si ya exist√≠a final_report.zip\n",
        "        final_zip_path.unlink()                                    # Lo borra\n",
        "\n",
        "    # Crea el zip final con todo lo disponible\n",
        "    with zipfile.ZipFile(final_zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:  # Abre zip para escribir\n",
        "        for p in to_zip:                                           # Recorre archivos a incluir\n",
        "            z.write(p, arcname=p.name)                              # Agrega con nombre simple dentro del zip\n",
        "\n",
        "    # Confirma creaci√≥n del zip final\n",
        "    print(\"‚úÖ ZIP final creado:\", final_zip_path)                   # Confirma ruta del zip\n",
        "    print(\"‚úÖ Incluye:\", [p.name for p in to_zip])                  # Muestra qu√© incluy√≥\n",
        "\n",
        "    # Intenta descargar autom√°ticamente el zip\n",
        "    try:\n",
        "        from google.colab import files                              # Importa herramienta de descarga\n",
        "        files.download(str(final_zip_path))                         # Descarga zip\n",
        "        print(\"‚úÖ Descarga iniciada (si tu navegador lo permite).\")  # Confirmaci√≥n\n",
        "    except Exception:\n",
        "        print(\"‚ö†Ô∏è No pude iniciar descarga autom√°tica, pero el zip qued√≥ en /content/out.\")  # Aviso\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuXnYeAA0AYm",
        "outputId": "c1da8eaf-b7ac-48f0-f1be-e7888c49bf36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Preparando empaquetado de resultados...\n",
            "‚úÖ best.pt listo en: /content/out/best.pt\n",
            "‚ö†Ô∏è No encontr√© detections.csv en: /content/out/detections.csv\n",
            "‚ö†Ô∏è No encontr√© events.csv en: /content/out/events.csv\n",
            "‚ö†Ô∏è No existe la carpeta de predicci√≥n de video: /content/runs/predict_video\n",
            "‚úÖ ZIP final creado: /content/out/final_report.zip\n",
            "‚úÖ Incluye: ['best.pt']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ccd9aa7b-51ba-4420-bde3-1a2e087191fd\", \"final_report.zip\", 5667109)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Descarga iniciada (si tu navegador lo permite).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 19 ‚Äî Interfaz simple (modo ‚Äúusuario final‚Äù):} \\\n",
        "\\\\\\ \\text{Permite subir un modelo best.pt y un video, ejecuta la predicci√≥n y genera final\\_report.zip (video anotado + CSVs) en #/content/out.}$$\n"
      ],
      "metadata": {
        "id": "eClX8PwF0_13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Interfaz m√≠nima: subes best.pt + video y el notebook te genera el zip final (si falta algo, no falla: avisa)\n",
        "from google.colab import files                                  # Herramienta de Colab para subir/descargar archivos\n",
        "\n",
        "# Define nombres est√°ndar de trabajo\n",
        "UI_MODEL_NAME = \"best.pt\"                                       # Nombre esperado para el modelo subido\n",
        "UI_VIDEO_NAME = None                                            # Nombre del video subido (lo detectamos por extensi√≥n)\n",
        "\n",
        "# Crea carpetas por si no existen (por seguridad)\n",
        "for d in [DIR_IN, DIR_RUNS, DIR_OUT]:                           # Asegura carpetas clave\n",
        "    d.mkdir(parents=True, exist_ok=True)                        # Crea si falta\n",
        "\n",
        "print(\"‚úÖ Interfaz simple: sube best.pt y un video (mp4/mov/avi/mkv).\")  # Instrucci√≥n amigable\n",
        "\n",
        "# Subida de archivos (el usuario elige desde su PC)\n",
        "uploaded = files.upload()                                       # Abre selector para subir archivos\n",
        "\n",
        "# Mueve lo subido a /content/in para mantener el est√°ndar\n",
        "for fname in uploaded.keys():                                   # Recorre nombres de archivos subidos\n",
        "    src = Path(\"/content\")/fname                                # Ruta temporal donde Colab deja los archivos\n",
        "    dst = DIR_IN/fname                                          # Ruta final en /content/in\n",
        "    if src.exists():                                            # Verifica existencia\n",
        "        shutil.move(str(src), str(dst))                         # Mueve a /content/in\n",
        "\n",
        "# Detecta best.pt y video dentro de /content/in\n",
        "model_path = DIR_IN/UI_MODEL_NAME                               # Ruta esperada del modelo (best.pt)\n",
        "video_path = next((p for p in DIR_IN.iterdir() if p.suffix.lower() in [\".mp4\",\".mov\",\".avi\",\".mkv\"]), None)  # Busca video\n",
        "\n",
        "# Valida inputs sin romper\n",
        "if not model_path.exists():                                     # Si no existe el modelo subido\n",
        "    print(\"‚ö†Ô∏è No encontr√© best.pt en /content/in.\")             # Aviso\n",
        "    print(\"‚ÑπÔ∏è Sube un archivo llamado exactamente 'best.pt'.\")  # Gu√≠a\n",
        "elif video_path is None:                                        # Si no se detect√≥ video\n",
        "    print(\"‚ö†Ô∏è No encontr√© un video en /content/in.\")            # Aviso\n",
        "    print(\"‚ÑπÔ∏è Sube un video .mp4/.mov/.avi/.mkv junto al best.pt.\")  # Gu√≠a\n",
        "else:\n",
        "    # Define carpeta de salida para esta predicci√≥n\n",
        "    pred_video_name = \"predict_video_ui\"                        # Nombre del run de predicci√≥n para interfaz\n",
        "    out_dir = DIR_RUNS/pred_video_name                          # Carpeta donde YOLO guardar√° resultados\n",
        "    labels_dir = out_dir/\"labels\"                               # Carpeta donde quedar√°n txt por frame\n",
        "\n",
        "    # Ejecuta predicci√≥n en video y guarda video + txt + conf\n",
        "    try:\n",
        "        print(\"‚úÖ Ejecutando predicci√≥n (interfaz):\")            # Mensaje de inicio\n",
        "        print(\" - Modelo:\", model_path)                          # Muestra modelo\n",
        "        print(\" - Video:\", video_path.name)                      # Muestra video\n",
        "        print(\" - Salida:\", out_dir)                             # Muestra salida\n",
        "\n",
        "        model = YOLO(str(model_path))                            # Carga el modelo subido\n",
        "        model.predict(                                           # Ejecuta predicci√≥n\n",
        "            source=str(video_path),                               # Video de entrada\n",
        "            save=True,                                            # Guarda salida visual\n",
        "            save_txt=True,                                        # Guarda txt por frame\n",
        "            save_conf=True,                                       # Guarda confidence\n",
        "            project=str(DIR_RUNS),                                # Carpeta base\n",
        "            name=pred_video_name,                                 # Nombre del run\n",
        "            exist_ok=True                                         # Reutiliza si existe\n",
        "        )\n",
        "\n",
        "        print(\"‚úÖ Predicci√≥n terminada.\")                         # Confirmaci√≥n\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è Fall√≥ la predicci√≥n por un error:\")            # Aviso de error\n",
        "        print(\"   \", str(e)[:400])                               # Muestra parte del error\n",
        "        print(\"‚ÑπÔ∏è Revisa que best.pt sea compatible con tu dataset/clases.\")  # Gu√≠a\n",
        "\n",
        "    # Construye detections.csv si existen labels\n",
        "    det_csv_path = DIR_OUT/\"detections.csv\"                      # Ruta detections final\n",
        "    events_csv_path = DIR_OUT/\"events.csv\"                       # Ruta events final\n",
        "\n",
        "    if not labels_dir.exists():                                  # Si no existe labels/\n",
        "        print(\"‚ö†Ô∏è No existe labels/ en la salida, as√≠ que no puedo construir CSVs.\")  # Aviso\n",
        "    else:\n",
        "        # Obtiene fps real para time_s (si falla, usa 1.0)\n",
        "        def get_video_fps_safe(path):                            # Funci√≥n segura para fps\n",
        "            try:\n",
        "                import json                                      # Para parsear JSON\n",
        "                cmd = f'ffprobe -v error -select_streams v:0 -show_entries stream=r_frame_rate -of json \"{path}\"'  # ffprobe\n",
        "                r = subprocess.run(cmd, shell=True, capture_output=True, text=True)  # Ejecuta\n",
        "                data = json.loads(r.stdout)                      # Parsea\n",
        "                rate = data[\"streams\"][0][\"r_frame_rate\"]        # Lee rate\n",
        "                num, den = rate.split(\"/\")                       # Separa\n",
        "                return float(num)/float(den)                     # Calcula fps\n",
        "            except Exception:\n",
        "                return 1.0                                       # Fallback\n",
        "\n",
        "        fps = get_video_fps_safe(video_path)                     # FPS para convertir frames a segundos\n",
        "        print(\"‚úÖ FPS usado:\", fps)                               # Confirma fps\n",
        "\n",
        "        # Lee txt y arma detections.csv\n",
        "        txt_files = sorted(labels_dir.glob(\"*.txt\"))             # Lista txt por frame\n",
        "        rows = []                                                # Filas para detections\n",
        "\n",
        "        for lf in txt_files:                                     # Recorre cada txt\n",
        "            digits = re.sub(r\"\\D\", \"\", lf.stem)                  # Extrae frame desde el nombre\n",
        "            if digits == \"\":                                     # Si no hay n√∫mero\n",
        "                continue                                         # Salta\n",
        "            frame_idx = int(digits)                              # Frame\n",
        "            time_s = frame_idx / fps                             # Tiempo en segundos (aprox)\n",
        "            content = lf.read_text(encoding=\"utf-8\").strip()     # Lee contenido\n",
        "            if content == \"\":                                    # Si vac√≠o\n",
        "                continue                                         # Salta\n",
        "\n",
        "            for line in content.splitlines():                    # Recorre detecciones\n",
        "                parts = line.split()                             # Separa\n",
        "                if len(parts) < 5:                               # Si no cumple m√≠nimo\n",
        "                    continue                                     # Salta\n",
        "                cls_id = int(parts[0])                           # Clase id\n",
        "                x, y, w, h = map(float, parts[1:5])              # Caja\n",
        "                conf = float(parts[5]) if len(parts) >= 6 else None  # Conf si existe\n",
        "                rows.append({\"frame\": frame_idx, \"time_s\": time_s, \"class_id\": cls_id, \"conf\": conf,\n",
        "                             \"x\": x, \"y\": y, \"w\": w, \"h\": h})    # Agrega fila\n",
        "\n",
        "        det_df = pd.DataFrame(rows)                              # Crea DataFrame\n",
        "        if det_df.empty:                                         # Si no hay detecciones\n",
        "            print(\"‚ö†Ô∏è No hubo detecciones, detections.csv quedar√° vac√≠o/no se generar√° events.csv.\")  # Aviso\n",
        "        else:\n",
        "            det_df = det_df.sort_values([\"frame\",\"conf\"], ascending=[True, False])  # Ordena\n",
        "            det_df.to_csv(det_csv_path, index=False, encoding=\"utf-8\")              # Guarda CSV\n",
        "            print(\"‚úÖ detections.csv listo en:\", det_csv_path)    # Confirma\n",
        "\n",
        "            # Genera events.csv agrupando por class_id (interfaz simple, sin nombres)\n",
        "            min_conf = 0.35                                      # Umbral conf\n",
        "            gap_frames = 2                                       # Huecos tolerados\n",
        "            min_len_frames = 3                                   # Largo m√≠nimo\n",
        "\n",
        "            events_rows = []                                     # Lista eventos\n",
        "            for cid in sorted(det_df[\"class_id\"].unique()):      # Recorre clases\n",
        "                sub = det_df[(det_df[\"class_id\"] == cid) & (det_df[\"conf\"].fillna(0) >= min_conf)]  # Filtra\n",
        "                frames = sorted(sub[\"frame\"].unique())           # Frames\n",
        "                if not frames:                                   # Si vac√≠o\n",
        "                    continue                                     # Salta\n",
        "                start = frames[0]; prev = frames[0]              # Inicializa evento\n",
        "                for fr in frames[1:]:                            # Recorre frames\n",
        "                    if fr <= prev + 1 + gap_frames:              # Si cercano\n",
        "                        prev = fr                                # Extiende\n",
        "                    else:\n",
        "                        if (prev - start + 1) >= min_len_frames: # Si cumple m√≠nimo\n",
        "                            events_rows.append([cid, start, prev])  # Guarda\n",
        "                        start = fr; prev = fr                    # Nuevo evento\n",
        "                if (prev - start + 1) >= min_len_frames:         # Cierra √∫ltimo\n",
        "                    events_rows.append([cid, start, prev])        # Guarda\n",
        "\n",
        "            ev_df = pd.DataFrame(events_rows, columns=[\"class_id\",\"start_frame\",\"end_frame\"])  # Tabla eventos\n",
        "            if ev_df.empty:                                      # Si no hay eventos\n",
        "                print(\"‚ö†Ô∏è No se generaron eventos con los par√°metros actuales.\")  # Aviso\n",
        "            else:\n",
        "                ev_df[\"start_s\"] = ev_df[\"start_frame\"]/fps      # Inicio s\n",
        "                ev_df[\"end_s\"] = ev_df[\"end_frame\"]/fps          # Fin s\n",
        "                ev_df[\"duration_s\"] = (ev_df[\"end_s\"]-ev_df[\"start_s\"]).clip(lower=0)  # Duraci√≥n\n",
        "                ev_df.to_csv(events_csv_path, index=False, encoding=\"utf-8\")            # Guarda CSV\n",
        "                print(\"‚úÖ events.csv listo en:\", events_csv_path)  # Confirma\n",
        "\n",
        "    # Copia video anotado (si existe) y arma zip final\n",
        "    final_zip_path = DIR_OUT/\"final_report.zip\"                  # Ruta zip final\n",
        "    to_zip = []                                                  # Lista archivos para zip\n",
        "\n",
        "    if model_path.exists():                                      # Si modelo existe\n",
        "        to_zip.append(model_path)                                # Agrega best.pt\n",
        "    if det_csv_path.exists():                                    # Si detections existe\n",
        "        to_zip.append(det_csv_path)                              # Agrega detections\n",
        "    if events_csv_path.exists():                                 # Si events existe\n",
        "        to_zip.append(events_csv_path)                           # Agrega events\n",
        "\n",
        "    # Busca un video anotado en la carpeta de salida y lo copia a /out\n",
        "    annotated_candidates = []                                    # Lista candidatos\n",
        "    for ext in [\".mp4\",\".mov\",\".avi\",\".mkv\"]:                    # Exts video\n",
        "        annotated_candidates += list(out_dir.glob(f\"*{ext}\"))     # Busca videos\n",
        "    if annotated_candidates:                                     # Si encontr√≥\n",
        "        shutil.copy2(annotated_candidates[0], DIR_OUT/\"annotated.mp4\")  # Copia a /out\n",
        "        to_zip.append(DIR_OUT/\"annotated.mp4\")                   # Agrega al zip\n",
        "        print(\"‚úÖ annotated.mp4 listo en /content/out.\")          # Confirma\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No encontr√© video anotado en la salida.\")       # Aviso\n",
        "\n",
        "    # Crea zip final si hay algo para comprimir\n",
        "    if len(to_zip) == 0:                                         # Si no hay nada\n",
        "        print(\"‚ö†Ô∏è No hay archivos para empaquetar todav√≠a.\")      # Aviso\n",
        "    else:\n",
        "        if final_zip_path.exists():                              # Si zip existe\n",
        "            final_zip_path.unlink()                              # Lo borra\n",
        "        with zipfile.ZipFile(final_zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:  # Crea zip\n",
        "            for p in to_zip:                                     # Recorre archivos\n",
        "                z.write(p, arcname=p.name)                       # Agrega al zip\n",
        "        print(\"‚úÖ final_report.zip creado en:\", final_zip_path)   # Confirma\n",
        "\n",
        "        # Descarga zip final\n",
        "        try:\n",
        "            files.download(str(final_zip_path))                  # Descarga zip\n",
        "            print(\"‚úÖ Descarga iniciada.\")                        # Confirmaci√≥n\n",
        "        except Exception:\n",
        "            print(\"‚ö†Ô∏è No pude iniciar descarga autom√°tica, pero qued√≥ en /content/out.\")  # Aviso\n"
      ],
      "metadata": {
        "id": "4r9ZXJCO1EqJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}