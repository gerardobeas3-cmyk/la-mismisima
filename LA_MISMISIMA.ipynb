{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "INDICACIONES INICIALES:\n",
        "\n",
        "- Correr en GPU\n",
        "- Las carpetas deben subirse en zip\n",
        "- Recordar subir best. pt para entrenar\n",
        "- El dataset utilizado para entrenar debe tener \"cvat\" en el nombre\n",
        "- Los csv para cruzar el modelo con las dimensiones de los da√±os deben tener \"paramento\" y \"losa\" en los nombres\n",
        "- Si se usan nuevos csvs buscar que los formatos sean iguales, ojo a las comas y puntos\n",
        "- Para que el sistema utilice el csv correcto las clases deben contener \"losa\", \"paramento\" y \"estr√≠a\" en el nombre"
      ],
      "metadata": {
        "id": "nrKfcy4piTYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "$$\\textbf{Bloques auxiliares}$$"
      ],
      "metadata": {
        "id": "KY4q8VSoB8io"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 1 ‚Äî Preparaci√≥n del entorno:}\n",
        "\\\\ \\text{Crea la estructura de carpetas del proyecto en Colab (inputs, temporales, dataset, runs y resultados) e instala librer√≠as.}$$\n"
      ],
      "metadata": {
        "id": "q3SamIJjmwHo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OTTeIyAmeIw",
        "outputId": "bb173a6f-aaa4-43a3-a04f-81aa960a4a11",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Entorno preparado. GPU disponible: True\n",
            "\n",
            "‚úÖ Listado r√°pido de carpetas del proyecto:\n",
            "\n",
            "üìÅ /content\n",
            " - DIR  .config\n",
            " - DIR  dataset\n",
            " - DIR  in\n",
            " - DIR  out\n",
            " - DIR  runs\n",
            " - DIR  sample_data\n",
            " - DIR  work\n",
            " - FILE best.pt\n",
            " - FILE losa.csv\n",
            " - FILE paramento.csv\n",
            " - FILE TRAMO 1 - PARTE 2.mp4\n",
            " - FILE TRAMO 1 - PARTE 2.srt\n",
            "\n",
            "üìÅ /content/in\n",
            " - FILE best.pt\n",
            " - FILE losa.csv\n",
            " - FILE paramento.csv\n",
            " - FILE TRAMO 1 - PARTE 2.mp4\n",
            " - FILE TRAMO 1 - PARTE 2.srt\n",
            "\n",
            "‚úÖ Espacio en disco:\n",
            "\n",
            "‚úÖ Resumen de Entradas Detectadas:\n",
            " - Video: TRAMO 1 - PARTE 2.mp4\n",
            " - Zip CVAT: ‚ùå No detectado\n",
            " - images.zip: ‚ùå No detectado\n",
            "\n",
            "üöÄ Rutas listas para el procesamiento t√©cnico.\n"
          ]
        }
      ],
      "source": [
        "import os, shutil, zipfile, subprocess, glob, re\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "from google.colab import files\n",
        "\n",
        "# Instalaciones de dependencias para el reporte y detecci√≥n\n",
        "!pip -q install ultralytics fpdf\n",
        "from ultralytics import YOLO\n",
        "from fpdf import FPDF\n",
        "\n",
        "# --- CONFIGURACI√ìN DE RUTAS MAESTRAS ---\n",
        "BASE = Path(\"/content\")\n",
        "\n",
        "# Definici√≥n de variables globales (Usadas en Bloque 4 y posteriores)\n",
        "DIR_IN = BASE/\"in\"\n",
        "DIR_WORK = BASE/\"work\"\n",
        "DIR_OUT = BASE/\"out\"\n",
        "DIR_DATASET = BASE/\"dataset\"\n",
        "DIR_RUNS = BASE/\"runs\"\n",
        "DIR_FRAMES = DIR_WORK/\"frames\"\n",
        "DIR_RAW = DIR_WORK/\"dataset_raw\"\n",
        "\n",
        "# Diccionario PATHS (Usado en Bloques 15, 16 y 17)\n",
        "PATHS = {\n",
        "    \"in\": DIR_IN,\n",
        "    \"work\": DIR_WORK,\n",
        "    \"out\": DIR_OUT,\n",
        "    \"frames\": DIR_FRAMES,\n",
        "    \"dataset\": DIR_DATASET\n",
        "}\n",
        "\n",
        "# Creaci√≥n f√≠sica de todo el √°rbol de directorios\n",
        "for p in [DIR_IN, DIR_WORK, DIR_OUT, DIR_DATASET, DIR_RUNS, DIR_FRAMES, DIR_RAW]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Entorno preparado. GPU disponible: {torch.cuda.is_available()}\")\n",
        "\n",
        "# --- FUNCIONES DE CHEQUEO (Ex Bloque 4) ---\n",
        "\n",
        "def listar_carpeta(ruta, max_items=50):\n",
        "    ruta = Path(ruta)\n",
        "    print(\"\\nüìÅ\", ruta)\n",
        "    if not ruta.exists():\n",
        "        print(\"‚ö†Ô∏è No existe todav√≠a.\")\n",
        "        return\n",
        "    items = sorted(list(ruta.iterdir()), key=lambda p: (p.is_file(), p.name.lower()))\n",
        "    if len(items) == 0:\n",
        "        print(\"‚ö†Ô∏è Est√° vac√≠a.\")\n",
        "        return\n",
        "    for p in items[:max_items]:\n",
        "        tipo = \"DIR \" if p.is_dir() else \"FILE\"\n",
        "        print(f\" - {tipo} {p.name}\")\n",
        "\n",
        "print(\"\\n‚úÖ Listado r√°pido de carpetas del proyecto:\")\n",
        "listar_carpeta(BASE)\n",
        "listar_carpeta(DIR_IN)\n",
        "\n",
        "# Chequeo de espacio y peso\n",
        "try:\n",
        "    print(\"\\n‚úÖ Espacio en disco:\")\n",
        "    subprocess.run([\"df\", \"-h\", \"/content\"], check=False)\n",
        "except: pass\n",
        "\n",
        "# --- DETECCI√ìN AUTOM√ÅTICA DE INPUTS ---\n",
        "in_files = list(DIR_IN.iterdir())\n",
        "video = next((p for p in in_files if p.suffix.lower() in [\".mp4\", \".mov\", \".avi\"]), None)\n",
        "zip_cvat = next((p for p in in_files if p.suffix.lower() == \".zip\" and \"cvat\" in p.name.lower()), None)\n",
        "zip_images = next((p for p in in_files if p.name.lower() == \"images.zip\"), None)\n",
        "\n",
        "print(\"\\n‚úÖ Resumen de Entradas Detectadas:\")\n",
        "print(\" - Video:\", video.name if video else \"‚ùå No detectado\")\n",
        "print(\" - Zip CVAT:\", zip_cvat.name if zip_cvat else \"‚ùå No detectado\")\n",
        "print(\" - images.zip:\", zip_images.name if zip_images else \"‚ùå No detectado\")\n",
        "\n",
        "print(\"\\nüöÄ Rutas listas para el procesamiento t√©cnico.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 3 ‚Äî Subida de archivos (cvat zip, videos, best.pt):} \\\n",
        "\\\\\\ \\text{Permite subir archivos desde tu computador a Colab y los deja guardados en content in para usarlos en el flujo.}$$"
      ],
      "metadata": {
        "id": "0mw1_dD2rcUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìÇ Selecciona archivos para a√±adir (Video, SRT, CSVs o Modelo)\")     # Aviso de carga\n",
        "subidos = files.upload()                                                   # Selector de archivos\n",
        "\n",
        "for nombre_original in subidos.keys():                                     # Itera sobre los archivos subidos\n",
        "    nombre_min = nombre_original.lower()                                   # Normaliza a min√∫sculas para comparar\n",
        "\n",
        "    # --- L√ìGICA DE CLASIFICACI√ìN (Mantiene archivos existentes) ---\n",
        "    if \"losa\" in nombre_min and nombre_original.endswith('.csv'):          # Identifica CSV de fondo\n",
        "        ruta_destino = PATHS[\"in\"] / \"losa.csv\"                            # Renombra para el motor de fusi√≥n\n",
        "        print(f\"üéØ Identificado como LOSA: {nombre_original}\")\n",
        "\n",
        "    elif \"paramento\" in nombre_min and nombre_original.endswith('.csv'):   # Identifica CSV de muros\n",
        "        ruta_destino = PATHS[\"in\"] / \"paramento.csv\"                       # Renombra para el motor de fusi√≥n\n",
        "        print(f\"üéØ Identificado como PARAMENTO: {nombre_original}\")\n",
        "\n",
        "    elif nombre_original.endswith('.pt'):                                 # Identifica modelos YOLO\n",
        "        ruta_destino = PATHS[\"in\"] / \"best.pt\"                             # Estandariza nombre del modelo\n",
        "        print(f\"üß† Modelo cargado/actualizado: {nombre_original}\")\n",
        "\n",
        "    else:                                                                  # Video, SRT y otros\n",
        "        ruta_destino = PATHS[\"in\"] / nombre_original                       # Conserva nombre original\n",
        "        print(f\"üì¶ Archivo guardado: {nombre_original}\")\n",
        "\n",
        "    # --- GUARDADO EN DISCO ---\n",
        "    with open(ruta_destino, \"wb\") as f:                                    # Abre destino sin borrar el resto de /in\n",
        "        f.write(subidos[nombre_original])                                  # Escribe el nuevo contenido"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ffn9I0vYriUw",
        "outputId": "f6c7ac5c-c317-4793-ae33-f21944b5d9f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Selecciona archivos para a√±adir (Video, SRT, CSVs o Modelo)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-43b3eb20-f32a-4343-9123-4a246b755239\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-43b3eb20-f32a-4343-9123-4a246b755239\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TRAMO 1 - PARTE 2.mp4 to TRAMO 1 - PARTE 2.mp4\n",
            "Saving TRAMO 1 - PARTE 2.srt to TRAMO 1 - PARTE 2.srt\n",
            "üì¶ Archivo guardado: TRAMO 1 - PARTE 2.mp4\n",
            "üì¶ Archivo guardado: TRAMO 1 - PARTE 2.srt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 6 ‚Äî Video ‚Üí Frames:} \\\n",
        "\\\\\\ \\text{Si hay un video, extrae im√°genes (frames) a una frecuencia definida (fps) y las guarda en #/content/work/frames para etiquetarlas despu√©s.}$$\n"
      ],
      "metadata": {
        "id": "Cqn_85R1t49f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Busca un video por extensi√≥n com√∫n (si existe)\n",
        "video = next((p for p in in_files if p.suffix.lower() in [\".mp4\", \".mov\", \".avi\", \".mkv\"]), None)  # Encuentra el primer video\n",
        "\n",
        "# Extrae frames desde el video detectado (si no hay video, no falla: solo avisa)\n",
        "fps_extract = 1.0                                              # Define cu√°ntas im√°genes por segundo extraer (ej: 1.0 = 1 frame/seg)\n",
        "img_ext = \"jpg\"                                                # Define el formato de imagen de salida (jpg o png)\n",
        "\n",
        "# Si no hay video, no hacemos nada y seguimos\n",
        "if video is None:                                              # Revisa si se detect√≥ un video en /content/in\n",
        "    print(\"‚ö†Ô∏è No hay video detectado en /content/in, as√≠ que no se extraen frames todav√≠a.\")  # Aviso sin romper el flujo\n",
        "else:\n",
        "    # Limpia frames anteriores para no mezclar corridas\n",
        "    old_frames = list(FRAMES_DIR.glob(f\"*.{img_ext}\"))          # Busca frames antiguos en la carpeta de frames\n",
        "    for f in old_frames:                                        # Recorre frames antiguos\n",
        "        f.unlink()                                              # Borra cada frame antiguo\n",
        "\n",
        "    # Define el n√∫mero inicial desde el cual deseas comenzar la numeraci√≥n\n",
        "    start_number = 886  # Puedes poner el n√∫mero que desees\n",
        "\n",
        "    # Define el patr√≥n de nombres con el n√∫mero de inicio\n",
        "    out_pattern = str(FRAMES_DIR / f\"%06d.{img_ext}\")\n",
        "\n",
        "    # Construye y ejecuta el comando ffmpeg para extraer frames\n",
        "    cmd = [\n",
        "    \"ffmpeg\", \"-y\",\n",
        "    \"-i\", str(video),\n",
        "    \"-vf\", f\"fps={fps_extract}\",\n",
        "    \"-start_number\", str(start_number), # <--- ESTO indica d√≥nde empezar\n",
        "    out_pattern]\n",
        "\n",
        "    print(\"‚úÖ Ejecutando FFmpeg para extraer frames:\")          # Mensaje de inicio\n",
        "    print(\"   \", \" \".join(cmd))                                 # Muestra el comando para trazabilidad\n",
        "    subprocess.run(cmd, check=False)                            # Ejecuta sin romper el notebook si ffmpeg devuelve error\n",
        "\n",
        "    # Cuenta y muestra resultados\n",
        "    frames = sorted(FRAMES_DIR.glob(f\"*.{img_ext}\"))            # Busca los frames generados\n",
        "    if len(frames) == 0:                                        # Si no se gener√≥ ning√∫n frame\n",
        "        print(\"‚ö†Ô∏è No se generaron frames (revisa si el video est√° OK o si fps_extract es muy bajo).\")  # Aviso\n",
        "    else:\n",
        "        print(f\"‚úÖ Frames listos: {len(frames)} en {FRAMES_DIR}\")  # Confirma cu√°ntos frames se crearon\n",
        "        print(\"   Ejemplo primero/√∫ltimo:\", frames[0].name, \"|\", frames[-1].name)  # Muestra nombres de ejemplo\n",
        "\n",
        "# Comprime los frames en un ZIP descargable (si no hay frames, no falla: solo avisa)\n",
        "zip_frames_path = DIR_OUT/\"frames.zip\"                         # Define d√≥nde quedar√° el zip final\n",
        "\n",
        "# Busca frames existentes en la carpeta de frames\n",
        "frame_files = sorted(list(FRAMES_DIR.glob(\"*.jpg\")) + list(FRAMES_DIR.glob(\"*.png\")))  # Re√∫ne frames jpg/png\n",
        "\n",
        "# Si no hay frames a√∫n, avisa y termina sin error\n",
        "if len(frame_files) == 0:                                      # Revisa si hay frames para comprimir\n",
        "    print(\"‚ö†Ô∏è No hay frames en /content/work/frames, as√≠ que no se puede crear frames.zip todav√≠a.\")  # Aviso\n",
        "else:\n",
        "    # Si ya exist√≠a un zip antiguo, lo borra para evitar confusiones\n",
        "    if zip_frames_path.exists():                               # Verifica si el zip ya existe\n",
        "        zip_frames_path.unlink()                               # Borra el zip anterior\n",
        "\n",
        "    # Crea el zip con todos los frames\n",
        "    with zipfile.ZipFile(zip_frames_path, \"w\", zipfile.ZIP_DEFLATED) as z:  # Abre un zip en modo escritura\n",
        "        for f in frame_files:                                  # Recorre cada frame\n",
        "            z.write(f, arcname=f.name)                         # Agrega el archivo al zip con su nombre\n",
        "\n",
        "    # Confirma que el zip se cre√≥ correctamente\n",
        "    print(\"‚úÖ ZIP creado para CVAT:\", zip_frames_path)          # Muestra la ruta del zip creado\n",
        "    print(f\"‚úÖ Incluye {len(frame_files)} im√°genes.\")          # Indica cu√°ntas im√°genes quedaron dentro\n",
        "\n",
        "    # Opci√≥n de descarga directa (si quieres)\n",
        "    try:\n",
        "        from google.colab import files                         # Importa herramienta de descarga de Colab\n",
        "        files.download(str(zip_frames_path))                   # Descarga el zip a tu PC\n",
        "        print(\"‚úÖ Descarga iniciada (si tu navegador lo permite).\")  # Confirmaci√≥n\n",
        "    except Exception:\n",
        "        print(\"‚ö†Ô∏è No pude iniciar descarga autom√°tica, pero el zip qued√≥ en /content/out para descargarlo manualmente.\")  # Aviso\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "V_neNeMBuqXH",
        "outputId": "6ca386ac-346e-4d72-e51b-5543e03b9edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Ejecutando FFmpeg para extraer frames:\n",
            "    ffmpeg -y -i /content/in/TRAMO 3 - PARTE 2.mp4 -vf fps=1.0 -start_number 590 /content/work/frames/%06d.jpg\n",
            "‚úÖ Frames listos: 296 en /content/work/frames\n",
            "   Ejemplo primero/√∫ltimo: 000590.jpg | 000885.jpg\n",
            "‚úÖ ZIP creado para CVAT: /content/out/frames.zip\n",
            "‚úÖ Incluye 296 im√°genes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5fde5128-9425-47b5-9a0a-df7539cedd53\", \"frames.zip\", 9302360)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Descarga iniciada (si tu navegador lo permite).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "$$\\textbf{Entrenamiento del modelo}$$"
      ],
      "metadata": {
        "id": "ljEWDgvkBNV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 8 ‚Äî Importar export de CVAT:} \\\n",
        "\\\\\\ \\text{Si hay zip de CVAT (BLOQUE 3), lo descomprime en /content #/work/dataset_raw. Si no tiene cvat revisar bloque 6.}$$\n"
      ],
      "metadata": {
        "id": "mIDh0gV0vizd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descomprime el export de CVAT (si existe) en /content/work/dataset_raw (si no existe, no falla: avisa)\n",
        "# Nota: Este zip suele llamarse algo como \"cvat_yolo_export.zip\" (el nombre puede variar)\n",
        "\n",
        "# Vuelve a buscar un zip que parezca de CVAT por si lo subiste reci√©n\n",
        "in_files = list(DIR_IN.iterdir())                                              # Lee archivos en /content/in\n",
        "zip_cvat = next((p for p in in_files if p.suffix.lower() == \".zip\" and \"cvat\" in p.name.lower()), None)  # Busca zip con \"cvat\" en el nombre\n",
        "\n",
        "# Si no encontramos zip CVAT, avisamos y seguimos sin error\n",
        "if zip_cvat is None:                                                           # Revisa si existe export de CVAT\n",
        "    print(\"‚ö†Ô∏è No detect√© ning√∫n .zip de CVAT en /content/in (debe tener 'cvat' en el nombre).\")           # Aviso\n",
        "    print(\"‚ÑπÔ∏è Cuando lo tengas, s√∫belo y vuelve a correr este bloque.\")         # Gu√≠a\n",
        "else:\n",
        "    # Limpia dataset_raw anterior para evitar mezclar versiones\n",
        "    if RAW_DIR.exists():                                                       # Revisa si ya existe dataset_raw\n",
        "        shutil.rmtree(RAW_DIR)                                                 # Borra dataset_raw anterior completo\n",
        "    RAW_DIR.mkdir(parents=True, exist_ok=True)                                 # Crea dataset_raw limpio\n",
        "\n",
        "    # Descomprime el zip de CVAT dentro de dataset_raw\n",
        "    with zipfile.ZipFile(zip_cvat, \"r\") as z:                                  # Abre el zip de CVAT\n",
        "        z.extractall(RAW_DIR)                                                  # Extrae todo su contenido en RAW_DIR\n",
        "\n",
        "    # Lista contenido para confirmar que se extrajo algo\n",
        "    extracted_any = any(RAW_DIR.rglob(\"*\"))                                     # Verifica si hay archivos extra√≠dos\n",
        "    if not extracted_any:                                                      # Si no se extrajo nada\n",
        "        print(\"‚ö†Ô∏è El zip se descomprimi√≥, pero no veo archivos dentro. Revisa si el zip est√° correcto.\")  # Aviso\n",
        "    else:\n",
        "        print(\"‚úÖ Export CVAT descomprimido en:\", RAW_DIR)                      # Confirmaci√≥n\n",
        "        # Muestra un vistazo r√°pido de archivos/carpetas extra√≠das\n",
        "        top_items = sorted(list(RAW_DIR.iterdir()))                             # Lista el primer nivel de dataset_raw\n",
        "        print(\"‚úÖ Primer nivel dentro de dataset_raw:\")                         # T√≠tulo del listado\n",
        "        for p in top_items[:30]:                                                # Muestra hasta 30 √≠tems\n",
        "            tag = \"DIR \" if p.is_dir() else \"FILE\"                              # Marca si es carpeta o archivo\n",
        "            print(\" -\", tag, p.name)                                            # Imprime nombre\n",
        "        if len(top_items) > 30:                                                 # Si hay muchos √≠tems\n",
        "            print(f\" ... y {len(top_items)-30} m√°s\")                            # Indica que hay m√°s\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SG3g9wUyvyuC",
        "outputId": "639757f6-af7f-4232-bc7a-8b75ae852a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Export CVAT descomprimido en: /content/work/dataset_raw\n",
            "‚úÖ Primer nivel dentro de dataset_raw:\n",
            " - DIR  cvat dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 9 ‚Äî Detectar (CVAT) + Normalizar YOLO + Split:} \\\n",
        "\\\\\\ \\text{Busca autom√°ticamente im√°genes y labels dentro de #dataset\\_raw, y construye el split en #/content/dataset.}$$\n"
      ],
      "metadata": {
        "id": "figIDZiWv9MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detecta im√°genes/labels en dataset_raw y construye dataset YOLO final (train/val) creando .txt vac√≠os para negativos\n",
        "import random                                                    # Sirve para mezclar antes del split\n",
        "\n",
        "img_exts = {\".jpg\", \".jpeg\", \".png\"}                             # Extensiones v√°lidas de im√°genes\n",
        "train_ratio = 0.8                                                # Proporci√≥n train/val\n",
        "seed = 42                                                        # Semilla para split repetible\n",
        "\n",
        "# Define rutas YOLO est√°ndar de salida\n",
        "IMG_TRAIN = DIR_DATASET/\"images/train\"                           # Im√°genes train\n",
        "IMG_VAL   = DIR_DATASET/\"images/val\"                             # Im√°genes val\n",
        "LBL_TRAIN = DIR_DATASET/\"labels/train\"                           # Labels train\n",
        "LBL_VAL   = DIR_DATASET/\"labels/val\"                             # Labels val\n",
        "\n",
        "# Crea carpetas de salida\n",
        "for d in [IMG_TRAIN, IMG_VAL, LBL_TRAIN, LBL_VAL]:               # Recorre carpetas YOLO\n",
        "    d.mkdir(parents=True, exist_ok=True)                         # Crea si falta\n",
        "\n",
        "# Verifica que exista dataset_raw\n",
        "if not RAW_DIR.exists():                                         # Si no existe dataset_raw\n",
        "    print(\"‚ö†Ô∏è No existe /content/work/dataset_raw todav√≠a. Corre el Bloque 8 (descomprimir CVAT) primero.\")  # Aviso\n",
        "else:\n",
        "    # Busca im√°genes y txt dentro de dataset_raw (recursivo)\n",
        "    all_imgs = [p for p in RAW_DIR.rglob(\"*\") if p.suffix.lower() in img_exts]   # Todas las im√°genes\n",
        "    all_txt  = [p for p in RAW_DIR.rglob(\"*.txt\")]                               # Todos los txt\n",
        "\n",
        "    print(\"‚úÖ Archivos encontrados dentro de dataset_raw:\")       # Resumen inicial\n",
        "    print(\" - Im√°genes:\", len(all_imgs))                         # Cantidad im√°genes\n",
        "    print(\" - TXT:\", len(all_txt))                               # Cantidad txt\n",
        "\n",
        "    # Si falta algo, avisa pero no rompe\n",
        "    if len(all_imgs) == 0:\n",
        "        print(\"‚ö†Ô∏è No encontr√© im√°genes dentro de dataset_raw. Revisa estructura del export (o tu zip).\")  # Aviso\n",
        "    if len(all_txt) == 0:\n",
        "        print(\"‚ö†Ô∏è No encontr√© labels (.txt) dentro de dataset_raw. Ojo: CVAT solo exporta txt con anotaciones.\")  # Aviso\n",
        "\n",
        "    # Detecta carpeta con m√°s im√°genes y carpeta con m√°s txt (candidatas principales)\n",
        "    img_dir = None                                               # Carpeta candidata de im√°genes\n",
        "    lbl_dir = None                                               # Carpeta candidata de labels\n",
        "\n",
        "    if len(all_imgs) > 0:                                        # Si hay im√°genes\n",
        "        counts_img_parent = {}                                   # Conteo por carpeta\n",
        "        for p in all_imgs:                                       # Recorre im√°genes\n",
        "            counts_img_parent[p.parent] = counts_img_parent.get(p.parent, 0) + 1  # Cuenta\n",
        "        img_dir = max(counts_img_parent, key=counts_img_parent.get)              # Elige mayor\n",
        "\n",
        "    if len(all_txt) > 0:                                         # Si hay txt\n",
        "        counts_lbl_parent = {}                                   # Conteo por carpeta\n",
        "        for p in all_txt:                                        # Recorre txt\n",
        "            counts_lbl_parent[p.parent] = counts_lbl_parent.get(p.parent, 0) + 1  # Cuenta\n",
        "        lbl_dir = max(counts_lbl_parent, key=counts_lbl_parent.get)              # Elige mayor\n",
        "\n",
        "    print(\"\\n‚úÖ Rutas detectadas (candidatas principales):\")      # Imprime rutas\n",
        "    print(\" - img_dir:\", str(img_dir) if img_dir else \"No detectado\")  # Carpeta im√°genes\n",
        "    print(\" - lbl_dir:\", str(lbl_dir) if lbl_dir else \"No detectado\")  # Carpeta labels\n",
        "\n",
        "    # Si no se detectaron rutas, termina sin error\n",
        "    if (img_dir is None) or (lbl_dir is None):\n",
        "        print(\"‚ö†Ô∏è No pude detectar img_dir y/o lbl_dir. Revisa qu√© hay dentro de dataset_raw (Bloque 4 listar carpetas).\")  # Aviso\n",
        "    else:\n",
        "        # Crea mapas por stem para hacer match imagen <-> label\n",
        "        img_map = {}                                             # stem -> ruta imagen\n",
        "        for p in img_dir.iterdir():                              # Recorre archivos en img_dir\n",
        "            if p.suffix.lower() in img_exts:                     # Si es imagen\n",
        "                img_map[p.stem] = p                              # Guarda\n",
        "\n",
        "        lbl_map = {}                                             # stem -> ruta label\n",
        "        for p in lbl_dir.iterdir():                              # Recorre archivos en lbl_dir\n",
        "            if p.suffix.lower() == \".txt\":                       # Si es txt\n",
        "                lbl_map[p.stem] = p                              # Guarda\n",
        "\n",
        "        # Diagn√≥stico de matching\n",
        "        all_stems = sorted(img_map.keys())                       # Todas las im√°genes (incluye negativos)\n",
        "        paired = sorted(set(img_map.keys()) & set(lbl_map.keys()))            # Con label\n",
        "        missing_lbl = sorted(set(img_map.keys()) - set(lbl_map.keys()))      # Sin label (negativos)\n",
        "        missing_img = sorted(set(lbl_map.keys()) - set(img_map.keys()))      # Txt sin imagen\n",
        "\n",
        "        print(\"\\n‚úÖ Matching imagen + label (incluyendo negativos):\")  # Reporte matching\n",
        "        print(\" - Total im√°genes:\", len(all_stems))              # Total\n",
        "        print(\" - Con label (.txt):\", len(paired))               # Con txt\n",
        "        print(\" - Sin label (se crear√° .txt vac√≠o):\", len(missing_lbl))  # Negativos\n",
        "        print(\" - Txt sin imagen (se ignoran):\", len(missing_img))       # Hu√©rfanos\n",
        "\n",
        "        # Si no hay im√°genes, no se puede construir dataset\n",
        "        if len(all_stems) == 0:\n",
        "            print(\"‚ö†Ô∏è No hay im√°genes v√°lidas para construir dataset. Revisa nombres/extensiones.\")  # Aviso\n",
        "        else:\n",
        "            # Limpia salidas anteriores\n",
        "            for d in [IMG_TRAIN, IMG_VAL, LBL_TRAIN, LBL_VAL]:   # Recorre carpetas de salida\n",
        "                for f in d.glob(\"*\"):                            # Recorre archivos dentro\n",
        "                    f.unlink()                                   # Borra\n",
        "\n",
        "            # Split train/val sobre TODAS las im√°genes\n",
        "            random.seed(seed)                                    # Semilla\n",
        "            random.shuffle(all_stems)                             # Mezcla\n",
        "            cut = int(len(all_stems) * train_ratio)              # Corte\n",
        "            train_ids = all_stems[:cut]                          # Train stems\n",
        "            val_ids = all_stems[cut:]                            # Val stems\n",
        "\n",
        "            # Copia imagen y label (o crea vac√≠o si falta)\n",
        "            def copy_img_and_label(stem, img_dst, lbl_dst):      # Funci√≥n copiar + label\n",
        "                img_src = img_map[stem]                          # Imagen fuente\n",
        "                shutil.copy2(img_src, img_dst / img_src.name)    # Copia imagen\n",
        "\n",
        "                lbl_out = lbl_dst / f\"{stem}.txt\"                # Label destino\n",
        "                if stem in lbl_map:                              # Si existe label real\n",
        "                    shutil.copy2(lbl_map[stem], lbl_out)         # Copia label\n",
        "                else:\n",
        "                    lbl_out.write_text(\"\", encoding=\"utf-8\")     # Crea label vac√≠o (negativo)\n",
        "\n",
        "            # Copia a train\n",
        "            for s in train_ids:                                  # Recorre train\n",
        "                copy_img_and_label(s, IMG_TRAIN, LBL_TRAIN)      # Copia\n",
        "\n",
        "            # Copia a val\n",
        "            for s in val_ids:                                    # Recorre val\n",
        "                copy_img_and_label(s, IMG_VAL, LBL_VAL)          # Copia\n",
        "\n",
        "            # Resumen final\n",
        "            n_train_img = len(list(IMG_TRAIN.glob(\"*\")))         # Cuenta imgs train\n",
        "            n_train_lbl = len(list(LBL_TRAIN.glob(\"*.txt\")))     # Cuenta labels train\n",
        "            n_val_img = len(list(IMG_VAL.glob(\"*\")))             # Cuenta imgs val\n",
        "            n_val_lbl = len(list(LBL_VAL.glob(\"*.txt\")))         # Cuenta labels val\n",
        "\n",
        "            print(\"\\n‚úÖ Dataset YOLO final creado en:\", DIR_DATASET)  # Confirma creaci√≥n\n",
        "            print(\" - Train: imgs =\", n_train_img, \"| lbls =\", n_train_lbl)  # Resumen train\n",
        "            print(\" - Val:   imgs =\", n_val_img,   \"| lbls =\", n_val_lbl)    # Resumen val\n",
        "\n",
        "            # Chequeo 1 txt por imagen (ideal)\n",
        "            if n_train_img != n_train_lbl:\n",
        "                print(\"‚ö†Ô∏è Ojo: TRAIN imgs != txt (deber√≠an ser iguales).\")  # Aviso\n",
        "            if n_val_img != n_val_lbl:\n",
        "                print(\"‚ö†Ô∏è Ojo: VAL imgs != txt (deber√≠an ser iguales).\")    # Aviso\n",
        "\n",
        "            # Guarda resumen para trazabilidad\n",
        "            summary_path = DIR_OUT/\"dataset_summary.txt\"         # Archivo resumen\n",
        "            summary_text = (\n",
        "                f\"total_imgs={len(all_stems)}\\n\"\n",
        "                f\"imgs_with_lbl={len(paired)}\\n\"\n",
        "                f\"imgs_without_lbl_created_empty={len(missing_lbl)}\\n\"\n",
        "                f\"txt_without_img_ignored={len(missing_img)}\\n\"\n",
        "                f\"train_ratio={train_ratio}\\n\"\n",
        "                f\"train_imgs={n_train_img}\\ntrain_lbls={n_train_lbl}\\n\"\n",
        "                f\"val_imgs={n_val_img}\\nval_lbls={n_val_lbl}\\n\"\n",
        "            )\n",
        "            summary_path.write_text(summary_text, encoding=\"utf-8\")  # Escribe resumen\n",
        "            print(\"‚úÖ Resumen guardado en:\", summary_path)        # Confirma guardado\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLR3oILLIfCr",
        "outputId": "522a2656-63b2-458a-b942-2c9b13bd20fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Archivos encontrados dentro de dataset_raw:\n",
            " - Im√°genes: 885\n",
            " - TXT: 321\n",
            "\n",
            "‚úÖ Rutas detectadas (candidatas principales):\n",
            " - img_dir: /content/work/dataset_raw/cvat dataset/images\n",
            " - lbl_dir: /content/work/dataset_raw/cvat dataset/labels\n",
            "\n",
            "‚úÖ Matching imagen + label (incluyendo negativos):\n",
            " - Total im√°genes: 885\n",
            " - Con label (.txt): 321\n",
            " - Sin label (se crear√° .txt vac√≠o): 564\n",
            " - Txt sin imagen (se ignoran): 0\n",
            "\n",
            "‚úÖ Dataset YOLO final creado en: /content/dataset\n",
            " - Train: imgs = 708 | lbls = 708\n",
            " - Val:   imgs = 177 | lbls = 177\n",
            "‚úÖ Resumen guardado en: /content/out/dataset_summary.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 11 ‚Äî Crear data.yaml (receta del dataset):} \\\n",
        "\\\\\\ \\text{Genera el archivo data.yaml que le dice a YOLO d√≥nde est√° tu dataset (train/val) y se crean manualmente las clases.}$$\n"
      ],
      "metadata": {
        "id": "ZSu_Gog4w7m9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea el archivo data.yaml para YOLO (si no hay dataset a√∫n, no falla: avisa)\n",
        "yaml_path = BASE/\"data.yaml\"                                    # Define la ruta donde se guardar√° el YAML\n",
        "\n",
        "# Define aqu√≠ tus clases EXACTAS y en el MISMO orden que usaste en CVAT - OJO DEBE HACERSE MANUAL\n",
        "classes = [\n",
        "    \"falla junta paramento izquierdo\",\n",
        "    \"falla junta paramento derecho\",\n",
        "    \"falla junta losa fondo\",\n",
        "    \"estr√≠a lado izquierdo\",\n",
        "    \"estr√≠a lado derecho\",\n",
        "    \"estr√≠a centro\",\n",
        "    \"da√±o paramento\",\n",
        "    \"da√±o losa fondo\",\n",
        "]                                                               # Lista de nombres de clases (ed√≠tala t√∫)\n",
        "\n",
        "# Verifica que existan carpetas train/val para evitar un YAML apuntando a nada\n",
        "train_dir_ok = (DIR_DATASET/\"images/train\").exists()            # Revisa si existe la carpeta de im√°genes train\n",
        "val_dir_ok = (DIR_DATASET/\"images/val\").exists()                # Revisa si existe la carpeta de im√°genes val\n",
        "\n",
        "# Si no hay estructura dataset, avisa y no rompe el notebook\n",
        "if not (train_dir_ok and val_dir_ok):                           # Si faltan carpetas b√°sicas del dataset\n",
        "    print(\"‚ö†Ô∏è No detecto la estructura de dataset en /content/dataset/images/train y /val.\")  # Aviso\n",
        "    print(\"‚ÑπÔ∏è Corre el Bloque 10 (normalizaci√≥n + split) antes de crear el data.yaml.\")       # Gu√≠a\n",
        "else:\n",
        "    # Si no definiste clases, avisa para que no entrenes con un YAML incompleto\n",
        "    if len(classes) == 0:                                       # Si la lista de clases est√° vac√≠a\n",
        "        print(\"‚ö†Ô∏è La lista 'classes' est√° vac√≠a. Agrega tus clases en el orden de CVAT antes de entrenar.\")  # Aviso\n",
        "        print(\"‚ÑπÔ∏è Igual crear√© el data.yaml, pero NO deber√≠as entrenar hasta completar 'classes'.\")          # Gu√≠a\n",
        "\n",
        "    # Construye el contenido del YAML que YOLO necesita\n",
        "    yaml_text = f\"\"\"path: {DIR_DATASET}\n",
        "train: images/train\n",
        "val: images/val\n",
        "names:\n",
        "\"\"\"                                                             # Texto base del YAML (path + rutas train/val)\n",
        "\n",
        "    # Agrega las clases con su √≠ndice (0,1,2...) en el orden correcto\n",
        "    for i, c in enumerate(classes):                              # Recorre clases con √≠ndice\n",
        "        yaml_text += f\"  {i}: {c}\\n\"                              # Agrega cada clase al YAML\n",
        "\n",
        "    # Guarda el archivo data.yaml\n",
        "    yaml_path.write_text(yaml_text, encoding=\"utf-8\")            # Escribe el YAML en disco\n",
        "\n",
        "    # Prints de confirmaci√≥n + vista r√°pida del contenido\n",
        "    print(\"‚úÖ data.yaml creado en:\", yaml_path)                   # Confirma ruta del archivo creado\n",
        "    print(\"‚úÖ Contenido de data.yaml:\")                           # T√≠tulo del contenido\n",
        "    print(yaml_text)                                              # Muestra el texto completo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxDl25huxK9B",
        "outputId": "bcff1a6d-fd54-41fa-cc1c-56ee80c3673e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ data.yaml creado en: /content/data.yaml\n",
            "‚úÖ Contenido de data.yaml:\n",
            "path: /content/dataset\n",
            "train: images/train\n",
            "val: images/val\n",
            "names:\n",
            "  0: falla junta paramento izquierdo\n",
            "  1: falla junta paramento derecho\n",
            "  2: falla junta losa fondo\n",
            "  3: estr√≠a lado izquierdo\n",
            "  4: estr√≠a lado derecho\n",
            "  5: estr√≠a centro\n",
            "  6: da√±o paramento\n",
            "  7: da√±o losa fondo\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 12 ‚Äî Entrenamiento YOLO:} \\\n",
        "\\\\\\ \\text{Entrena un modelo YOLO usando data.yaml y guarda los pesos (best.pt/last.pt) y m√©tricas dentro de #/content/runs/train.}$$\n"
      ],
      "metadata": {
        "id": "miS4L2gWxXUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloque 12 ‚Äî Entrenamiento YOLO (Modo \"Save Game\" con Auto-Descarga)\n",
        "\n",
        "from google.colab import files  # Necesario para la descarga autom√°tica\n",
        "\n",
        "# 1. Configuraci√≥n de par√°metros\n",
        "data_yaml = \"/content/data.yaml\"\n",
        "batch_size = 16\n",
        "epochs = 300\n",
        "img_size = 640\n",
        "output_dir = \"/content/runs\"\n",
        "best_pt_path = Path(\"/content/in/best.pt\") # Ruta de tu \"Partida Guardada\"\n",
        "\n",
        "# Asegurar que la carpeta /content/in existe\n",
        "best_pt_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. L√≥gica de carga de modelo (Continuar Partida o Empezar de Cero)\n",
        "if best_pt_path.exists():\n",
        "    print(f\"üéÆ 'Save Game' detectado. Cargando progreso desde: {best_pt_path}\")\n",
        "    model = YOLO(str(best_pt_path))\n",
        "    lr_inicial = 0.001 # Tasa m√°s baja para no arruinar lo ya aprendido\n",
        "else:\n",
        "    print(\"üÜï No hay partida guardada. Iniciando entrenamiento desde cero (YOLOv8n).\")\n",
        "    model = YOLO(\"yolov8n.pt\")\n",
        "    lr_inicial = 0.01\n",
        "\n",
        "# 3. Entrenamiento\n",
        "print(f\"üöÄ Iniciando entrenamiento (M√°ximo {epochs} epochs)...\")\n",
        "results = model.train(\n",
        "    data=data_yaml,\n",
        "    epochs=epochs,\n",
        "    imgsz=img_size,\n",
        "    batch=batch_size,\n",
        "    project=output_dir,\n",
        "    name=\"train_experiment\",\n",
        "    exist_ok=True,\n",
        "    lr0=lr_inicial,\n",
        "    patience=30,      # Si deja de mejorar por 30 epochs, se detiene\n",
        "    save=True,\n",
        "    pretrained=True\n",
        ")\n",
        "\n",
        "# 4. Gesti√≥n de archivos y Auto-Descarga (\"Guardado Final\")\n",
        "print(\"‚úÖ Entrenamiento finalizado.\")\n",
        "\n",
        "# Ruta donde YOLO acaba de guardar el mejor modelo de esta sesi√≥n\n",
        "new_best_path = Path(output_dir) / \"train_experiment\" / \"weights\" / \"best.pt\"\n",
        "\n",
        "if new_best_path.exists():\n",
        "    # 4a. Sobreescribir el Save Game en /content/in (Para la pr√≥xima vez que corras el bloque)\n",
        "    shutil.copy2(new_best_path, best_pt_path)\n",
        "    print(f\"‚≠ê 'Save Game' actualizado localmente en: {best_pt_path}\")\n",
        "\n",
        "    # 4b. Descargar el archivo al PC autom√°ticamente\n",
        "    try:\n",
        "        print(\"üì• Iniciando descarga del modelo 'best.pt' a tu ordenador...\")\n",
        "        files.download(str(best_pt_path))\n",
        "        print(\"‚úÖ Descarga iniciada. ¬°Guarda bien este archivo!\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è No se pudo iniciar la descarga autom√°tica: {e}\")\n",
        "        print(\"‚ÑπÔ∏è Puedes descargarlo manualmente desde la carpeta /content/in en el panel izquierdo.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Error: No se encontr√≥ el archivo generado en esta sesi√≥n.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uAa4XjvWxtr1",
        "outputId": "c43b720a-74f4-4ae4-bf2c-9197c10e7f58",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üÜï No hay partida guardada. Iniciando entrenamiento desde cero (YOLOv8n).\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov8n.pt to 'yolov8n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2MB 104.0MB/s 0.1s\n",
            "üöÄ Iniciando entrenamiento (M√°ximo 300 epochs)...\n",
            "Ultralytics 8.4.9 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=300, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train_experiment, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/train_experiment, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.Unicode.ttf to '/root/.config/Ultralytics/Arial.Unicode.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22.2MB 95.6MB/s 0.2s\n",
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752872  ultralytics.nn.modules.head.Detect           [8, 16, None, [64, 128, 256]] \n",
            "Model summary: 130 layers, 3,012,408 parameters, 3,012,392 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.3MB 122.4MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1417.0¬±504.0 MB/s, size: 34.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train... 708 images, 455 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 708/708 3.2Kit/s 0.2s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 568.7¬±367.2 MB/s, size: 35.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val... 177 images, 109 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 177/177 2.3Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/labels/val.cache\n",
            "Plotting labels to /content/runs/train_experiment/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/train_experiment\u001b[0m\n",
            "Starting training for 300 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 21.6MB/s 0.0s\n",
            "\u001b[K      1/300      2.09G      2.049      5.286      1.746          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.0it/s 15.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 1.9it/s 3.2s\n",
            "                   all        177        152    0.00392       0.41      0.135     0.0768\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/300       2.2G      1.838      4.108      1.476          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.3it/s 1.8s\n",
            "                   all        177        152       0.91     0.0472       0.31      0.176\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/300      2.22G      1.825      3.581      1.473          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.1it/s 1.9s\n",
            "                   all        177        152      0.687      0.323       0.36      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/300      2.23G      1.739      3.252      1.409          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.7it/s 12.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.1it/s 2.9s\n",
            "                   all        177        152      0.806      0.277      0.328      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/300      2.24G      1.727      2.857      1.435          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.863       0.23      0.287      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/300      2.27G      1.717      2.606       1.43          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.9it/s 1.5s\n",
            "                   all        177        152      0.914       0.33      0.556      0.274\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/300      2.29G      1.683      2.452      1.409          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.828      0.433      0.537      0.254\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/300       2.3G      1.638      2.305      1.389         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.9it/s 2.1s\n",
            "                   all        177        152      0.849      0.583      0.559      0.295\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/300      2.31G      1.647      2.155      1.409          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.4it/s 1.8s\n",
            "                   all        177        152      0.636      0.563      0.541      0.306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/300      2.34G       1.61      1.964      1.355         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.9s\n",
            "                   all        177        152      0.413      0.473      0.499      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/300      2.35G      1.555      1.802      1.368          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.777      0.477      0.541      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/300      2.37G      1.534       1.82      1.342         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.769      0.477      0.497      0.309\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/300      2.38G      1.564      1.761      1.347          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.7it/s 2.2s\n",
            "                   all        177        152      0.832      0.535      0.562      0.315\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/300      2.41G      1.584      1.815      1.377         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.7it/s 12.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.0it/s 2.0s\n",
            "                   all        177        152       0.87      0.462      0.563      0.312\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/300      2.42G      1.556      1.645      1.351          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 4.0it/s 1.5s\n",
            "                   all        177        152      0.562      0.593      0.545      0.326\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/300      2.44G      1.528       1.58      1.312          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.3it/s 1.8s\n",
            "                   all        177        152      0.697      0.488       0.53      0.313\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/300      2.45G      1.493      1.598      1.314          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.8it/s 1.6s\n",
            "                   all        177        152      0.863      0.536      0.578      0.336\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/300      2.47G      1.492      1.474      1.301          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.4it/s 2.5s\n",
            "                   all        177        152      0.808      0.565      0.565      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/300      2.49G      1.461      1.433       1.28         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.9s\n",
            "                   all        177        152      0.596      0.553      0.578      0.343\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/300      2.51G       1.43      1.414      1.299          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.7it/s 1.6s\n",
            "                   all        177        152      0.691      0.512      0.523      0.323\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/300      2.52G      1.491      1.393      1.299         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.4it/s 1.8s\n",
            "                   all        177        152      0.915      0.574      0.606      0.345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/300      2.54G      1.492      1.405      1.299          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.885      0.542      0.572      0.306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/300      2.56G      1.509      1.407      1.301         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.6it/s 2.3s\n",
            "                   all        177        152      0.654      0.628      0.576      0.339\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/300      2.57G      1.467      1.348      1.303          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.724      0.578      0.618      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/300      2.58G      1.464      1.329      1.285          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.7it/s 12.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.531      0.575      0.601      0.338\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/300      2.61G       1.42      1.285      1.243          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.9s\n",
            "                   all        177        152      0.674      0.503       0.56      0.307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/300      2.63G      1.429      1.335      1.258          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.6it/s 2.3s\n",
            "                   all        177        152       0.64       0.58      0.571       0.31\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/300      2.64G      1.387      1.288      1.241          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.734       0.56      0.585      0.324\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/300      2.65G      1.404      1.204      1.253          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.3it/s 1.8s\n",
            "                   all        177        152      0.646      0.581      0.608      0.342\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/300      2.68G      1.417       1.11      1.238          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 4.1it/s 1.5s\n",
            "                   all        177        152      0.618      0.428      0.482      0.269\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/300       2.7G      1.409      1.209       1.28         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.7it/s 1.6s\n",
            "                   all        177        152      0.622      0.602       0.63      0.352\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/300      2.71G      1.383      1.161      1.241         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.4it/s 2.6s\n",
            "                   all        177        152       0.58      0.595      0.541      0.315\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/300      2.72G      1.379      1.244      1.248          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.926      0.574      0.613       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/300      2.74G      1.398      1.116      1.225          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 2.5it/s 17.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 1.7it/s 3.6s\n",
            "                   all        177        152      0.724      0.603      0.602       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/300      2.77G      1.348      1.119      1.217          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.0it/s 15.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.8it/s 1.6s\n",
            "                   all        177        152      0.721      0.521      0.554      0.318\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/300      2.78G      1.347      1.121      1.237          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.2it/s 14.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.768      0.553      0.584      0.359\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/300      2.79G      1.364       1.09      1.231          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 2.7it/s 16.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152       0.66      0.575      0.623      0.375\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/300      2.81G      1.355       1.08      1.227         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.7it/s 1.6s\n",
            "                   all        177        152        0.9       0.55      0.584      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/300      2.83G      1.343      1.061      1.217          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.3it/s 13.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.572      0.575      0.575      0.352\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/300      2.85G      1.352      1.125      1.237          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.2it/s 13.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.8it/s 2.1s\n",
            "                   all        177        152        0.6       0.59      0.615      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/300      2.85G       1.38      1.063      1.253         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.767      0.548      0.609      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/300      2.88G      1.279     0.9873      1.193          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 4.1it/s 1.5s\n",
            "                   all        177        152       0.71      0.554      0.567      0.322\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/300       2.9G      1.307      1.016      1.209          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 4.0it/s 1.5s\n",
            "                   all        177        152      0.747      0.561      0.597      0.369\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/300      2.92G      1.327      1.042      1.213         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.2it/s 14.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.6it/s 2.3s\n",
            "                   all        177        152      0.705      0.604      0.626       0.38\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/300      2.92G      1.313     0.9915      1.214          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.8it/s 2.1s\n",
            "                   all        177        152      0.818      0.532      0.618      0.358\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/300      2.95G      1.283     0.9442      1.183         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.4it/s 1.8s\n",
            "                   all        177        152      0.779      0.584      0.625       0.35\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/300      2.97G      1.314      1.006      1.191          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.2it/s 14.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.9s\n",
            "                   all        177        152      0.637      0.581      0.625      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/300      2.99G      1.281     0.9439      1.189         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.3it/s 2.6s\n",
            "                   all        177        152       0.94      0.579      0.637      0.366\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/300      2.99G       1.29     0.9478      1.197          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.7it/s 1.6s\n",
            "                   all        177        152       0.52      0.559      0.503      0.306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/300      3.02G       1.27     0.9337      1.193          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.3it/s 1.8s\n",
            "                   all        177        152      0.761      0.568      0.577      0.359\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/300      3.04G      1.242     0.8976      1.169          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.3it/s 1.8s\n",
            "                   all        177        152      0.776      0.568      0.601      0.375\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/300      3.05G      1.246     0.9215      1.182          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.6it/s 2.3s\n",
            "                   all        177        152      0.636      0.583      0.616      0.385\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/300      3.06G      1.224     0.9294       1.17          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.859       0.59      0.605      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/300      3.09G      1.266     0.8896      1.186          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.775      0.502      0.531      0.339\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/300      3.11G      1.265     0.9155      1.185          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.9it/s 1.5s\n",
            "                   all        177        152      0.782      0.572      0.612      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/300      3.12G      1.246     0.9226       1.15          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.0it/s 2.0s\n",
            "                   all        177        152      0.753      0.532      0.591      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/300      3.13G      1.251     0.9623       1.18          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.4it/s 1.8s\n",
            "                   all        177        152      0.535      0.592      0.512      0.316\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/300      3.16G      1.189     0.8533      1.141         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.9it/s 1.5s\n",
            "                   all        177        152      0.636      0.587      0.602      0.376\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/300      3.17G      1.236     0.9026      1.179          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.3it/s 1.8s\n",
            "                   all        177        152      0.716      0.581      0.603      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/300      3.19G      1.224     0.8745      1.168          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.9s\n",
            "                   all        177        152      0.565      0.582      0.601      0.349\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/300       3.2G      1.223     0.8761      1.174         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.7it/s 12.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.3it/s 2.6s\n",
            "                   all        177        152      0.824      0.567      0.622       0.39\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/300      3.22G      1.184     0.8069      1.128          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.614      0.583      0.617      0.394\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/300      3.24G       1.23     0.8313       1.16          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.637      0.566      0.613      0.397\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/300      3.26G      1.204     0.8654      1.136          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.9it/s 1.5s\n",
            "                   all        177        152       0.56      0.657      0.685      0.411\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/300      3.27G      1.164     0.8311      1.119         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.787      0.554      0.604      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/300      3.29G      1.229     0.8564      1.164          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.4it/s 1.8s\n",
            "                   all        177        152      0.611      0.565      0.602      0.376\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/300      3.31G      1.207     0.8393      1.157          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.9it/s 1.5s\n",
            "                   all        177        152      0.969      0.534      0.555      0.376\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/300      3.33G      1.226     0.8716      1.159          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.607       0.58      0.552      0.355\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/300      3.33G      1.197     0.8691      1.172          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.8s\n",
            "                   all        177        152      0.602      0.581      0.613      0.398\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/300      3.36G      1.184     0.7987      1.135          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.4it/s 2.5s\n",
            "                   all        177        152      0.597      0.583      0.607      0.384\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/300      3.38G      1.194     0.8221      1.131          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.6s\n",
            "                   all        177        152      0.752      0.567      0.586      0.384\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/300      3.39G      1.178     0.8102      1.128          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.9it/s 1.5s\n",
            "                   all        177        152      0.642      0.576      0.608      0.377\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/300       3.4G      1.174     0.7928      1.132          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.9s\n",
            "                   all        177        152       0.64      0.591      0.631      0.395\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/300      3.43G      1.192     0.8073      1.152          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 4.1it/s 1.5s\n",
            "                   all        177        152      0.836       0.53       0.59      0.393\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/300      3.45G      1.201     0.8117      1.153          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.5it/s 2.4s\n",
            "                   all        177        152      0.609      0.576      0.609      0.401\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/300      3.46G      1.118      0.753      1.115          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.3it/s 1.8s\n",
            "                   all        177        152      0.537      0.585       0.58      0.378\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     77/300      3.47G      1.156     0.7706      1.127          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.9it/s 1.5s\n",
            "                   all        177        152      0.781      0.563       0.61      0.374\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     78/300       3.5G      1.159     0.7839      1.131          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.4it/s 1.7s\n",
            "                   all        177        152      0.576      0.561      0.589      0.376\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     79/300      3.51G      1.157     0.7932      1.117          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.3it/s 1.8s\n",
            "                   all        177        152      0.739       0.57      0.602      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     80/300      3.53G      1.127     0.7414      1.091          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.8it/s 2.1s\n",
            "                   all        177        152      0.505        0.6      0.597      0.353\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     81/300      3.54G      1.108     0.7363      1.111          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152       0.59      0.582      0.605      0.366\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     82/300      3.57G       1.15      0.767       1.12         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.688      0.558      0.565      0.348\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     83/300      3.58G      1.152     0.7916      1.121         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 2.9it/s 15.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 1.9it/s 3.2s\n",
            "                   all        177        152      0.584      0.577      0.608      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     84/300       3.6G      1.136     0.8221      1.126          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.2it/s 14.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 4.4it/s 1.4s\n",
            "                   all        177        152      0.615      0.581       0.61      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     85/300      3.61G      1.123     0.7556      1.113          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.9it/s 1.5s\n",
            "                   all        177        152      0.819      0.578      0.605      0.398\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     86/300      3.63G      1.133     0.7285      1.088          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.3it/s 13.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.4it/s 1.8s\n",
            "                   all        177        152      0.519      0.591      0.618      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     87/300      3.65G      1.137     0.7514      1.127          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.8it/s 2.2s\n",
            "                   all        177        152      0.542      0.591      0.618      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     88/300      3.67G      1.102      0.773      1.091          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.603       0.57      0.563      0.372\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     89/300      3.68G      1.175     0.8249      1.138         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.2it/s 13.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.8it/s 1.6s\n",
            "                   all        177        152      0.557      0.567      0.608      0.385\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     90/300       3.7G      1.102     0.7191       1.09          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.3it/s 13.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.9s\n",
            "                   all        177        152       0.77      0.577       0.61      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     91/300      3.72G      1.086      0.726      1.108          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.8it/s 11.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.6it/s 2.3s\n",
            "                   all        177        152      0.598      0.564      0.564       0.37\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     92/300      3.74G       1.08     0.7145      1.088          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152       0.71      0.572      0.581      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     93/300      3.74G      1.092     0.7175       1.09          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.9s\n",
            "                   all        177        152       0.76       0.64      0.632      0.393\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     94/300      3.77G      1.097     0.7231      1.104          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.7it/s 1.6s\n",
            "                   all        177        152       0.59      0.579      0.598      0.388\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 30 epochs. Best results observed at epoch 64, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=30) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "94 epochs completed in 0.418 hours.\n",
            "Optimizer stripped from /content/runs/train_experiment/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/train_experiment/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/train_experiment/weights/best.pt...\n",
            "Ultralytics 8.4.9 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 73 layers, 3,007,208 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.2it/s 2.7s\n",
            "                   all        177        152       0.56      0.656      0.685      0.411\n",
            "falla junta paramento derecho          2          2      0.249          1      0.995      0.647\n",
            "falla junta losa fondo          1          2       0.45        0.5      0.497      0.149\n",
            " estr√≠a lado izquierdo         30         60      0.964      0.967      0.992      0.652\n",
            "   estr√≠a lado derecho         22         38      0.866      0.816      0.953      0.612\n",
            "         estr√≠a centro          9         18      0.734          1      0.929      0.693\n",
            "        da√±o paramento         12         31      0.658      0.311      0.431      0.126\n",
            "       da√±o losa fondo          1          1          0          0          0          0\n",
            "Speed: 0.3ms preprocess, 2.2ms inference, 0.0ms loss, 5.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/train_experiment\u001b[0m\n",
            "‚úÖ Entrenamiento finalizado.\n",
            "‚≠ê 'Save Game' actualizado localmente en: /content/in/best.pt\n",
            "üì• Iniciando descarga del modelo 'best.pt' a tu ordenador...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aadd030f-1d59-4164-8f62-44fbb345bd0d\", \"best.pt\", 6234026)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Descarga iniciada. ¬°Guarda bien este archivo!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 13 ‚Äî Validaci√≥n visual en im√°genes (val):} \\\n",
        "\\\\\\ \\text{Usa best.pt para predecir sobre images/val y guarda im√°genes con cajas dibujadas y las descarga.}$$\n"
      ],
      "metadata": {
        "id": "nPW6lHvex422"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloque 13 ‚Äî Predicciones sobre val\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# --- 1. CONFIGURACI√ìN DE RUTAS ---\n",
        "base_path = Path(\"/content\")\n",
        "dir_dataset = base_path / \"dataset\"\n",
        "dir_runs = base_path / \"runs\"\n",
        "dir_out = base_path / \"out\"\n",
        "dir_in = base_path / \"in\"\n",
        "\n",
        "# Ruta del modelo y de las im√°genes\n",
        "best_model_path = dir_in / \"best.pt\"\n",
        "val_images_path = dir_dataset / \"images/val\"\n",
        "\n",
        "# Carpeta de salida\n",
        "pred_name = \"predict_val\"\n",
        "final_pred_dir = dir_runs / pred_name\n",
        "\n",
        "# --- 2. VALIDACI√ìN ---\n",
        "if not best_model_path.exists():\n",
        "    print(f\"‚ö†Ô∏è No se encuentra el modelo en {best_model_path}. Revisa el Bloque 12.\")\n",
        "elif not val_images_path.exists():\n",
        "    print(f\"‚ö†Ô∏è No existe la carpeta de validaci√≥n en {val_images_path}\")\n",
        "else:\n",
        "    try:\n",
        "        print(f\"üöÄ Iniciando predicci√≥n visual con l√≠neas delgadas...\")\n",
        "        model = YOLO(str(best_model_path))\n",
        "\n",
        "        # Ejecutamos la predicci√≥n con ajustes visuales\n",
        "        model.predict(\n",
        "            source=str(val_images_path),\n",
        "            save=True,\n",
        "            project=str(dir_runs),\n",
        "            name=pred_name,\n",
        "            exist_ok=True,\n",
        "            conf=0.25,         # Solo muestra lo que tenga > 25% certeza\n",
        "            iou=0.3,          # Umbral de solapamiento (ajustar si hay cajas duplicadas)\n",
        "            # --- AJUSTES PARA QUE NO SE TAPEN LAS FALLAS ---\n",
        "            line_width=3,\n",
        "            show_labels=True,  # Muestra el nombre de la falla\n",
        "            show_conf=False,   # Quitamos el % de confianza para limpiar la imagen\n",
        "            save_txt=False     # No necesitamos los .txt aqu√≠, solo las fotos\n",
        "        )\n",
        "\n",
        "        print(f\"‚úÖ Fotos guardadas en: {final_pred_dir}\")\n",
        "\n",
        "        # --- 3. CREACI√ìN DE ZIP Y DESCARGA ---\n",
        "        zip_file_path = dir_out / \"val_predictions_clean.zip\"\n",
        "        dir_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Empaquetamos solo las im√°genes resultantes\n",
        "        with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "            # Buscamos extensiones comunes de imagen\n",
        "            for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
        "                for img_file in final_pred_dir.rglob(ext):\n",
        "                    zipf.write(img_file, arcname=img_file.name)\n",
        "\n",
        "        if zip_file_path.stat().st_size > 0:\n",
        "            print(f\"üì¶ ZIP creado: {zip_file_path}\")\n",
        "            files.download(str(zip_file_path))\n",
        "            print(\"üì• Descarga iniciada.\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è El ZIP est√° vac√≠o. ¬øSeguro que hubo detecciones?\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")"
      ],
      "metadata": {
        "id": "juhQ5HwnyOiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "$$\\textbf{Modelo DAICH}$$"
      ],
      "metadata": {
        "id": "ls8UJE9ha_mj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 14 ‚Äî Motor de Procesamiento de Video:}\n",
        "\\\\\n",
        "\\ \\text{Analiza los archivos SRT y los procesa para usarlos luego}$$"
      ],
      "metadata": {
        "id": "9wLJ_wGzs5Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def procesar_telemetria_srt(ruta_srt):\n",
        "    print(f\"üìñ Leyendo archivo: {ruta_srt.name}\")\n",
        "    with open(ruta_srt, 'r', encoding='utf-8-sig', errors='ignore') as f:\n",
        "        contenido = f.read()\n",
        "\n",
        "    # Captura tiempos como \"0:00:01\" o \"00:00:01,000\"\n",
        "    patron_tiempo = r'(\\d{1,2}:\\d{1,2}:\\d{1,2}(?:[.,]\\d+)?) --> (\\d{1,2}:\\d{1,2}:\\d{1,2}(?:[.,]\\d+)?)'\n",
        "    tiempos = re.findall(patron_tiempo, contenido)\n",
        "\n",
        "    # 2. Dividimos el contenido por las marcas de tiempo para obtener los textos\n",
        "    partes = re.split(patron_tiempo, contenido)\n",
        "    # Tras el split, los textos quedan en las posiciones 3, 6, 9... (saltando los grupos de captura)\n",
        "    textos = partes[3::3]\n",
        "\n",
        "    mapeo = []\n",
        "\n",
        "    for i, (inicio, fin) in enumerate(tiempos):\n",
        "        try:\n",
        "            # Procesar el tiempo de inicio a segundos totales\n",
        "            partes_hms = inicio.replace(',', '.').split(':')\n",
        "            h = int(partes_hms[0])\n",
        "            m = int(partes_hms[1])\n",
        "            s = float(partes_hms[2])\n",
        "            seg_total = h * 3600 + m * 60 + s\n",
        "\n",
        "            # Obtener el texto del bloque actual\n",
        "            texto_bloque = textos[i] if i < len(textos) else \"\"\n",
        "\n",
        "            # Limpiar etiquetas <i> y sacar el √∫ltimo n√∫mero (el metro)\n",
        "            texto_limpio = re.sub(r'<.*?>', '', texto_bloque).strip()\n",
        "            numeros = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", texto_limpio)\n",
        "\n",
        "            if numeros:\n",
        "                # Tomamos el √∫ltimo n√∫mero porque tu SRT dice \"TRAMO 2 - Parte 2 - 1343 m\"\n",
        "                # El 1343 es el que nos interesa.\n",
        "                m_valor = float(numeros[-1])\n",
        "                mapeo.append({'s': seg_total, 'm': m_valor})\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    df_map = pd.DataFrame(mapeo)"
      ],
      "metadata": {
        "id": "K6LupneVtVVu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 15 ‚Äî Motor de Procesamiento de Video:}\n",
        "\\\\\n",
        " \\ \\text{Analiza el video, sincroniza el tiempo con el archivo SRT y ejecuta YOLO.}$$"
      ],
      "metadata": {
        "id": "neWJinplbEOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- INICIO DEL PROCESO DE INFERENCIA ---\n",
        "model = YOLO(PATHS[\"in\"] / \"best.pt\")\n",
        "video_path = next(PATHS[\"in\"].glob(\"*.mp4\"))\n",
        "df_telemetria = procesar_telemetria_srt(next(PATHS[\"in\"].glob(\"*.srt\")))\n",
        "\n",
        "if df_telemetria.empty:\n",
        "    print(\"‚ùå ABORTANDO: El archivo SRT no tiene el formato correcto.\")\n",
        "else:\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    hallazgos_crudos = []\n",
        "    f_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "        if f_count % int(fps) == 0:\n",
        "            seg_act = f_count / fps\n",
        "            m_act = np.interp(seg_act, df_telemetria['s'], df_telemetria['m'])\n",
        "            # Subir conf de 0.25 a 0.45 dependiendo de la precisi√≥n del modelo\n",
        "            preds = model.predict(frame, conf=0.25, verbose=False)\n",
        "            for r in preds:\n",
        "                if len(r.boxes) > 0:\n",
        "                    img_f = f\"evidencia_m_{m_act:.2f}.jpg\"\n",
        "                    cv2.imwrite(str(PATHS[\"frames\"] / img_f), r.plot())\n",
        "                    for b in r.boxes:\n",
        "                        hallazgos_crudos.append({\n",
        "                            'metro': m_act,\n",
        "                            'seg_video': seg_act, # <--- GUARDAMOS EL SEGUNDO\n",
        "                            'cls': model.names[int(b.cls)],\n",
        "                            'img': img_f\n",
        "                        })\n",
        "            print(f\"üîç Escaneando Metro: {m_act:.2f} | Detecciones: {len(hallazgos_crudos)}\", end=\"\\r\")\n",
        "        f_count += 1\n",
        "    cap.release()\n",
        "    df_vis = pd.DataFrame(hallazgos_crudos)\n",
        "    print(f\"\\n‚úÖ An√°lisis visual terminado. Se encontraron {len(df_vis)} registros.\")"
      ],
      "metadata": {
        "id": "TBZvMKxKbQsq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf1c43ab-b26f-4216-95cb-3cda0dc16a0f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìñ Leyendo archivo: TRAMO 1 - PARTE 2.srt\n",
            "--------------------------------------------------\n",
            "‚úÖ TELEMETR√çA CARGADA\n",
            "üìä Registros: 465\n",
            "üìç Rango: 1213.00m a 1343.00m\n",
            "--------------------------------------------------\n",
            "üîç Escaneando Metro: 1213.10 | Detecciones: 230\n",
            "‚úÖ An√°lisis visual terminado. Se encontraron 230 registros.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 16 ‚Äî Fusi√≥n T√©cnica e Interpolaci√≥n Condicional:}\n",
        "\\\n",
        "\\\\\n",
        "\\text{Cruza las detecciones visuales con los registros del robot en csv}$$"
      ],
      "metadata": {
        "id": "_0oupvkSiYC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURACI√ìN DE UMBRAL ---\n",
        "UMBRAL_DISTANCIA = 2.0\n",
        "\n",
        "def cargar_datos_robot(ruta):\n",
        "    try:\n",
        "        df = pd.read_csv(ruta, sep=';', decimal=',', encoding='latin-1')\n",
        "    except:\n",
        "        df = pd.read_csv(ruta, sep=';', decimal=',', encoding='cp1252')\n",
        "    return df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
        "\n",
        "print(\"üß† Fusionando datos con regla de proximidad estricta (+-2m)...\")\n",
        "df_l = cargar_datos_robot(PATHS[\"in\"] / \"losa.csv\")\n",
        "df_p = cargar_datos_robot(PATHS[\"in\"] / \"paramento.csv\")\n",
        "datos_finales = []\n",
        "\n",
        "for _, det in df_vis.iterrows():\n",
        "    clase_ia = det['cls'].lower()\n",
        "    # Selecci√≥n de DB seg√∫n clase\n",
        "    db, origen = (df_l, \"losa.csv\") if any(k in clase_ia for k in [\"estr√≠a\", \"losa\", \"fondo\"]) else (df_p, \"paramento.csv\")\n",
        "\n",
        "    # Encontrar el punto m√°s cercano (sin interpolar)\n",
        "    db['diff'] = (db['Metros'] - det['metro']).abs()\n",
        "    cercano = db.nsmallest(1, 'diff').iloc[0]\n",
        "    distancia_minima = cercano['diff']\n",
        "\n",
        "    res = {**det, 'csv_usado': origen}\n",
        "    cols_tecnicas = ['Extensi√≥n (cm)', 'Alto (cm)', '√Årea (m2)', 'Volumen (m3)', 'Profundidad (cm)']\n",
        "\n",
        "    # VALIDACI√ìN DE RANGO 2 METROS\n",
        "    if distancia_minima <= UMBRAL_DISTANCIA:\n",
        "        res['tiene_datos'] = True\n",
        "        for c in cols_tecnicas:\n",
        "            res[c] = cercano.get(c, 0)\n",
        "        res['Magnitud'] = cercano.get('Magnitud', 'N/A')\n",
        "    else:\n",
        "        # Si est√° fuera de rango, no vinculamos datos t√©cnicos\n",
        "        res['tiene_datos'] = False\n",
        "        for c in cols_tecnicas: res[c] = 0\n",
        "        res['Magnitud'] = \"N/A\"\n",
        "\n",
        "    datos_finales.append(res)\n",
        "\n",
        "# Filtro antiduplicados (misma clase en el mismo metro redondo)\n",
        "df_temp = pd.DataFrame(datos_finales)\n",
        "df_temp['metro_redondo'] = df_temp['metro'].round(1)\n",
        "df_reporte = df_temp.drop_duplicates(subset=['metro_redondo', 'cls'], keep='first').copy()\n",
        "\n",
        "print(f\"üìä Fusi√≥n lista. Hallazgos totales: {len(df_reporte)}\")"
      ],
      "metadata": {
        "id": "zd9K2LPjilhQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb32c55e-d424-4a2b-f94a-b5f6a8148901"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Fusionando datos con regla de proximidad estricta (+-2m)...\n",
            "üìä Fusi√≥n lista. Hallazgos totales: 115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 17 ‚Äî Generaci√≥n de Reporte y Descarga Autom√°tica:}\n",
        "\\\\\n",
        " \\ \\text{Construye el documento PDF con las evidencias capturadas y los datos t√©cnicos.}$$"
      ],
      "metadata": {
        "id": "5486ylnbjI7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìÑ Generando reporte final...\")\n",
        "pdf = FPDF()\n",
        "pdf.set_auto_page_break(auto=True, margin=15)\n",
        "\n",
        "def clean(val):\n",
        "    try:\n",
        "        f = float(val)\n",
        "        return ('%.4f' % f).rstrip('0').rstrip('.')\n",
        "    except: return str(val)\n",
        "\n",
        "for idx, f in df_reporte.iterrows():\n",
        "    pdf.add_page()\n",
        "\n",
        "    # --- T√çTULO: CLASE\n",
        "    pdf.set_font(\"Arial\", 'B', 14)\n",
        "\n",
        "    clase_nombre = f['cls'].upper()\n",
        "    # L√≥gica de g√©nero para el sufijo\n",
        "    sufijo = \"DETECTADO/A\"\n",
        "\n",
        "    # Redondeo de la cifra original a 2 decimales\n",
        "    metro_tit = f\"{round(f['metro'], 2):.2f}\"\n",
        "\n",
        "    # Construcci√≥n del t√≠tulo en may√∫sculas\n",
        "    titulo_final = f\"{clase_nombre} {sufijo} EN KM {metro_tit}\"\n",
        "    pdf.cell(200, 10, titulo_final, ln=True, align='C')\n",
        "\n",
        "    # Imagen de la IA\n",
        "    pdf.image(str(PATHS[\"frames\"]/f['img']), x=10, y=30, w=180)\n",
        "\n",
        "    # --- SUBT√çTULO: Solo Tiempo y Origen ---\n",
        "    pdf.set_y(155)\n",
        "    pdf.set_font(\"Arial\", 'B', 10)\n",
        "    pdf.set_fill_color(230, 230, 230)\n",
        "\n",
        "    m, s = divmod(int(f['seg_video']), 60)\n",
        "    info_sub = f\" TIEMPO VIDEO: {m}m {s}s | ORIGEN DATOS: {f['csv_usado']}\"\n",
        "    pdf.cell(190, 10, info_sub, ln=True, fill=True)\n",
        "\n",
        "    pdf.set_font(\"Arial\", '', 10)\n",
        "\n",
        "    if f['tiene_datos']:\n",
        "        # Fila 1: Extensi√≥n y Ancho\n",
        "        pdf.cell(95, 8, f\" Extensi√≥n: {clean(f.get('Extensi√≥n (cm)', 0))} cm\", border=1)\n",
        "        pdf.cell(95, 8, f\" Ancho: {clean(f.get('Alto (cm)', 0))} cm\", border=1, ln=True)\n",
        "\n",
        "        # Fila 2: √Årea m¬≤ y Volumen m¬≥\n",
        "        area = f.get('√Årea (m2)', f.get('Area (m2)', 0))\n",
        "        pdf.cell(95, 8, f\" √Årea: {clean(area)} m¬≤\", border=1)\n",
        "        pdf.cell(95, 8, f\" Volumen: {clean(f.get('Volumen (m3)', 0))} m¬≥\", border=1, ln=True)\n",
        "\n",
        "        # Fila 3: Profundidad y Magnitud\n",
        "        pdf.cell(95, 8, f\" Profundidad: {clean(f.get('Profundidad (cm)', 0))} cm\", border=1)\n",
        "        pdf.cell(95, 8, f\" Magnitud de da√±o: {f.get('Magnitud', 'N/A')}\", border=1, ln=True)\n",
        "    else:\n",
        "        # Nota roja\n",
        "        pdf.set_text_color(200, 0, 0)\n",
        "        pdf.set_font(\"Arial\", 'B', 10)\n",
        "        msj = \"\\nAVISO: ESTE HALLAZGO DETECTADO POR EL MODELO NO TIENE COINCIDENCIA T√âCNICA EN LA NUBE DE PUNTOS DEL ROBOT (+-2M).\"\n",
        "        pdf.multi_cell(190, 8, msj, border=1, align='C')\n",
        "        pdf.set_text_color(0, 0, 0)\n",
        "\n",
        "report_name = \"Reporte_Inspeccion_Final.pdf\"\n",
        "pdf.output(report_name)\n",
        "files.download(report_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "plOpRH11c5DI",
        "outputId": "ecb1dd37-753a-4b2b-9b22-732ccec303ce"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ Generando reporte final...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4024ea54-be0f-4d4a-9964-9d5be5fc54eb\", \"Reporte_Inspeccion_Final.pdf\", 32628601)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}