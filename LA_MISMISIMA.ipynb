{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "INDICACIONES INICIALES:\n",
        "\n",
        "- Correr en GPU\n",
        "- Las carpetas deben subirse en zip\n",
        "- Si se entrena el entorno, debe descargarse best. pt usando bloque 17, luego volver a subirlo usando bloque 3"
      ],
      "metadata": {
        "id": "nrKfcy4piTYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "$$\\textbf{Entrenamiento del modelo}$$"
      ],
      "metadata": {
        "id": "ljEWDgvkBNV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 1 ‚Äî Preparaci√≥n del entorno:}\n",
        "\\\\ \\text{Crea la estructura de carpetas del proyecto en Colab (inputs, temporales, dataset, runs y resultados) e instala librer√≠as.}$$\n"
      ],
      "metadata": {
        "id": "q3SamIJjmwHo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OTTeIyAmeIw",
        "outputId": "4fbfc93f-2fdd-41d0-9782-8dc8b679f6e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.7/1.2 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "‚úÖ Carpetas listas:\n",
            "IN: /content/in\n",
            "WORK: /content/work\n",
            "DATASET: /content/dataset\n",
            "RUNS: /content/runs\n",
            "OUT: /content/out\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "‚úÖ Ultralytics (YOLO) instalado y disponible\n"
          ]
        }
      ],
      "source": [
        "# Importa herramientas para manejar rutas, archivos, comandos y datos\n",
        "from pathlib import Path                  # Permite trabajar con rutas de carpetas/archivos de forma simple\n",
        "import shutil                             # Sirve para copiar/mover/borrar archivos y carpetas\n",
        "import zipfile                            # Sirve para descomprimir/comprimir archivos .zip\n",
        "import subprocess                         # Sirve para ejecutar comandos del sistema (ffmpeg, etc.)\n",
        "import os                                 # Utilidades del sistema (rutas, variables, etc.)\n",
        "import glob                               # Buscar archivos con patrones (ej: *.jpg)\n",
        "import re                                 # Manejo de texto con patrones (regex)\n",
        "import pandas as pd\n",
        "!pip -q install ultralytics\n",
        "from ultralytics import YOLO\n",
        "import zipfile\n",
        "\n",
        "BASE = Path(\"/content\")                   # Define la carpeta ra√≠z del entorno Colab\n",
        "DIR_IN = BASE/\"in\"                        # Carpeta para archivos que t√∫ subes (video/zip)\n",
        "DIR_WORK = BASE/\"work\"                    # Carpeta para trabajo temporal (frames, raw, etc.)\n",
        "DIR_DATASET = BASE/\"dataset\"              # Carpeta del dataset final en formato YOLO\n",
        "DIR_RUNS = BASE/\"runs\"                    # Carpeta donde YOLO guarda entrenamientos/predicciones\n",
        "DIR_OUT = BASE/\"out\"                      # Carpeta para resultados finales listos para descargar\n",
        "\n",
        "for d in [DIR_IN, DIR_WORK, DIR_DATASET, DIR_RUNS, DIR_OUT]:  # Recorre cada carpeta necesaria\n",
        "    d.mkdir(parents=True, exist_ok=True)                      # Crea la carpeta si no existe\n",
        "\n",
        "print(\"‚úÖ Carpetas listas:\")              # Muestra confirmaci√≥n\n",
        "print(\"IN:\", DIR_IN)                     # Imprime ruta de inputs\n",
        "print(\"WORK:\", DIR_WORK)                 # Imprime ruta de temporales\n",
        "print(\"DATASET:\", DIR_DATASET)           # Imprime ruta del dataset final\n",
        "print(\"RUNS:\", DIR_RUNS)                 # Imprime ruta de salidas de YOLO\n",
        "print(\"OUT:\", DIR_OUT)                   # Imprime ruta de resultados descargables\n",
        "\n",
        "# Muestra la versi√≥n de FFmpeg para verificar que est√° instalado\n",
        "!ffmpeg -version | head -n 2\n",
        "\n",
        "# Lista la GPU disponible (si hay) para confirmar aceleraci√≥n por hardware\n",
        "!nvidia-smi -L || true\n",
        "\n",
        "# Imprime confirmaci√≥n de que Ultralytics qued√≥ listo\n",
        "print(\"‚úÖ Ultralytics (YOLO) instalado y disponible\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 4 ‚Äî Exploraci√≥n y control de espacio:} \\\n",
        "\\\\\\ \\text{Te muestra qu√© hay dentro de las carpetas del proyecto  y deja listas las carpetas de trabajo para frames y dataset crudo.}$$\n"
      ],
      "metadata": {
        "id": "tqVlN1oVsqqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define una funci√≥n simple para listar contenido de una carpeta sin tirar error\n",
        "def listar_carpeta(ruta, max_items=50):                  # Crea una funci√≥n para listar archivos/carpetas\n",
        "    ruta = Path(ruta)                                    # Convierte la ruta a formato Path\n",
        "    print(\"\\nüìÅ\", ruta)                                   # Imprime la carpeta que se est√° revisando\n",
        "    if not ruta.exists():                                # Si la carpeta no existe\n",
        "        print(\"‚ö†Ô∏è No existe todav√≠a.\")                    # Avisa sin romper el notebook\n",
        "        return                                            # Termina la funci√≥n\n",
        "\n",
        "    items = sorted(list(ruta.iterdir()), key=lambda p: (p.is_file(), p.name.lower()))  # Ordena primero carpetas\n",
        "    if len(items) == 0:                                  # Si no hay nada dentro\n",
        "        print(\"‚ö†Ô∏è Est√° vac√≠a.\")                           # Avisa sin romper el notebook\n",
        "        return                                            # Termina la funci√≥n\n",
        "\n",
        "    for p in items[:max_items]:                          # Recorre hasta max_items elementos\n",
        "        tipo = \"DIR \" if p.is_dir() else \"FILE\"          # Marca si es carpeta o archivo\n",
        "        print(f\" - {tipo} {p.name}\")                     # Imprime el nombre\n",
        "\n",
        "    if len(items) > max_items:                           # Si hay m√°s de max_items\n",
        "        print(f\" ... y {len(items)-max_items} m√°s\")      # Avisa cu√°ntos faltan por mostrar\n",
        "\n",
        "# Lista las carpetas principales del proyecto para ver el estado general\n",
        "print(\"‚úÖ Listado r√°pido de carpetas del proyecto:\")      # Mensaje de inicio\n",
        "listar_carpeta(\"/content\")                               # Muestra lo que hay en /content\n",
        "listar_carpeta(DIR_IN)                                   # Muestra lo que hay en /content/in\n",
        "listar_carpeta(DIR_WORK)                                 # Muestra lo que hay en /content/work\n",
        "listar_carpeta(DIR_DATASET)                              # Muestra lo que hay en /content/dataset\n",
        "listar_carpeta(DIR_RUNS)                                 # Muestra lo que hay en /content/runs\n",
        "listar_carpeta(DIR_OUT)                                  # Muestra lo que hay en /content/out\n",
        "\n",
        "# Muestra el espacio total del disco del entorno (si el comando est√° disponible)\n",
        "print(\"\\n‚úÖ Espacio total del entorno (df -h):\")           # T√≠tulo del chequeo\n",
        "try:\n",
        "    subprocess.run([\"df\", \"-h\"], check=False)            # Ejecuta df sin romper si falla\n",
        "except Exception:\n",
        "    print(\"‚ö†Ô∏è No pude ejecutar df -h en este entorno.\")   # Aviso si no se pudo\n",
        "\n",
        "# Muestra cu√°nto pesa cada carpeta dentro de /content (para detectar qu√© est√° llenando)\n",
        "print(\"\\n‚úÖ Peso por carpeta dentro de /content (du -h):\") # T√≠tulo del chequeo\n",
        "try:\n",
        "    subprocess.run([\"bash\", \"-lc\", \"du -h --max-depth=1 /content | sort -h\"], check=False)  # Ejecuta du ordenado\n",
        "except Exception:\n",
        "    print(\"‚ö†Ô∏è No pude ejecutar du en este entorno.\")      # Aviso si no se pudo\n",
        "\n",
        "# Detecta autom√°ticamente qu√© tipo de archivo tienes en /content/in (sin tirar error si no hay nada)\n",
        "in_files = list(DIR_IN.iterdir())                               # Lee todo lo que hay dentro de /content/in\n",
        "\n",
        "# Busca un video por extensi√≥n com√∫n (si existe)\n",
        "video = next((p for p in in_files if p.suffix.lower() in [\".mp4\", \".mov\", \".avi\", \".mkv\"]), None)  # Encuentra el primer video\n",
        "\n",
        "# Busca un zip que se llame images.zip (si existe)\n",
        "zip_images = next((p for p in in_files if p.name.lower() == \"images.zip\"), None)  # Encuentra images.zip\n",
        "\n",
        "# Busca un zip que parezca export de CVAT (si existe)\n",
        "zip_cvat = next((p for p in in_files if p.suffix.lower() == \".zip\" and \"cvat\" in p.name.lower()), None)  # Encuentra zip CVAT\n",
        "\n",
        "# Define carpetas de trabajo est√°ndar (frames y dataset_raw)\n",
        "FRAMES_DIR = DIR_WORK/\"frames\"                                  # Carpeta donde se guardan frames extra√≠dos del video\n",
        "RAW_DIR = DIR_WORK/\"dataset_raw\"                                # Carpeta donde se descomprime el export de CVAT\n",
        "\n",
        "# Crea las carpetas si no existen\n",
        "FRAMES_DIR.mkdir(parents=True, exist_ok=True)                   # Crea /content/work/frames si no existe\n",
        "RAW_DIR.mkdir(parents=True, exist_ok=True)                      # Crea /content/work/dataset_raw si no existe\n",
        "\n",
        "# Imprime un resumen claro de lo que se detect√≥\n",
        "print(\"‚úÖ Detecci√≥n de inputs en /content/in:\")                  # T√≠tulo del resumen\n",
        "print(\" - Video:\", video.name if video else \"No detectado\")      # Informa si hay video\n",
        "print(\" - images.zip:\", zip_images.name if zip_images else \"No detectado\")  # Informa si hay zip de im√°genes\n",
        "print(\" - zip CVAT:\", zip_cvat.name if zip_cvat else \"No detectado\")        # Informa si hay export CVAT\n",
        "\n",
        "# Imprime rutas de trabajo listas\n",
        "print(\"\\n‚úÖ Rutas de trabajo listas:\")                           # T√≠tulo para rutas\n",
        "print(\" - FRAMES_DIR:\", FRAMES_DIR)                              # Ruta donde ir√°n los frames\n",
        "print(\" - RAW_DIR:\", RAW_DIR)                                    # Ruta donde ir√° el dataset crudo\n",
        "\n",
        "# Mensaje gu√≠a para tu siguiente decisi√≥n (sin obligarte a nada)\n",
        "print(\"\\n‚ÑπÔ∏è Pr√≥ximo paso sugerido:\")                              # Gu√≠a de flujo\n",
        "if video:\n",
        "    print(\" - Tienes video: puedes extraer frames (Bloque 6).\")   # Recomienda ruta A\n",
        "elif zip_cvat:\n",
        "    print(\" - Tienes export CVAT: puedes descomprimir y normalizar dataset (Bloques 8+).\")  # Recomienda ruta CVAT\n",
        "elif zip_images:\n",
        "    print(\" - Tienes images.zip: puedes descomprimir para etiquetar (si lo necesitas).\")    # Recomienda ruta B\n",
        "else:\n",
        "    print(\" - A√∫n no hay inputs: puedes seguir armando notebook igual y subir despu√©s.\")    # Recomienda seguir sin datos\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TuGy7isGsswg",
        "outputId": "92e6a8dd-6c77-4532-82b5-d58d50e6a61a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Listado r√°pido de carpetas del proyecto:\n",
            "\n",
            "üìÅ /content\n",
            " - DIR  .config\n",
            " - DIR  dataset\n",
            " - DIR  in\n",
            " - DIR  out\n",
            " - DIR  runs\n",
            " - DIR  sample_data\n",
            " - DIR  work\n",
            " - FILE cvat dataset.zip\n",
            "\n",
            "üìÅ /content/in\n",
            " - FILE best.pt\n",
            " - FILE cvat dataset (1).zip\n",
            "\n",
            "üìÅ /content/work\n",
            "‚ö†Ô∏è Est√° vac√≠a.\n",
            "\n",
            "üìÅ /content/dataset\n",
            "‚ö†Ô∏è Est√° vac√≠a.\n",
            "\n",
            "üìÅ /content/runs\n",
            "‚ö†Ô∏è Est√° vac√≠a.\n",
            "\n",
            "üìÅ /content/out\n",
            "‚ö†Ô∏è Est√° vac√≠a.\n",
            "\n",
            "‚úÖ Espacio total del entorno (df -h):\n",
            "\n",
            "‚úÖ Peso por carpeta dentro de /content (du -h):\n",
            "‚úÖ Detecci√≥n de inputs en /content/in:\n",
            " - Video: No detectado\n",
            " - images.zip: No detectado\n",
            " - zip CVAT: cvat dataset (1).zip\n",
            "\n",
            "‚úÖ Rutas de trabajo listas:\n",
            " - FRAMES_DIR: /content/work/frames\n",
            " - RAW_DIR: /content/work/dataset_raw\n",
            "\n",
            "‚ÑπÔ∏è Pr√≥ximo paso sugerido:\n",
            " - Tienes export CVAT: puedes descomprimir y normalizar dataset (Bloques 8+).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 8 ‚Äî Importar export de CVAT:} \\\n",
        "\\\\\\ \\text{Si hay zip de CVAT (BLOQUE 3), lo descomprime en /content #/work/dataset_raw. Si no tiene cvat revisar bloque 6.}$$\n"
      ],
      "metadata": {
        "id": "mIDh0gV0vizd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descomprime el export de CVAT (si existe) en /content/work/dataset_raw (si no existe, no falla: avisa)\n",
        "# Nota: Este zip suele llamarse algo como \"cvat_yolo_export.zip\" (el nombre puede variar)\n",
        "\n",
        "# Vuelve a buscar un zip que parezca de CVAT por si lo subiste reci√©n\n",
        "in_files = list(DIR_IN.iterdir())                                              # Lee archivos en /content/in\n",
        "zip_cvat = next((p for p in in_files if p.suffix.lower() == \".zip\" and \"cvat\" in p.name.lower()), None)  # Busca zip con \"cvat\" en el nombre\n",
        "\n",
        "# Si no encontramos zip CVAT, avisamos y seguimos sin error\n",
        "if zip_cvat is None:                                                           # Revisa si existe export de CVAT\n",
        "    print(\"‚ö†Ô∏è No detect√© ning√∫n .zip de CVAT en /content/in (debe tener 'cvat' en el nombre).\")           # Aviso\n",
        "    print(\"‚ÑπÔ∏è Cuando lo tengas, s√∫belo y vuelve a correr este bloque.\")         # Gu√≠a\n",
        "else:\n",
        "    # Limpia dataset_raw anterior para evitar mezclar versiones\n",
        "    if RAW_DIR.exists():                                                       # Revisa si ya existe dataset_raw\n",
        "        shutil.rmtree(RAW_DIR)                                                 # Borra dataset_raw anterior completo\n",
        "    RAW_DIR.mkdir(parents=True, exist_ok=True)                                 # Crea dataset_raw limpio\n",
        "\n",
        "    # Descomprime el zip de CVAT dentro de dataset_raw\n",
        "    with zipfile.ZipFile(zip_cvat, \"r\") as z:                                  # Abre el zip de CVAT\n",
        "        z.extractall(RAW_DIR)                                                  # Extrae todo su contenido en RAW_DIR\n",
        "\n",
        "    # Lista contenido para confirmar que se extrajo algo\n",
        "    extracted_any = any(RAW_DIR.rglob(\"*\"))                                     # Verifica si hay archivos extra√≠dos\n",
        "    if not extracted_any:                                                      # Si no se extrajo nada\n",
        "        print(\"‚ö†Ô∏è El zip se descomprimi√≥, pero no veo archivos dentro. Revisa si el zip est√° correcto.\")  # Aviso\n",
        "    else:\n",
        "        print(\"‚úÖ Export CVAT descomprimido en:\", RAW_DIR)                      # Confirmaci√≥n\n",
        "        # Muestra un vistazo r√°pido de archivos/carpetas extra√≠das\n",
        "        top_items = sorted(list(RAW_DIR.iterdir()))                             # Lista el primer nivel de dataset_raw\n",
        "        print(\"‚úÖ Primer nivel dentro de dataset_raw:\")                         # T√≠tulo del listado\n",
        "        for p in top_items[:30]:                                                # Muestra hasta 30 √≠tems\n",
        "            tag = \"DIR \" if p.is_dir() else \"FILE\"                              # Marca si es carpeta o archivo\n",
        "            print(\" -\", tag, p.name)                                            # Imprime nombre\n",
        "        if len(top_items) > 30:                                                 # Si hay muchos √≠tems\n",
        "            print(f\" ... y {len(top_items)-30} m√°s\")                            # Indica que hay m√°s\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SG3g9wUyvyuC",
        "outputId": "639757f6-af7f-4232-bc7a-8b75ae852a3b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Export CVAT descomprimido en: /content/work/dataset_raw\n",
            "‚úÖ Primer nivel dentro de dataset_raw:\n",
            " - DIR  cvat dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 9 ‚Äî Detectar (CVAT) + Normalizar YOLO + Split:} \\\n",
        "\\\\\\ \\text{Busca autom√°ticamente im√°genes y labels dentro de #dataset\\_raw, y construye el split en #/content/dataset.}$$\n"
      ],
      "metadata": {
        "id": "figIDZiWv9MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detecta im√°genes/labels en dataset_raw y construye dataset YOLO final (train/val) creando .txt vac√≠os para negativos\n",
        "import random                                                    # Sirve para mezclar antes del split\n",
        "\n",
        "img_exts = {\".jpg\", \".jpeg\", \".png\"}                             # Extensiones v√°lidas de im√°genes\n",
        "train_ratio = 0.8                                                # Proporci√≥n train/val\n",
        "seed = 42                                                        # Semilla para split repetible\n",
        "\n",
        "# Define rutas YOLO est√°ndar de salida\n",
        "IMG_TRAIN = DIR_DATASET/\"images/train\"                           # Im√°genes train\n",
        "IMG_VAL   = DIR_DATASET/\"images/val\"                             # Im√°genes val\n",
        "LBL_TRAIN = DIR_DATASET/\"labels/train\"                           # Labels train\n",
        "LBL_VAL   = DIR_DATASET/\"labels/val\"                             # Labels val\n",
        "\n",
        "# Crea carpetas de salida\n",
        "for d in [IMG_TRAIN, IMG_VAL, LBL_TRAIN, LBL_VAL]:               # Recorre carpetas YOLO\n",
        "    d.mkdir(parents=True, exist_ok=True)                         # Crea si falta\n",
        "\n",
        "# Verifica que exista dataset_raw\n",
        "if not RAW_DIR.exists():                                         # Si no existe dataset_raw\n",
        "    print(\"‚ö†Ô∏è No existe /content/work/dataset_raw todav√≠a. Corre el Bloque 8 (descomprimir CVAT) primero.\")  # Aviso\n",
        "else:\n",
        "    # Busca im√°genes y txt dentro de dataset_raw (recursivo)\n",
        "    all_imgs = [p for p in RAW_DIR.rglob(\"*\") if p.suffix.lower() in img_exts]   # Todas las im√°genes\n",
        "    all_txt  = [p for p in RAW_DIR.rglob(\"*.txt\")]                               # Todos los txt\n",
        "\n",
        "    print(\"‚úÖ Archivos encontrados dentro de dataset_raw:\")       # Resumen inicial\n",
        "    print(\" - Im√°genes:\", len(all_imgs))                         # Cantidad im√°genes\n",
        "    print(\" - TXT:\", len(all_txt))                               # Cantidad txt\n",
        "\n",
        "    # Si falta algo, avisa pero no rompe\n",
        "    if len(all_imgs) == 0:\n",
        "        print(\"‚ö†Ô∏è No encontr√© im√°genes dentro de dataset_raw. Revisa estructura del export (o tu zip).\")  # Aviso\n",
        "    if len(all_txt) == 0:\n",
        "        print(\"‚ö†Ô∏è No encontr√© labels (.txt) dentro de dataset_raw. Ojo: CVAT solo exporta txt con anotaciones.\")  # Aviso\n",
        "\n",
        "    # Detecta carpeta con m√°s im√°genes y carpeta con m√°s txt (candidatas principales)\n",
        "    img_dir = None                                               # Carpeta candidata de im√°genes\n",
        "    lbl_dir = None                                               # Carpeta candidata de labels\n",
        "\n",
        "    if len(all_imgs) > 0:                                        # Si hay im√°genes\n",
        "        counts_img_parent = {}                                   # Conteo por carpeta\n",
        "        for p in all_imgs:                                       # Recorre im√°genes\n",
        "            counts_img_parent[p.parent] = counts_img_parent.get(p.parent, 0) + 1  # Cuenta\n",
        "        img_dir = max(counts_img_parent, key=counts_img_parent.get)              # Elige mayor\n",
        "\n",
        "    if len(all_txt) > 0:                                         # Si hay txt\n",
        "        counts_lbl_parent = {}                                   # Conteo por carpeta\n",
        "        for p in all_txt:                                        # Recorre txt\n",
        "            counts_lbl_parent[p.parent] = counts_lbl_parent.get(p.parent, 0) + 1  # Cuenta\n",
        "        lbl_dir = max(counts_lbl_parent, key=counts_lbl_parent.get)              # Elige mayor\n",
        "\n",
        "    print(\"\\n‚úÖ Rutas detectadas (candidatas principales):\")      # Imprime rutas\n",
        "    print(\" - img_dir:\", str(img_dir) if img_dir else \"No detectado\")  # Carpeta im√°genes\n",
        "    print(\" - lbl_dir:\", str(lbl_dir) if lbl_dir else \"No detectado\")  # Carpeta labels\n",
        "\n",
        "    # Si no se detectaron rutas, termina sin error\n",
        "    if (img_dir is None) or (lbl_dir is None):\n",
        "        print(\"‚ö†Ô∏è No pude detectar img_dir y/o lbl_dir. Revisa qu√© hay dentro de dataset_raw (Bloque 4 listar carpetas).\")  # Aviso\n",
        "    else:\n",
        "        # Crea mapas por stem para hacer match imagen <-> label\n",
        "        img_map = {}                                             # stem -> ruta imagen\n",
        "        for p in img_dir.iterdir():                              # Recorre archivos en img_dir\n",
        "            if p.suffix.lower() in img_exts:                     # Si es imagen\n",
        "                img_map[p.stem] = p                              # Guarda\n",
        "\n",
        "        lbl_map = {}                                             # stem -> ruta label\n",
        "        for p in lbl_dir.iterdir():                              # Recorre archivos en lbl_dir\n",
        "            if p.suffix.lower() == \".txt\":                       # Si es txt\n",
        "                lbl_map[p.stem] = p                              # Guarda\n",
        "\n",
        "        # Diagn√≥stico de matching\n",
        "        all_stems = sorted(img_map.keys())                       # Todas las im√°genes (incluye negativos)\n",
        "        paired = sorted(set(img_map.keys()) & set(lbl_map.keys()))            # Con label\n",
        "        missing_lbl = sorted(set(img_map.keys()) - set(lbl_map.keys()))      # Sin label (negativos)\n",
        "        missing_img = sorted(set(lbl_map.keys()) - set(img_map.keys()))      # Txt sin imagen\n",
        "\n",
        "        print(\"\\n‚úÖ Matching imagen + label (incluyendo negativos):\")  # Reporte matching\n",
        "        print(\" - Total im√°genes:\", len(all_stems))              # Total\n",
        "        print(\" - Con label (.txt):\", len(paired))               # Con txt\n",
        "        print(\" - Sin label (se crear√° .txt vac√≠o):\", len(missing_lbl))  # Negativos\n",
        "        print(\" - Txt sin imagen (se ignoran):\", len(missing_img))       # Hu√©rfanos\n",
        "\n",
        "        # Si no hay im√°genes, no se puede construir dataset\n",
        "        if len(all_stems) == 0:\n",
        "            print(\"‚ö†Ô∏è No hay im√°genes v√°lidas para construir dataset. Revisa nombres/extensiones.\")  # Aviso\n",
        "        else:\n",
        "            # Limpia salidas anteriores\n",
        "            for d in [IMG_TRAIN, IMG_VAL, LBL_TRAIN, LBL_VAL]:   # Recorre carpetas de salida\n",
        "                for f in d.glob(\"*\"):                            # Recorre archivos dentro\n",
        "                    f.unlink()                                   # Borra\n",
        "\n",
        "            # Split train/val sobre TODAS las im√°genes\n",
        "            random.seed(seed)                                    # Semilla\n",
        "            random.shuffle(all_stems)                             # Mezcla\n",
        "            cut = int(len(all_stems) * train_ratio)              # Corte\n",
        "            train_ids = all_stems[:cut]                          # Train stems\n",
        "            val_ids = all_stems[cut:]                            # Val stems\n",
        "\n",
        "            # Copia imagen y label (o crea vac√≠o si falta)\n",
        "            def copy_img_and_label(stem, img_dst, lbl_dst):      # Funci√≥n copiar + label\n",
        "                img_src = img_map[stem]                          # Imagen fuente\n",
        "                shutil.copy2(img_src, img_dst / img_src.name)    # Copia imagen\n",
        "\n",
        "                lbl_out = lbl_dst / f\"{stem}.txt\"                # Label destino\n",
        "                if stem in lbl_map:                              # Si existe label real\n",
        "                    shutil.copy2(lbl_map[stem], lbl_out)         # Copia label\n",
        "                else:\n",
        "                    lbl_out.write_text(\"\", encoding=\"utf-8\")     # Crea label vac√≠o (negativo)\n",
        "\n",
        "            # Copia a train\n",
        "            for s in train_ids:                                  # Recorre train\n",
        "                copy_img_and_label(s, IMG_TRAIN, LBL_TRAIN)      # Copia\n",
        "\n",
        "            # Copia a val\n",
        "            for s in val_ids:                                    # Recorre val\n",
        "                copy_img_and_label(s, IMG_VAL, LBL_VAL)          # Copia\n",
        "\n",
        "            # Resumen final\n",
        "            n_train_img = len(list(IMG_TRAIN.glob(\"*\")))         # Cuenta imgs train\n",
        "            n_train_lbl = len(list(LBL_TRAIN.glob(\"*.txt\")))     # Cuenta labels train\n",
        "            n_val_img = len(list(IMG_VAL.glob(\"*\")))             # Cuenta imgs val\n",
        "            n_val_lbl = len(list(LBL_VAL.glob(\"*.txt\")))         # Cuenta labels val\n",
        "\n",
        "            print(\"\\n‚úÖ Dataset YOLO final creado en:\", DIR_DATASET)  # Confirma creaci√≥n\n",
        "            print(\" - Train: imgs =\", n_train_img, \"| lbls =\", n_train_lbl)  # Resumen train\n",
        "            print(\" - Val:   imgs =\", n_val_img,   \"| lbls =\", n_val_lbl)    # Resumen val\n",
        "\n",
        "            # Chequeo 1 txt por imagen (ideal)\n",
        "            if n_train_img != n_train_lbl:\n",
        "                print(\"‚ö†Ô∏è Ojo: TRAIN imgs != txt (deber√≠an ser iguales).\")  # Aviso\n",
        "            if n_val_img != n_val_lbl:\n",
        "                print(\"‚ö†Ô∏è Ojo: VAL imgs != txt (deber√≠an ser iguales).\")    # Aviso\n",
        "\n",
        "            # Guarda resumen para trazabilidad\n",
        "            summary_path = DIR_OUT/\"dataset_summary.txt\"         # Archivo resumen\n",
        "            summary_text = (\n",
        "                f\"total_imgs={len(all_stems)}\\n\"\n",
        "                f\"imgs_with_lbl={len(paired)}\\n\"\n",
        "                f\"imgs_without_lbl_created_empty={len(missing_lbl)}\\n\"\n",
        "                f\"txt_without_img_ignored={len(missing_img)}\\n\"\n",
        "                f\"train_ratio={train_ratio}\\n\"\n",
        "                f\"train_imgs={n_train_img}\\ntrain_lbls={n_train_lbl}\\n\"\n",
        "                f\"val_imgs={n_val_img}\\nval_lbls={n_val_lbl}\\n\"\n",
        "            )\n",
        "            summary_path.write_text(summary_text, encoding=\"utf-8\")  # Escribe resumen\n",
        "            print(\"‚úÖ Resumen guardado en:\", summary_path)        # Confirma guardado\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLR3oILLIfCr",
        "outputId": "522a2656-63b2-458a-b942-2c9b13bd20fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Archivos encontrados dentro de dataset_raw:\n",
            " - Im√°genes: 885\n",
            " - TXT: 321\n",
            "\n",
            "‚úÖ Rutas detectadas (candidatas principales):\n",
            " - img_dir: /content/work/dataset_raw/cvat dataset/images\n",
            " - lbl_dir: /content/work/dataset_raw/cvat dataset/labels\n",
            "\n",
            "‚úÖ Matching imagen + label (incluyendo negativos):\n",
            " - Total im√°genes: 885\n",
            " - Con label (.txt): 321\n",
            " - Sin label (se crear√° .txt vac√≠o): 564\n",
            " - Txt sin imagen (se ignoran): 0\n",
            "\n",
            "‚úÖ Dataset YOLO final creado en: /content/dataset\n",
            " - Train: imgs = 708 | lbls = 708\n",
            " - Val:   imgs = 177 | lbls = 177\n",
            "‚úÖ Resumen guardado en: /content/out/dataset_summary.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 11 ‚Äî Crear data.yaml (receta del dataset):} \\\n",
        "\\\\\\ \\text{Genera el archivo data.yaml que le dice a YOLO d√≥nde est√° tu dataset (train/val) y se crean manualmente las clases.}$$\n"
      ],
      "metadata": {
        "id": "ZSu_Gog4w7m9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea el archivo data.yaml para YOLO (si no hay dataset a√∫n, no falla: avisa)\n",
        "yaml_path = BASE/\"data.yaml\"                                    # Define la ruta donde se guardar√° el YAML\n",
        "\n",
        "# Define aqu√≠ tus clases EXACTAS y en el MISMO orden que usaste en CVAT - OJO DEBE HACERSE MANUAL\n",
        "classes = [\n",
        "    \"falla junta paramento izquierdo\",\n",
        "    \"falla junta paramento derecho\",\n",
        "    \"falla junta losa fondo\",\n",
        "    \"estr√≠a lado izquierdo\",\n",
        "    \"estr√≠a lado derecho\",\n",
        "    \"estr√≠a centro\",\n",
        "    \"da√±o paramento\",\n",
        "    \"da√±o losa fondo\",\n",
        "]                                                               # Lista de nombres de clases (ed√≠tala t√∫)\n",
        "\n",
        "# Verifica que existan carpetas train/val para evitar un YAML apuntando a nada\n",
        "train_dir_ok = (DIR_DATASET/\"images/train\").exists()            # Revisa si existe la carpeta de im√°genes train\n",
        "val_dir_ok = (DIR_DATASET/\"images/val\").exists()                # Revisa si existe la carpeta de im√°genes val\n",
        "\n",
        "# Si no hay estructura dataset, avisa y no rompe el notebook\n",
        "if not (train_dir_ok and val_dir_ok):                           # Si faltan carpetas b√°sicas del dataset\n",
        "    print(\"‚ö†Ô∏è No detecto la estructura de dataset en /content/dataset/images/train y /val.\")  # Aviso\n",
        "    print(\"‚ÑπÔ∏è Corre el Bloque 10 (normalizaci√≥n + split) antes de crear el data.yaml.\")       # Gu√≠a\n",
        "else:\n",
        "    # Si no definiste clases, avisa para que no entrenes con un YAML incompleto\n",
        "    if len(classes) == 0:                                       # Si la lista de clases est√° vac√≠a\n",
        "        print(\"‚ö†Ô∏è La lista 'classes' est√° vac√≠a. Agrega tus clases en el orden de CVAT antes de entrenar.\")  # Aviso\n",
        "        print(\"‚ÑπÔ∏è Igual crear√© el data.yaml, pero NO deber√≠as entrenar hasta completar 'classes'.\")          # Gu√≠a\n",
        "\n",
        "    # Construye el contenido del YAML que YOLO necesita\n",
        "    yaml_text = f\"\"\"path: {DIR_DATASET}\n",
        "train: images/train\n",
        "val: images/val\n",
        "names:\n",
        "\"\"\"                                                             # Texto base del YAML (path + rutas train/val)\n",
        "\n",
        "    # Agrega las clases con su √≠ndice (0,1,2...) en el orden correcto\n",
        "    for i, c in enumerate(classes):                              # Recorre clases con √≠ndice\n",
        "        yaml_text += f\"  {i}: {c}\\n\"                              # Agrega cada clase al YAML\n",
        "\n",
        "    # Guarda el archivo data.yaml\n",
        "    yaml_path.write_text(yaml_text, encoding=\"utf-8\")            # Escribe el YAML en disco\n",
        "\n",
        "    # Prints de confirmaci√≥n + vista r√°pida del contenido\n",
        "    print(\"‚úÖ data.yaml creado en:\", yaml_path)                   # Confirma ruta del archivo creado\n",
        "    print(\"‚úÖ Contenido de data.yaml:\")                           # T√≠tulo del contenido\n",
        "    print(yaml_text)                                              # Muestra el texto completo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxDl25huxK9B",
        "outputId": "bcff1a6d-fd54-41fa-cc1c-56ee80c3673e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ data.yaml creado en: /content/data.yaml\n",
            "‚úÖ Contenido de data.yaml:\n",
            "path: /content/dataset\n",
            "train: images/train\n",
            "val: images/val\n",
            "names:\n",
            "  0: falla junta paramento izquierdo\n",
            "  1: falla junta paramento derecho\n",
            "  2: falla junta losa fondo\n",
            "  3: estr√≠a lado izquierdo\n",
            "  4: estr√≠a lado derecho\n",
            "  5: estr√≠a centro\n",
            "  6: da√±o paramento\n",
            "  7: da√±o losa fondo\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 12 ‚Äî Entrenamiento YOLO:} \\\n",
        "\\\\\\ \\text{Entrena un modelo YOLO usando data.yaml y guarda los pesos (best.pt/last.pt) y m√©tricas dentro de #/content/runs/train.}$$\n"
      ],
      "metadata": {
        "id": "miS4L2gWxXUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloque 12 ‚Äî Entrenamiento YOLO (Modo \"Save Game\" con Auto-Descarga)\n",
        "\n",
        "from google.colab import files  # Necesario para la descarga autom√°tica\n",
        "\n",
        "# 1. Configuraci√≥n de par√°metros\n",
        "data_yaml = \"/content/data.yaml\"\n",
        "batch_size = 16\n",
        "epochs = 300\n",
        "img_size = 640\n",
        "output_dir = \"/content/runs\"\n",
        "best_pt_path = Path(\"/content/in/best.pt\") # Ruta de tu \"Partida Guardada\"\n",
        "\n",
        "# Asegurar que la carpeta /content/in existe\n",
        "best_pt_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. L√≥gica de carga de modelo (Continuar Partida o Empezar de Cero)\n",
        "if best_pt_path.exists():\n",
        "    print(f\"üéÆ 'Save Game' detectado. Cargando progreso desde: {best_pt_path}\")\n",
        "    model = YOLO(str(best_pt_path))\n",
        "    lr_inicial = 0.001 # Tasa m√°s baja para no arruinar lo ya aprendido\n",
        "else:\n",
        "    print(\"üÜï No hay partida guardada. Iniciando entrenamiento desde cero (YOLOv8n).\")\n",
        "    model = YOLO(\"yolov8n.pt\")\n",
        "    lr_inicial = 0.01\n",
        "\n",
        "# 3. Entrenamiento\n",
        "print(f\"üöÄ Iniciando entrenamiento (M√°ximo {epochs} epochs)...\")\n",
        "results = model.train(\n",
        "    data=data_yaml,\n",
        "    epochs=epochs,\n",
        "    imgsz=img_size,\n",
        "    batch=batch_size,\n",
        "    project=output_dir,\n",
        "    name=\"train_experiment\",\n",
        "    exist_ok=True,\n",
        "    lr0=lr_inicial,\n",
        "    patience=30,      # Si deja de mejorar por 30 epochs, se detiene\n",
        "    save=True,\n",
        "    pretrained=True\n",
        ")\n",
        "\n",
        "# 4. Gesti√≥n de archivos y Auto-Descarga (\"Guardado Final\")\n",
        "print(\"‚úÖ Entrenamiento finalizado.\")\n",
        "\n",
        "# Ruta donde YOLO acaba de guardar el mejor modelo de esta sesi√≥n\n",
        "new_best_path = Path(output_dir) / \"train_experiment\" / \"weights\" / \"best.pt\"\n",
        "\n",
        "if new_best_path.exists():\n",
        "    # 4a. Sobreescribir el Save Game en /content/in (Para la pr√≥xima vez que corras el bloque)\n",
        "    shutil.copy2(new_best_path, best_pt_path)\n",
        "    print(f\"‚≠ê 'Save Game' actualizado localmente en: {best_pt_path}\")\n",
        "\n",
        "    # 4b. Descargar el archivo al PC autom√°ticamente\n",
        "    try:\n",
        "        print(\"üì• Iniciando descarga del modelo 'best.pt' a tu ordenador...\")\n",
        "        files.download(str(best_pt_path))\n",
        "        print(\"‚úÖ Descarga iniciada. ¬°Guarda bien este archivo!\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è No se pudo iniciar la descarga autom√°tica: {e}\")\n",
        "        print(\"‚ÑπÔ∏è Puedes descargarlo manualmente desde la carpeta /content/in en el panel izquierdo.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Error: No se encontr√≥ el archivo generado en esta sesi√≥n.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uAa4XjvWxtr1",
        "outputId": "c43b720a-74f4-4ae4-bf2c-9197c10e7f58",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üÜï No hay partida guardada. Iniciando entrenamiento desde cero (YOLOv8n).\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov8n.pt to 'yolov8n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2MB 104.0MB/s 0.1s\n",
            "üöÄ Iniciando entrenamiento (M√°ximo 300 epochs)...\n",
            "Ultralytics 8.4.9 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=300, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train_experiment, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/train_experiment, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.Unicode.ttf to '/root/.config/Ultralytics/Arial.Unicode.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22.2MB 95.6MB/s 0.2s\n",
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752872  ultralytics.nn.modules.head.Detect           [8, 16, None, [64, 128, 256]] \n",
            "Model summary: 130 layers, 3,012,408 parameters, 3,012,392 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.3MB 122.4MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1417.0¬±504.0 MB/s, size: 34.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train... 708 images, 455 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 708/708 3.2Kit/s 0.2s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 568.7¬±367.2 MB/s, size: 35.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val... 177 images, 109 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 177/177 2.3Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/labels/val.cache\n",
            "Plotting labels to /content/runs/train_experiment/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/train_experiment\u001b[0m\n",
            "Starting training for 300 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 21.6MB/s 0.0s\n",
            "\u001b[K      1/300      2.09G      2.049      5.286      1.746          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.0it/s 15.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 1.9it/s 3.2s\n",
            "                   all        177        152    0.00392       0.41      0.135     0.0768\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/300       2.2G      1.838      4.108      1.476          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.3it/s 1.8s\n",
            "                   all        177        152       0.91     0.0472       0.31      0.176\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/300      2.22G      1.825      3.581      1.473          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.1it/s 1.9s\n",
            "                   all        177        152      0.687      0.323       0.36      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/300      2.23G      1.739      3.252      1.409          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.7it/s 12.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.1it/s 2.9s\n",
            "                   all        177        152      0.806      0.277      0.328      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/300      2.24G      1.727      2.857      1.435          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.863       0.23      0.287      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/300      2.27G      1.717      2.606       1.43          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.9it/s 1.5s\n",
            "                   all        177        152      0.914       0.33      0.556      0.274\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/300      2.29G      1.683      2.452      1.409          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.828      0.433      0.537      0.254\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/300       2.3G      1.638      2.305      1.389         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.9it/s 2.1s\n",
            "                   all        177        152      0.849      0.583      0.559      0.295\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/300      2.31G      1.647      2.155      1.409          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.4it/s 1.8s\n",
            "                   all        177        152      0.636      0.563      0.541      0.306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/300      2.34G       1.61      1.964      1.355         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.9s\n",
            "                   all        177        152      0.413      0.473      0.499      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/300      2.35G      1.555      1.802      1.368          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.777      0.477      0.541      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/300      2.37G      1.534       1.82      1.342         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.769      0.477      0.497      0.309\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/300      2.38G      1.564      1.761      1.347          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.7it/s 2.2s\n",
            "                   all        177        152      0.832      0.535      0.562      0.315\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/300      2.41G      1.584      1.815      1.377         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.7it/s 12.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.0it/s 2.0s\n",
            "                   all        177        152       0.87      0.462      0.563      0.312\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/300      2.42G      1.556      1.645      1.351          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 4.0it/s 1.5s\n",
            "                   all        177        152      0.562      0.593      0.545      0.326\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/300      2.44G      1.528       1.58      1.312          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.3it/s 1.8s\n",
            "                   all        177        152      0.697      0.488       0.53      0.313\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/300      2.45G      1.493      1.598      1.314          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.8it/s 1.6s\n",
            "                   all        177        152      0.863      0.536      0.578      0.336\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/300      2.47G      1.492      1.474      1.301          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.4it/s 2.5s\n",
            "                   all        177        152      0.808      0.565      0.565      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/300      2.49G      1.461      1.433       1.28         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.9s\n",
            "                   all        177        152      0.596      0.553      0.578      0.343\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/300      2.51G       1.43      1.414      1.299          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.7it/s 1.6s\n",
            "                   all        177        152      0.691      0.512      0.523      0.323\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/300      2.52G      1.491      1.393      1.299         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.4it/s 1.8s\n",
            "                   all        177        152      0.915      0.574      0.606      0.345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/300      2.54G      1.492      1.405      1.299          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.885      0.542      0.572      0.306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/300      2.56G      1.509      1.407      1.301         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.6it/s 2.3s\n",
            "                   all        177        152      0.654      0.628      0.576      0.339\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/300      2.57G      1.467      1.348      1.303          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.724      0.578      0.618      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/300      2.58G      1.464      1.329      1.285          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.7it/s 12.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.531      0.575      0.601      0.338\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/300      2.61G       1.42      1.285      1.243          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.9s\n",
            "                   all        177        152      0.674      0.503       0.56      0.307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/300      2.63G      1.429      1.335      1.258          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.6it/s 2.3s\n",
            "                   all        177        152       0.64       0.58      0.571       0.31\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/300      2.64G      1.387      1.288      1.241          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.734       0.56      0.585      0.324\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/300      2.65G      1.404      1.204      1.253          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.3it/s 1.8s\n",
            "                   all        177        152      0.646      0.581      0.608      0.342\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/300      2.68G      1.417       1.11      1.238          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 4.1it/s 1.5s\n",
            "                   all        177        152      0.618      0.428      0.482      0.269\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/300       2.7G      1.409      1.209       1.28         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.7it/s 1.6s\n",
            "                   all        177        152      0.622      0.602       0.63      0.352\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/300      2.71G      1.383      1.161      1.241         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.4it/s 2.6s\n",
            "                   all        177        152       0.58      0.595      0.541      0.315\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/300      2.72G      1.379      1.244      1.248          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.926      0.574      0.613       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/300      2.74G      1.398      1.116      1.225          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 2.5it/s 17.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 1.7it/s 3.6s\n",
            "                   all        177        152      0.724      0.603      0.602       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/300      2.77G      1.348      1.119      1.217          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.0it/s 15.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.8it/s 1.6s\n",
            "                   all        177        152      0.721      0.521      0.554      0.318\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/300      2.78G      1.347      1.121      1.237          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.2it/s 14.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.768      0.553      0.584      0.359\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/300      2.79G      1.364       1.09      1.231          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 2.7it/s 16.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152       0.66      0.575      0.623      0.375\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/300      2.81G      1.355       1.08      1.227         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.7it/s 1.6s\n",
            "                   all        177        152        0.9       0.55      0.584      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/300      2.83G      1.343      1.061      1.217          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.3it/s 13.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.572      0.575      0.575      0.352\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/300      2.85G      1.352      1.125      1.237          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.2it/s 13.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.8it/s 2.1s\n",
            "                   all        177        152        0.6       0.59      0.615      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/300      2.85G       1.38      1.063      1.253         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.767      0.548      0.609      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/300      2.88G      1.279     0.9873      1.193          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 4.1it/s 1.5s\n",
            "                   all        177        152       0.71      0.554      0.567      0.322\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/300       2.9G      1.307      1.016      1.209          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 4.0it/s 1.5s\n",
            "                   all        177        152      0.747      0.561      0.597      0.369\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/300      2.92G      1.327      1.042      1.213         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.2it/s 14.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.6it/s 2.3s\n",
            "                   all        177        152      0.705      0.604      0.626       0.38\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/300      2.92G      1.313     0.9915      1.214          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.8it/s 2.1s\n",
            "                   all        177        152      0.818      0.532      0.618      0.358\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/300      2.95G      1.283     0.9442      1.183         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.4it/s 1.8s\n",
            "                   all        177        152      0.779      0.584      0.625       0.35\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/300      2.97G      1.314      1.006      1.191          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.2it/s 14.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.9s\n",
            "                   all        177        152      0.637      0.581      0.625      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/300      2.99G      1.281     0.9439      1.189         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.3it/s 2.6s\n",
            "                   all        177        152       0.94      0.579      0.637      0.366\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/300      2.99G       1.29     0.9478      1.197          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.7it/s 1.6s\n",
            "                   all        177        152       0.52      0.559      0.503      0.306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/300      3.02G       1.27     0.9337      1.193          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.3it/s 1.8s\n",
            "                   all        177        152      0.761      0.568      0.577      0.359\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/300      3.04G      1.242     0.8976      1.169          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.3it/s 1.8s\n",
            "                   all        177        152      0.776      0.568      0.601      0.375\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/300      3.05G      1.246     0.9215      1.182          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.6it/s 2.3s\n",
            "                   all        177        152      0.636      0.583      0.616      0.385\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/300      3.06G      1.224     0.9294       1.17          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.859       0.59      0.605      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/300      3.09G      1.266     0.8896      1.186          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.775      0.502      0.531      0.339\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/300      3.11G      1.265     0.9155      1.185          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.9it/s 1.5s\n",
            "                   all        177        152      0.782      0.572      0.612      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/300      3.12G      1.246     0.9226       1.15          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.0it/s 2.0s\n",
            "                   all        177        152      0.753      0.532      0.591      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/300      3.13G      1.251     0.9623       1.18          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.4it/s 1.8s\n",
            "                   all        177        152      0.535      0.592      0.512      0.316\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/300      3.16G      1.189     0.8533      1.141         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.9it/s 1.5s\n",
            "                   all        177        152      0.636      0.587      0.602      0.376\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/300      3.17G      1.236     0.9026      1.179          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.3it/s 1.8s\n",
            "                   all        177        152      0.716      0.581      0.603      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/300      3.19G      1.224     0.8745      1.168          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.9s\n",
            "                   all        177        152      0.565      0.582      0.601      0.349\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/300       3.2G      1.223     0.8761      1.174         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.7it/s 12.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.3it/s 2.6s\n",
            "                   all        177        152      0.824      0.567      0.622       0.39\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/300      3.22G      1.184     0.8069      1.128          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152      0.614      0.583      0.617      0.394\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/300      3.24G       1.23     0.8313       1.16          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.637      0.566      0.613      0.397\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/300      3.26G      1.204     0.8654      1.136          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.9it/s 1.5s\n",
            "                   all        177        152       0.56      0.657      0.685      0.411\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/300      3.27G      1.164     0.8311      1.119         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.787      0.554      0.604      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/300      3.29G      1.229     0.8564      1.164          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.4it/s 1.8s\n",
            "                   all        177        152      0.611      0.565      0.602      0.376\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/300      3.31G      1.207     0.8393      1.157          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.9it/s 1.5s\n",
            "                   all        177        152      0.969      0.534      0.555      0.376\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/300      3.33G      1.226     0.8716      1.159          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.607       0.58      0.552      0.355\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/300      3.33G      1.197     0.8691      1.172          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.8s\n",
            "                   all        177        152      0.602      0.581      0.613      0.398\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/300      3.36G      1.184     0.7987      1.135          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.4it/s 2.5s\n",
            "                   all        177        152      0.597      0.583      0.607      0.384\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/300      3.38G      1.194     0.8221      1.131          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.6s\n",
            "                   all        177        152      0.752      0.567      0.586      0.384\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/300      3.39G      1.178     0.8102      1.128          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.9it/s 1.5s\n",
            "                   all        177        152      0.642      0.576      0.608      0.377\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/300       3.4G      1.174     0.7928      1.132          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.9s\n",
            "                   all        177        152       0.64      0.591      0.631      0.395\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/300      3.43G      1.192     0.8073      1.152          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 4.1it/s 1.5s\n",
            "                   all        177        152      0.836       0.53       0.59      0.393\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/300      3.45G      1.201     0.8117      1.153          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.5it/s 2.4s\n",
            "                   all        177        152      0.609      0.576      0.609      0.401\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/300      3.46G      1.118      0.753      1.115          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.3it/s 1.8s\n",
            "                   all        177        152      0.537      0.585       0.58      0.378\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     77/300      3.47G      1.156     0.7706      1.127          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.9it/s 1.5s\n",
            "                   all        177        152      0.781      0.563       0.61      0.374\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     78/300       3.5G      1.159     0.7839      1.131          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.4it/s 1.7s\n",
            "                   all        177        152      0.576      0.561      0.589      0.376\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     79/300      3.51G      1.157     0.7932      1.117          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.3it/s 1.8s\n",
            "                   all        177        152      0.739       0.57      0.602      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     80/300      3.53G      1.127     0.7414      1.091          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.8it/s 2.1s\n",
            "                   all        177        152      0.505        0.6      0.597      0.353\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     81/300      3.54G      1.108     0.7363      1.111          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.5it/s 1.7s\n",
            "                   all        177        152       0.59      0.582      0.605      0.366\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     82/300      3.57G       1.15      0.767       1.12         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.688      0.558      0.565      0.348\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     83/300      3.58G      1.152     0.7916      1.121         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 2.9it/s 15.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 1.9it/s 3.2s\n",
            "                   all        177        152      0.584      0.577      0.608      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     84/300       3.6G      1.136     0.8221      1.126          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.2it/s 14.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 4.4it/s 1.4s\n",
            "                   all        177        152      0.615      0.581       0.61      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     85/300      3.61G      1.123     0.7556      1.113          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.9it/s 1.5s\n",
            "                   all        177        152      0.819      0.578      0.605      0.398\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     86/300      3.63G      1.133     0.7285      1.088          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.3it/s 13.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.4it/s 1.8s\n",
            "                   all        177        152      0.519      0.591      0.618      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     87/300      3.65G      1.137     0.7514      1.127          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.6it/s 12.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.8it/s 2.2s\n",
            "                   all        177        152      0.542      0.591      0.618      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     88/300      3.67G      1.102      0.773      1.091          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 13.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152      0.603       0.57      0.563      0.372\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     89/300      3.68G      1.175     0.8249      1.138         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.2it/s 13.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.8it/s 1.6s\n",
            "                   all        177        152      0.557      0.567      0.608      0.385\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     90/300       3.7G      1.102     0.7191       1.09          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.3it/s 13.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.9s\n",
            "                   all        177        152       0.77      0.577       0.61      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     91/300      3.72G      1.086      0.726      1.108          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.8it/s 11.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.6it/s 2.3s\n",
            "                   all        177        152      0.598      0.564      0.564       0.37\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     92/300      3.74G       1.08     0.7145      1.088          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.4it/s 13.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.6it/s 1.7s\n",
            "                   all        177        152       0.71      0.572      0.581      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     93/300      3.74G      1.092     0.7175       1.09          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.2it/s 1.9s\n",
            "                   all        177        152       0.76       0.64      0.632      0.393\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     94/300      3.77G      1.097     0.7231      1.104          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 3.7it/s 1.6s\n",
            "                   all        177        152       0.59      0.579      0.598      0.388\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 30 epochs. Best results observed at epoch 64, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=30) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "94 epochs completed in 0.418 hours.\n",
            "Optimizer stripped from /content/runs/train_experiment/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/train_experiment/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/train_experiment/weights/best.pt...\n",
            "Ultralytics 8.4.9 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 73 layers, 3,007,208 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6/6 2.2it/s 2.7s\n",
            "                   all        177        152       0.56      0.656      0.685      0.411\n",
            "falla junta paramento derecho          2          2      0.249          1      0.995      0.647\n",
            "falla junta losa fondo          1          2       0.45        0.5      0.497      0.149\n",
            " estr√≠a lado izquierdo         30         60      0.964      0.967      0.992      0.652\n",
            "   estr√≠a lado derecho         22         38      0.866      0.816      0.953      0.612\n",
            "         estr√≠a centro          9         18      0.734          1      0.929      0.693\n",
            "        da√±o paramento         12         31      0.658      0.311      0.431      0.126\n",
            "       da√±o losa fondo          1          1          0          0          0          0\n",
            "Speed: 0.3ms preprocess, 2.2ms inference, 0.0ms loss, 5.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/train_experiment\u001b[0m\n",
            "‚úÖ Entrenamiento finalizado.\n",
            "‚≠ê 'Save Game' actualizado localmente en: /content/in/best.pt\n",
            "üì• Iniciando descarga del modelo 'best.pt' a tu ordenador...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aadd030f-1d59-4164-8f62-44fbb345bd0d\", \"best.pt\", 6234026)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Descarga iniciada. ¬°Guarda bien este archivo!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 13 ‚Äî Validaci√≥n visual en im√°genes (val):} \\\n",
        "\\\\\\ \\text{Usa best.pt para predecir sobre images/val y guarda im√°genes con cajas dibujadas y las descarga.}$$\n"
      ],
      "metadata": {
        "id": "nPW6lHvex422"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloque 13 ‚Äî Predicciones sobre val\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# --- 1. CONFIGURACI√ìN DE RUTAS ---\n",
        "base_path = Path(\"/content\")\n",
        "dir_dataset = base_path / \"dataset\"\n",
        "dir_runs = base_path / \"runs\"\n",
        "dir_out = base_path / \"out\"\n",
        "dir_in = base_path / \"in\"\n",
        "\n",
        "# Ruta del modelo y de las im√°genes\n",
        "best_model_path = dir_in / \"best.pt\"\n",
        "val_images_path = dir_dataset / \"images/val\"\n",
        "\n",
        "# Carpeta de salida\n",
        "pred_name = \"predict_val\"\n",
        "final_pred_dir = dir_runs / pred_name\n",
        "\n",
        "# --- 2. VALIDACI√ìN ---\n",
        "if not best_model_path.exists():\n",
        "    print(f\"‚ö†Ô∏è No se encuentra el modelo en {best_model_path}. Revisa el Bloque 12.\")\n",
        "elif not val_images_path.exists():\n",
        "    print(f\"‚ö†Ô∏è No existe la carpeta de validaci√≥n en {val_images_path}\")\n",
        "else:\n",
        "    try:\n",
        "        print(f\"üöÄ Iniciando predicci√≥n visual con l√≠neas delgadas...\")\n",
        "        model = YOLO(str(best_model_path))\n",
        "\n",
        "        # Ejecutamos la predicci√≥n con ajustes visuales\n",
        "        model.predict(\n",
        "            source=str(val_images_path),\n",
        "            save=True,\n",
        "            project=str(dir_runs),\n",
        "            name=pred_name,\n",
        "            exist_ok=True,\n",
        "            conf=0.25,         # Solo muestra lo que tenga > 25% certeza\n",
        "            iou=0.3,          # Umbral de solapamiento (ajustar si hay cajas duplicadas)\n",
        "            # --- AJUSTES PARA QUE NO SE TAPEN LAS FALLAS ---\n",
        "            line_width=3,\n",
        "            show_labels=True,  # Muestra el nombre de la falla\n",
        "            show_conf=False,   # Quitamos el % de confianza para limpiar la imagen\n",
        "            save_txt=False     # No necesitamos los .txt aqu√≠, solo las fotos\n",
        "        )\n",
        "\n",
        "        print(f\"‚úÖ Fotos guardadas en: {final_pred_dir}\")\n",
        "\n",
        "        # --- 3. CREACI√ìN DE ZIP Y DESCARGA ---\n",
        "        zip_file_path = dir_out / \"val_predictions_clean.zip\"\n",
        "        dir_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Empaquetamos solo las im√°genes resultantes\n",
        "        with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "            # Buscamos extensiones comunes de imagen\n",
        "            for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
        "                for img_file in final_pred_dir.rglob(ext):\n",
        "                    zipf.write(img_file, arcname=img_file.name)\n",
        "\n",
        "        if zip_file_path.stat().st_size > 0:\n",
        "            print(f\"üì¶ ZIP creado: {zip_file_path}\")\n",
        "            files.download(str(zip_file_path))\n",
        "            print(\"üì• Descarga iniciada.\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è El ZIP est√° vac√≠o. ¬øSeguro que hubo detecciones?\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "juhQ5HwnyOiv",
        "outputId": "017e8e96-949d-487d-9e24-cdbd59a71604"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Iniciando predicci√≥n visual con l√≠neas delgadas...\n",
            "\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.Unicode.ttf to '/root/.config/Ultralytics/Arial.Unicode.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22.2MB 147.7MB/s 0.2s\n",
            "image 1/177 /content/dataset/images/val/000004.jpg: 384x640 2 da√±o losa fondos, 308.6ms\n",
            "image 2/177 /content/dataset/images/val/000007.jpg: 384x640 (no detections), 154.0ms\n",
            "image 3/177 /content/dataset/images/val/000012.jpg: 384x640 (no detections), 128.6ms\n",
            "image 4/177 /content/dataset/images/val/000026.jpg: 384x640 2 estr√≠a centros, 127.1ms\n",
            "image 5/177 /content/dataset/images/val/000028.jpg: 384x640 2 estr√≠a centros, 131.7ms\n",
            "image 6/177 /content/dataset/images/val/000031.jpg: 384x640 2 estr√≠a centros, 125.9ms\n",
            "image 7/177 /content/dataset/images/val/000033.jpg: 384x640 2 estr√≠a centros, 133.5ms\n",
            "image 8/177 /content/dataset/images/val/000045.jpg: 384x640 2 estr√≠a lado derechos, 144.2ms\n",
            "image 9/177 /content/dataset/images/val/000047.jpg: 384x640 2 estr√≠a lado derechos, 134.3ms\n",
            "image 10/177 /content/dataset/images/val/000049.jpg: 384x640 2 estr√≠a lado derechos, 130.2ms\n",
            "image 11/177 /content/dataset/images/val/000058.jpg: 384x640 2 estr√≠a lado derechos, 128.3ms\n",
            "image 12/177 /content/dataset/images/val/000066.jpg: 384x640 (no detections), 130.5ms\n",
            "image 13/177 /content/dataset/images/val/000068.jpg: 384x640 (no detections), 129.2ms\n",
            "image 14/177 /content/dataset/images/val/000072.jpg: 384x640 (no detections), 142.0ms\n",
            "image 15/177 /content/dataset/images/val/000074.jpg: 384x640 (no detections), 131.0ms\n",
            "image 16/177 /content/dataset/images/val/000081.jpg: 384x640 (no detections), 133.4ms\n",
            "image 17/177 /content/dataset/images/val/000082.jpg: 384x640 (no detections), 125.7ms\n",
            "image 18/177 /content/dataset/images/val/000090.jpg: 384x640 2 estr√≠a centros, 125.2ms\n",
            "image 19/177 /content/dataset/images/val/000094.jpg: 384x640 2 estr√≠a centros, 127.0ms\n",
            "image 20/177 /content/dataset/images/val/000095.jpg: 384x640 2 estr√≠a centros, 142.2ms\n",
            "image 21/177 /content/dataset/images/val/000096.jpg: 384x640 2 estr√≠a centros, 126.1ms\n",
            "image 22/177 /content/dataset/images/val/000100.jpg: 384x640 2 estr√≠a centros, 130.1ms\n",
            "image 23/177 /content/dataset/images/val/000104.jpg: 384x640 2 estr√≠a centros, 127.5ms\n",
            "image 24/177 /content/dataset/images/val/000105.jpg: 384x640 1 estr√≠a lado izquierdo, 2 estr√≠a centros, 127.2ms\n",
            "image 25/177 /content/dataset/images/val/000113.jpg: 384x640 2 estr√≠a lado izquierdos, 129.0ms\n",
            "image 26/177 /content/dataset/images/val/000115.jpg: 384x640 2 estr√≠a lado izquierdos, 135.4ms\n",
            "image 27/177 /content/dataset/images/val/000118.jpg: 384x640 2 estr√≠a lado izquierdos, 124.9ms\n",
            "image 28/177 /content/dataset/images/val/000128.jpg: 384x640 2 estr√≠a lado izquierdos, 125.8ms\n",
            "image 29/177 /content/dataset/images/val/000142.jpg: 384x640 (no detections), 126.7ms\n",
            "image 30/177 /content/dataset/images/val/000143.jpg: 384x640 (no detections), 125.3ms\n",
            "image 31/177 /content/dataset/images/val/000147.jpg: 384x640 (no detections), 127.8ms\n",
            "image 32/177 /content/dataset/images/val/000157.jpg: 384x640 (no detections), 125.4ms\n",
            "image 33/177 /content/dataset/images/val/000160.jpg: 384x640 (no detections), 141.0ms\n",
            "image 34/177 /content/dataset/images/val/000162.jpg: 384x640 (no detections), 153.5ms\n",
            "image 35/177 /content/dataset/images/val/000164.jpg: 384x640 (no detections), 126.1ms\n",
            "image 36/177 /content/dataset/images/val/000167.jpg: 384x640 (no detections), 130.5ms\n",
            "image 37/177 /content/dataset/images/val/000168.jpg: 384x640 (no detections), 123.6ms\n",
            "image 38/177 /content/dataset/images/val/000176.jpg: 384x640 (no detections), 124.1ms\n",
            "image 39/177 /content/dataset/images/val/000197.jpg: 384x640 (no detections), 146.2ms\n",
            "image 40/177 /content/dataset/images/val/000204.jpg: 384x640 (no detections), 199.7ms\n",
            "image 41/177 /content/dataset/images/val/000215.jpg: 384x640 (no detections), 198.8ms\n",
            "image 42/177 /content/dataset/images/val/000217.jpg: 384x640 (no detections), 190.4ms\n",
            "image 43/177 /content/dataset/images/val/000218.jpg: 384x640 (no detections), 195.4ms\n",
            "image 44/177 /content/dataset/images/val/000221.jpg: 384x640 (no detections), 209.9ms\n",
            "image 45/177 /content/dataset/images/val/000224.jpg: 384x640 (no detections), 193.3ms\n",
            "image 46/177 /content/dataset/images/val/000225.jpg: 384x640 (no detections), 193.2ms\n",
            "image 47/177 /content/dataset/images/val/000226.jpg: 384x640 (no detections), 192.9ms\n",
            "image 48/177 /content/dataset/images/val/000229.jpg: 384x640 (no detections), 216.3ms\n",
            "image 49/177 /content/dataset/images/val/000234.jpg: 384x640 (no detections), 211.4ms\n",
            "image 50/177 /content/dataset/images/val/000235.jpg: 384x640 (no detections), 205.8ms\n",
            "image 51/177 /content/dataset/images/val/000239.jpg: 384x640 (no detections), 168.9ms\n",
            "image 52/177 /content/dataset/images/val/000251.jpg: 384x640 1 falla junta paramento derecho, 2 estr√≠a lado izquierdos, 138.8ms\n",
            "image 53/177 /content/dataset/images/val/000253.jpg: 384x640 2 estr√≠a lado izquierdos, 130.9ms\n",
            "image 54/177 /content/dataset/images/val/000258.jpg: 384x640 2 estr√≠a lado izquierdos, 126.4ms\n",
            "image 55/177 /content/dataset/images/val/000270.jpg: 384x640 2 estr√≠a lado izquierdos, 2 da√±o paramentos, 129.0ms\n",
            "image 56/177 /content/dataset/images/val/000271.jpg: 384x640 2 estr√≠a lado izquierdos, 2 da√±o paramentos, 128.0ms\n",
            "image 57/177 /content/dataset/images/val/000272.jpg: 384x640 2 estr√≠a lado izquierdos, 2 da√±o paramentos, 128.7ms\n",
            "image 58/177 /content/dataset/images/val/000274.jpg: 384x640 2 estr√≠a lado izquierdos, 2 da√±o paramentos, 129.2ms\n",
            "image 59/177 /content/dataset/images/val/000275.jpg: 384x640 2 estr√≠a lado izquierdos, 2 da√±o paramentos, 133.6ms\n",
            "image 60/177 /content/dataset/images/val/000277.jpg: 384x640 2 estr√≠a lado izquierdos, 130.1ms\n",
            "image 61/177 /content/dataset/images/val/000282.jpg: 384x640 2 estr√≠a lado izquierdos, 128.3ms\n",
            "image 62/177 /content/dataset/images/val/000285.jpg: 384x640 2 estr√≠a lado izquierdos, 128.3ms\n",
            "image 63/177 /content/dataset/images/val/000297.jpg: 384x640 (no detections), 124.4ms\n",
            "image 64/177 /content/dataset/images/val/000301.jpg: 384x640 1 falla junta paramento derecho, 127.3ms\n",
            "image 65/177 /content/dataset/images/val/000323.jpg: 384x640 (no detections), 138.5ms\n",
            "image 66/177 /content/dataset/images/val/000324.jpg: 384x640 (no detections), 143.1ms\n",
            "image 67/177 /content/dataset/images/val/000333.jpg: 384x640 (no detections), 126.0ms\n",
            "image 68/177 /content/dataset/images/val/000345.jpg: 384x640 (no detections), 128.4ms\n",
            "image 69/177 /content/dataset/images/val/000349.jpg: 384x640 1 estr√≠a lado izquierdo, 130.1ms\n",
            "image 70/177 /content/dataset/images/val/000353.jpg: 384x640 (no detections), 127.7ms\n",
            "image 71/177 /content/dataset/images/val/000364.jpg: 384x640 (no detections), 130.7ms\n",
            "image 72/177 /content/dataset/images/val/000368.jpg: 384x640 (no detections), 146.3ms\n",
            "image 73/177 /content/dataset/images/val/000371.jpg: 384x640 (no detections), 125.1ms\n",
            "image 74/177 /content/dataset/images/val/000374.jpg: 384x640 (no detections), 127.5ms\n",
            "image 75/177 /content/dataset/images/val/000380.jpg: 384x640 (no detections), 128.6ms\n",
            "image 76/177 /content/dataset/images/val/000388.jpg: 384x640 (no detections), 131.8ms\n",
            "image 77/177 /content/dataset/images/val/000389.jpg: 384x640 (no detections), 130.9ms\n",
            "image 78/177 /content/dataset/images/val/000390.jpg: 384x640 (no detections), 125.8ms\n",
            "image 79/177 /content/dataset/images/val/000391.jpg: 384x640 (no detections), 133.0ms\n",
            "image 80/177 /content/dataset/images/val/000395.jpg: 384x640 (no detections), 125.3ms\n",
            "image 81/177 /content/dataset/images/val/000406.jpg: 384x640 2 estr√≠a lado derechos, 129.2ms\n",
            "image 82/177 /content/dataset/images/val/000409.jpg: 384x640 (no detections), 132.9ms\n",
            "image 83/177 /content/dataset/images/val/000411.jpg: 384x640 (no detections), 130.8ms\n",
            "image 84/177 /content/dataset/images/val/000430.jpg: 384x640 (no detections), 125.7ms\n",
            "image 85/177 /content/dataset/images/val/000433.jpg: 384x640 (no detections), 142.1ms\n",
            "image 86/177 /content/dataset/images/val/000439.jpg: 384x640 2 estr√≠a lado derechos, 127.0ms\n",
            "image 87/177 /content/dataset/images/val/000446.jpg: 384x640 1 estr√≠a lado derecho, 129.3ms\n",
            "image 88/177 /content/dataset/images/val/000460.jpg: 384x640 (no detections), 127.9ms\n",
            "image 89/177 /content/dataset/images/val/000465.jpg: 384x640 (no detections), 130.2ms\n",
            "image 90/177 /content/dataset/images/val/000470.jpg: 384x640 1 estr√≠a lado derecho, 129.1ms\n",
            "image 91/177 /content/dataset/images/val/000471.jpg: 384x640 (no detections), 135.5ms\n",
            "image 92/177 /content/dataset/images/val/000474.jpg: 384x640 1 estr√≠a lado derecho, 125.4ms\n",
            "image 93/177 /content/dataset/images/val/000480.jpg: 384x640 2 estr√≠a lado derechos, 128.9ms\n",
            "image 94/177 /content/dataset/images/val/000506.jpg: 384x640 (no detections), 133.4ms\n",
            "image 95/177 /content/dataset/images/val/000512.jpg: 384x640 (no detections), 129.9ms\n",
            "image 96/177 /content/dataset/images/val/000518.jpg: 384x640 (no detections), 130.9ms\n",
            "image 97/177 /content/dataset/images/val/000522.jpg: 384x640 (no detections), 126.4ms\n",
            "image 98/177 /content/dataset/images/val/000542.jpg: 384x640 1 falla junta paramento derecho, 138.8ms\n",
            "image 99/177 /content/dataset/images/val/000547.jpg: 384x640 1 falla junta paramento derecho, 130.1ms\n",
            "image 100/177 /content/dataset/images/val/000550.jpg: 384x640 (no detections), 127.9ms\n",
            "image 101/177 /content/dataset/images/val/000552.jpg: 384x640 (no detections), 127.9ms\n",
            "image 102/177 /content/dataset/images/val/000559.jpg: 384x640 (no detections), 129.2ms\n",
            "image 103/177 /content/dataset/images/val/000566.jpg: 384x640 (no detections), 124.3ms\n",
            "image 104/177 /content/dataset/images/val/000567.jpg: 384x640 (no detections), 140.3ms\n",
            "image 105/177 /content/dataset/images/val/000571.jpg: 384x640 (no detections), 129.6ms\n",
            "image 106/177 /content/dataset/images/val/000575.jpg: 384x640 1 estr√≠a lado derecho, 127.0ms\n",
            "image 107/177 /content/dataset/images/val/000581.jpg: 384x640 1 estr√≠a lado derecho, 128.3ms\n",
            "image 108/177 /content/dataset/images/val/000592.jpg: 384x640 (no detections), 130.0ms\n",
            "image 109/177 /content/dataset/images/val/000598.jpg: 384x640 (no detections), 125.9ms\n",
            "image 110/177 /content/dataset/images/val/000599.jpg: 384x640 (no detections), 127.7ms\n",
            "image 111/177 /content/dataset/images/val/000604.jpg: 384x640 (no detections), 135.6ms\n",
            "image 112/177 /content/dataset/images/val/000605.jpg: 384x640 (no detections), 168.7ms\n",
            "image 113/177 /content/dataset/images/val/000611.jpg: 384x640 (no detections), 199.6ms\n",
            "image 114/177 /content/dataset/images/val/000617.jpg: 384x640 (no detections), 204.4ms\n",
            "image 115/177 /content/dataset/images/val/000619.jpg: 384x640 (no detections), 207.7ms\n",
            "image 116/177 /content/dataset/images/val/000624.jpg: 384x640 (no detections), 202.9ms\n",
            "image 117/177 /content/dataset/images/val/000634.jpg: 384x640 (no detections), 200.1ms\n",
            "image 118/177 /content/dataset/images/val/000643.jpg: 384x640 (no detections), 194.2ms\n",
            "image 119/177 /content/dataset/images/val/000644.jpg: 384x640 (no detections), 194.6ms\n",
            "image 120/177 /content/dataset/images/val/000651.jpg: 384x640 2 estr√≠a lado izquierdos, 214.0ms\n",
            "image 121/177 /content/dataset/images/val/000655.jpg: 384x640 2 estr√≠a lado izquierdos, 198.3ms\n",
            "image 122/177 /content/dataset/images/val/000656.jpg: 384x640 2 estr√≠a lado izquierdos, 208.1ms\n",
            "image 123/177 /content/dataset/images/val/000657.jpg: 384x640 2 estr√≠a lado izquierdos, 198.0ms\n",
            "image 124/177 /content/dataset/images/val/000659.jpg: 384x640 2 estr√≠a lado izquierdos, 151.5ms\n",
            "image 125/177 /content/dataset/images/val/000664.jpg: 384x640 2 estr√≠a lado izquierdos, 129.0ms\n",
            "image 126/177 /content/dataset/images/val/000666.jpg: 384x640 2 estr√≠a lado izquierdos, 126.5ms\n",
            "image 127/177 /content/dataset/images/val/000672.jpg: 384x640 2 estr√≠a lado izquierdos, 127.2ms\n",
            "image 128/177 /content/dataset/images/val/000678.jpg: 384x640 (no detections), 125.9ms\n",
            "image 129/177 /content/dataset/images/val/000687.jpg: 384x640 (no detections), 126.5ms\n",
            "image 130/177 /content/dataset/images/val/000693.jpg: 384x640 (no detections), 130.7ms\n",
            "image 131/177 /content/dataset/images/val/000697.jpg: 384x640 (no detections), 136.4ms\n",
            "image 132/177 /content/dataset/images/val/000699.jpg: 384x640 (no detections), 127.6ms\n",
            "image 133/177 /content/dataset/images/val/000700.jpg: 384x640 (no detections), 129.0ms\n",
            "image 134/177 /content/dataset/images/val/000702.jpg: 384x640 (no detections), 127.3ms\n",
            "image 135/177 /content/dataset/images/val/000705.jpg: 384x640 (no detections), 124.5ms\n",
            "image 136/177 /content/dataset/images/val/000715.jpg: 384x640 (no detections), 130.5ms\n",
            "image 137/177 /content/dataset/images/val/000719.jpg: 384x640 (no detections), 139.0ms\n",
            "image 138/177 /content/dataset/images/val/000722.jpg: 384x640 (no detections), 131.1ms\n",
            "image 139/177 /content/dataset/images/val/000732.jpg: 384x640 (no detections), 127.4ms\n",
            "image 140/177 /content/dataset/images/val/000734.jpg: 384x640 (no detections), 126.6ms\n",
            "image 141/177 /content/dataset/images/val/000736.jpg: 384x640 1 da√±o losa fondo, 126.8ms\n",
            "image 142/177 /content/dataset/images/val/000747.jpg: 384x640 (no detections), 132.4ms\n",
            "image 143/177 /content/dataset/images/val/000748.jpg: 384x640 (no detections), 129.2ms\n",
            "image 144/177 /content/dataset/images/val/000750.jpg: 384x640 (no detections), 134.5ms\n",
            "image 145/177 /content/dataset/images/val/000755.jpg: 384x640 (no detections), 130.2ms\n",
            "image 146/177 /content/dataset/images/val/000759.jpg: 384x640 (no detections), 129.4ms\n",
            "image 147/177 /content/dataset/images/val/000760.jpg: 384x640 (no detections), 141.4ms\n",
            "image 148/177 /content/dataset/images/val/000776.jpg: 384x640 (no detections), 133.3ms\n",
            "image 149/177 /content/dataset/images/val/000778.jpg: 384x640 (no detections), 126.7ms\n",
            "image 150/177 /content/dataset/images/val/000782.jpg: 384x640 (no detections), 146.7ms\n",
            "image 151/177 /content/dataset/images/val/000792.jpg: 384x640 (no detections), 128.0ms\n",
            "image 152/177 /content/dataset/images/val/000794.jpg: 384x640 (no detections), 129.5ms\n",
            "image 153/177 /content/dataset/images/val/000801.jpg: 384x640 (no detections), 130.5ms\n",
            "image 154/177 /content/dataset/images/val/000802.jpg: 384x640 (no detections), 127.9ms\n",
            "image 155/177 /content/dataset/images/val/000817.jpg: 384x640 (no detections), 129.5ms\n",
            "image 156/177 /content/dataset/images/val/000820.jpg: 384x640 (no detections), 147.3ms\n",
            "image 157/177 /content/dataset/images/val/000825.jpg: 384x640 (no detections), 132.4ms\n",
            "image 158/177 /content/dataset/images/val/000826.jpg: 384x640 (no detections), 129.5ms\n",
            "image 159/177 /content/dataset/images/val/000827.jpg: 384x640 (no detections), 126.2ms\n",
            "image 160/177 /content/dataset/images/val/000829.jpg: 384x640 (no detections), 125.6ms\n",
            "image 161/177 /content/dataset/images/val/000835.jpg: 384x640 2 estr√≠a lado izquierdos, 126.5ms\n",
            "image 162/177 /content/dataset/images/val/000842.jpg: 384x640 2 estr√≠a lado izquierdos, 128.7ms\n",
            "image 163/177 /content/dataset/images/val/000843.jpg: 384x640 2 estr√≠a lado izquierdos, 141.1ms\n",
            "image 164/177 /content/dataset/images/val/000844.jpg: 384x640 2 estr√≠a lado izquierdos, 128.9ms\n",
            "image 165/177 /content/dataset/images/val/000846.jpg: 384x640 2 estr√≠a lado izquierdos, 126.3ms\n",
            "image 166/177 /content/dataset/images/val/000851.jpg: 384x640 1 falla junta paramento derecho, 129.0ms\n",
            "image 167/177 /content/dataset/images/val/000857.jpg: 384x640 1 estr√≠a lado izquierdo, 131.3ms\n",
            "image 168/177 /content/dataset/images/val/000859.jpg: 384x640 (no detections), 133.9ms\n",
            "image 169/177 /content/dataset/images/val/000861.jpg: 384x640 (no detections), 145.5ms\n",
            "image 170/177 /content/dataset/images/val/000865.jpg: 384x640 1 estr√≠a lado derecho, 133.3ms\n",
            "image 171/177 /content/dataset/images/val/000869.jpg: 384x640 2 estr√≠a lado derechos, 126.7ms\n",
            "image 172/177 /content/dataset/images/val/000870.jpg: 384x640 2 estr√≠a lado derechos, 132.6ms\n",
            "image 173/177 /content/dataset/images/val/000873.jpg: 384x640 2 estr√≠a lado derechos, 125.7ms\n",
            "image 174/177 /content/dataset/images/val/000876.jpg: 384x640 2 estr√≠a lado derechos, 131.2ms\n",
            "image 175/177 /content/dataset/images/val/000878.jpg: 384x640 2 estr√≠a lado derechos, 147.4ms\n",
            "image 176/177 /content/dataset/images/val/000880.jpg: 384x640 2 estr√≠a lado derechos, 134.5ms\n",
            "image 177/177 /content/dataset/images/val/000884.jpg: 384x640 2 estr√≠a lado derechos, 128.3ms\n",
            "Speed: 3.1ms preprocess, 141.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/runs/predict_val\u001b[0m\n",
            "‚úÖ Fotos guardadas en: /content/runs/predict_val\n",
            "üì¶ ZIP creado: /content/out/val_predictions_clean.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cb8638e1-a7c4-4389-a818-bf2b8734b0a2\", \"val_predictions_clean.zip\", 14378241)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Descarga iniciada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "$$\\textbf{Modelo DAICH}$$"
      ],
      "metadata": {
        "id": "l4RsxO8_BmlU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 14 ‚Äî Predicci√≥n en VIDEO (salida anotada + labels):} \\\n",
        "\\\\\\ \\text{Usa best.pt para predecir sobre un video y guarda: (1) video anotado y (2) archivos .txt por frame con detecciones (para luego armar CSVs).}$$\n"
      ],
      "metadata": {
        "id": "QYfLnicVyVd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Corre predicci√≥n sobre un video usando best.pt y guarda resultados (si falta algo, no falla: avisa)\n",
        "run_name = \"train\"                                                # Define el nombre del entrenamiento (igual que antes)\n",
        "pred_video_name = \"predict_video\"                                 # Define el nombre de la carpeta de salida para video\n",
        "\n",
        "best_path = DIR_RUNS/run_name/\"weights/best.pt\"                   # Ruta esperada del modelo entrenado best.pt\n",
        "video_path = next((p for p in DIR_IN.iterdir() if p.suffix.lower() in [\".mp4\", \".mov\", \".avi\", \".mkv\"]), None)  # Busca un video en /content/in\n",
        "\n",
        "# Chequea prerequisitos sin tirar error\n",
        "if not best_path.exists():                                        # Si no existe best.pt\n",
        "    print(\"‚ö†Ô∏è No encuentro best.pt en:\", best_path)               # Aviso\n",
        "    print(\"‚ÑπÔ∏è Corre el Bloque 12 (entrenamiento) antes de este bloque.\")  # Gu√≠a\n",
        "elif video_path is None:                                          # Si no hay video subido\n",
        "    print(\"‚ö†Ô∏è No detecto ning√∫n video en /content/in.\")           # Aviso\n",
        "    print(\"‚ÑπÔ∏è Sube un video (mp4/mov/avi/mkv) y vuelve a correr este bloque.\")  # Gu√≠a\n",
        "else:\n",
        "    # Intenta correr la predicci√≥n de YOLO sobre el video\n",
        "    try:\n",
        "        print(\"‚úÖ Iniciando predicci√≥n en video:\")                # Mensaje de inicio\n",
        "        print(\" - Modelo:\", best_path)                            # Muestra el modelo usado\n",
        "        print(\" - Video:\", video_path.name)                       # Muestra el video usado\n",
        "        print(\" - Salida:\", DIR_RUNS/pred_video_name)             # Muestra la carpeta de salida\n",
        "\n",
        "        model = YOLO(str(best_path))                              # Carga el modelo entrenado\n",
        "        model.predict(                                            # Ejecuta predicci√≥n\n",
        "            source=str(video_path),                               # Fuente: video\n",
        "            save=True,                                            # Guarda el video/frames con cajas dibujadas\n",
        "            save_txt=True,                                        # Guarda detecciones en .txt (por frame)\n",
        "            save_conf=True,                                       # Incluye confidence en esos .txt\n",
        "            project=str(DIR_RUNS),                                # Carpeta base de salida\n",
        "            name=pred_video_name,                                 # Nombre del run de predicci√≥n\n",
        "            exist_ok=True                                         # Reutiliza carpeta si ya existe\n",
        "        )\n",
        "\n",
        "        print(\"‚úÖ Predicci√≥n completada en:\", DIR_RUNS/pred_video_name)  # Confirmaci√≥n\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è Fall√≥ la predicci√≥n en video por un error:\")    # Aviso de error\n",
        "        print(\"   \", str(e)[:400])                                # Muestra parte del error\n",
        "        print(\"‚ÑπÔ∏è Tip t√≠pico: revisa que el video no est√© corrupto o que best.pt exista.\")  # Gu√≠a\n",
        "\n",
        "    # Chequea outputs esperados (sin romper)\n",
        "    out_dir = DIR_RUNS/pred_video_name                            # Carpeta de salida del predict\n",
        "    labels_dir = out_dir/\"labels\"                                 # Carpeta donde deber√≠an quedar los .txt\n",
        "\n",
        "    print(\"\\n‚úÖ Chequeo de outputs:\")                              # T√≠tulo del chequeo\n",
        "    if out_dir.exists():                                          # Si existe la carpeta de salida\n",
        "        print(\" - Carpeta salida OK:\", out_dir)                   # Confirma\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No existe la carpeta de salida:\", out_dir)      # Aviso\n",
        "\n",
        "    if labels_dir.exists():                                       # Si existe la carpeta labels\n",
        "        n_txt = len(list(labels_dir.glob(\"*.txt\")))               # Cuenta cuantos txt hay\n",
        "        print(\" - Labels (.txt) OK:\", labels_dir, \"| cantidad:\", n_txt)  # Confirma cantidad\n",
        "        if n_txt == 0:                                            # Si no hay txt\n",
        "            print(\"‚ö†Ô∏è labels/ existe pero no tiene .txt (puede ser que no detect√≥ nada o fall√≥ el guardado).\")  # Aviso\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No encontr√© carpeta labels/ en:\", labels_dir)   # Aviso\n",
        "        print(\"‚ÑπÔ∏è Si no existe, revisa que predict se ejecut√≥ con save_txt=True.\")  # Gu√≠a\n",
        "\n",
        "    # Intenta encontrar el video anotado generado y reportarlo\n",
        "    annotated_candidates = []                                     # Lista para candidatos de video anotado\n",
        "    for ext in [\".mp4\", \".mov\", \".avi\", \".mkv\"]:                  # Revisa extensiones comunes\n",
        "        annotated_candidates += list(out_dir.glob(f\"*{ext}\"))     # Agrega coincidencias\n",
        "\n",
        "    if annotated_candidates:                                      # Si hay alg√∫n candidato\n",
        "        annotated_video = annotated_candidates[0]                 # Toma el primero\n",
        "        print(\" - Video anotado detectado:\", annotated_video.name)  # Confirma nombre\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No pude detectar un video anotado en la carpeta de salida (a veces YOLO guarda frames en vez de video).\")  # Aviso\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "yt_ivSbyyly5",
        "outputId": "9746413a-f0a8-4248-9406-84c656e73739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'DIR_RUNS' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3816604416.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred_video_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"predict_video\"\u001b[0m                                 \u001b[0;31m# Define el nombre de la carpeta de salida para video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDIR_RUNS\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"weights/best.pt\"\u001b[0m                   \u001b[0;31m# Ruta esperada del modelo entrenado best.pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDIR_IN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\".mp4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".mov\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".avi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".mkv\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Busca un video en /content/in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DIR_RUNS' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 15 ‚Äî Construir detections.csv (detecciones por frame/tiempo):} \\\n",
        "\\\\\\ \\text{Lee los .txt generados por YOLO en labels/ y crea una tabla (CSV) con frame, tiempo, clase, confianza y caja (x,y,w,h).}$$\n"
      ],
      "metadata": {
        "id": "_W6gCFpMywBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea detections.csv desde los .txt de /content/runs/predict_video/labels (si falta algo, no falla: avisa)\n",
        "import json                                                     # Sirve para leer salida JSON de ffprobe (fps del video)\n",
        "import math                                                     # Utilidades matem√°ticas (por si se necesita)\n",
        "\n",
        "pred_video_name = \"predict_video\"                               # Debe coincidir con el nombre usado en el Bloque 14\n",
        "out_dir = DIR_RUNS/pred_video_name                              # Carpeta de salida de la predicci√≥n de video\n",
        "labels_dir = out_dir/\"labels\"                                   # Carpeta donde YOLO deja los .txt por frame\n",
        "det_csv_path = DIR_OUT/\"detections.csv\"                         # Ruta final del CSV de detecciones\n",
        "\n",
        "# Intenta detectar el video en /content/in (para calcular tiempo real con fps)\n",
        "video_path = next((p for p in DIR_IN.iterdir() if p.suffix.lower() in [\".mp4\", \".mov\", \".avi\", \".mkv\"]), None)  # Busca video subido\n",
        "\n",
        "# Funci√≥n para obtener FPS real del video usando ffprobe (si falla, devuelve None)\n",
        "def get_video_fps(path):                                        # Define funci√≥n para leer fps del video\n",
        "    try:\n",
        "        cmd = f'ffprobe -v error -select_streams v:0 -show_entries stream=r_frame_rate -of json \"{path}\"'  # Comando ffprobe\n",
        "        r = subprocess.run(cmd, shell=True, capture_output=True, text=True)  # Ejecuta ffprobe\n",
        "        data = json.loads(r.stdout)                              # Parsea JSON\n",
        "        rate = data[\"streams\"][0][\"r_frame_rate\"]                # Lee r_frame_rate (ej: \"30000/1001\")\n",
        "        num, den = rate.split(\"/\")                               # Separa numerador/denominador\n",
        "        return float(num) / float(den)                           # Calcula fps como n√∫mero\n",
        "    except Exception:\n",
        "        return None                                              # Si algo falla, retorna None\n",
        "\n",
        "# Chequea prerequisitos sin romper el notebook\n",
        "if not out_dir.exists():                                        # Si no existe carpeta de predicci√≥n de video\n",
        "    print(\"‚ö†Ô∏è No existe la carpeta de predicci√≥n:\", out_dir)     # Aviso\n",
        "    print(\"‚ÑπÔ∏è Corre el Bloque 14 (predicci√≥n en video) antes de este bloque.\")  # Gu√≠a\n",
        "elif not labels_dir.exists():                                    # Si no existe labels/\n",
        "    print(\"‚ö†Ô∏è No existe la carpeta labels/:\", labels_dir)        # Aviso\n",
        "    print(\"‚ÑπÔ∏è Aseg√∫rate de correr el Bloque 14 con save_txt=True y save_conf=True.\")  # Gu√≠a\n",
        "else:\n",
        "    # Obtiene fps del video (si no hay video o falla, usa fps=1 como fallback)\n",
        "    fps = get_video_fps(video_path) if video_path else None      # Calcula fps real si hay video\n",
        "    if fps is None:                                              # Si no se pudo obtener fps\n",
        "        fps = 1.0                                                # Fallback para no romper el flujo\n",
        "        print(\"‚ö†Ô∏è No pude obtener FPS del video; usar√© fps=1.0 como aproximaci√≥n para time_s.\")  # Aviso\n",
        "    else:\n",
        "        print(\"‚úÖ FPS detectado del video:\", fps)                 # Confirma fps real\n",
        "\n",
        "    # Lee todos los .txt de labels/ ordenados por nombre\n",
        "    txt_files = sorted(labels_dir.glob(\"*.txt\"))                 # Lista txt en labels/\n",
        "    if len(txt_files) == 0:                                      # Si no hay txt\n",
        "        print(\"‚ö†Ô∏è labels/ existe pero no tiene .txt. Puede que no haya detecciones o algo fall√≥.\")  # Aviso\n",
        "    else:\n",
        "        rows = []                                                # Lista para acumular filas del CSV\n",
        "\n",
        "        # Recorre cada archivo .txt (cada uno representa un frame/imagen)\n",
        "        for lf in txt_files:                                     # Recorre cada archivo de detecci√≥n\n",
        "            stem = lf.stem                                       # Nombre sin extensi√≥n (ej: \"000001\")\n",
        "            digits = re.sub(r\"\\D\", \"\", stem)                     # Extrae solo n√∫meros del nombre\n",
        "            if digits == \"\":                                     # Si no hay n√∫meros, salta\n",
        "                continue                                         # Evita errores de conversi√≥n\n",
        "\n",
        "            frame_idx = int(digits)                              # Convierte a √≠ndice de frame\n",
        "            time_s = frame_idx / fps                             # Convierte frame a tiempo en segundos (aprox)\n",
        "\n",
        "            # Lee cada detecci√≥n dentro del txt (una l√≠nea por detecci√≥n)\n",
        "            content = lf.read_text(encoding=\"utf-8\").strip()     # Lee el contenido del archivo\n",
        "            if content == \"\":                                    # Si est√° vac√≠o, no hay detecciones en ese frame\n",
        "                continue                                         # Salta\n",
        "\n",
        "            for line in content.splitlines():                    # Recorre cada l√≠nea del txt\n",
        "                parts = line.split()                             # Separa por espacios\n",
        "                if len(parts) < 5:                               # Si no tiene lo m√≠nimo YOLO\n",
        "                    continue                                     # Salta l√≠neas raras\n",
        "\n",
        "                cls_id = int(parts[0])                           # ID de clase (0,1,2...)\n",
        "                x = float(parts[1]); y = float(parts[2])         # Centro x,y normalizado (0-1)\n",
        "                w = float(parts[3]); h = float(parts[4])         # Ancho/alto normalizado (0-1)\n",
        "\n",
        "                # confidence solo existe si guardaste save_conf=True\n",
        "                conf = float(parts[5]) if len(parts) >= 6 else None  # Lee confidence si existe\n",
        "\n",
        "                # Obtiene nombre de clase si existe lista 'classes' (si no, deja el id)\n",
        "                class_name = None                                # Inicializa nombre de clase\n",
        "                if \"classes\" in globals() and isinstance(classes, list) and cls_id < len(classes):  # Si existe lista classes\n",
        "                    class_name = classes[cls_id]                 # Traduce id a nombre\n",
        "                else:\n",
        "                    class_name = str(cls_id)                     # Fallback: usa el id como texto\n",
        "\n",
        "                # Agrega una fila a la tabla\n",
        "                rows.append({                                    # Crea un dict por detecci√≥n\n",
        "                    \"frame\": frame_idx,                          # Frame detectado\n",
        "                    \"time_s\": time_s,                            # Tiempo aproximado en segundos\n",
        "                    \"class_id\": cls_id,                          # ID de clase\n",
        "                    \"class_name\": class_name,                    # Nombre de clase (si est√° definido)\n",
        "                    \"conf\": conf,                                # Confianza (puede ser None)\n",
        "                    \"x\": x, \"y\": y, \"w\": w, \"h\": h               # Caja en formato YOLO normalizado\n",
        "                })\n",
        "\n",
        "        # Convierte a DataFrame y guarda CSV\n",
        "        det_df = pd.DataFrame(rows)                              # Crea tabla con todas las detecciones\n",
        "        if det_df.empty:                                         # Si qued√≥ vac√≠o\n",
        "            print(\"‚ö†Ô∏è No se generaron filas en detections.csv (quiz√°s no hubo detecciones).\")  # Aviso\n",
        "        else:\n",
        "            det_df = det_df.sort_values([\"frame\", \"conf\"], ascending=[True, False])  # Ordena por frame y mejor confianza\n",
        "            det_df.to_csv(det_csv_path, index=False, encoding=\"utf-8\")               # Guarda el CSV\n",
        "\n",
        "            print(\"‚úÖ detections.csv creado en:\", det_csv_path)   # Confirma salida\n",
        "            print(\"‚úÖ Filas:\", len(det_df), \"| Frames √∫nicos:\", det_df[\"frame\"].nunique())  # Resumen r√°pido\n",
        "            print(\"‚úÖ Ejemplo de 5 filas:\")                       # T√≠tulo ejemplo\n",
        "            print(det_df.head(5).to_string(index=False))          # Muestra 5 filas\n"
      ],
      "metadata": {
        "id": "-YtL6dH6zEI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 16 ‚Äî Construir events.csv (intervalos/timeline):} \\\n",
        "\\\\\\ \\text{Convierte detections.csv en ‚Äúeventos‚Äù por clase: agrupa frames cercanos en intervalos (inicio‚Äìfin) para evitar parpadeos y generar un timeline legible.}$$\n"
      ],
      "metadata": {
        "id": "ooUu7Bg8zgsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea events.csv agrupando detecciones por clase en intervalos (si falta detections.csv, no falla: avisa)\n",
        "events_csv_path = DIR_OUT/\"events.csv\"                             # Define d√≥nde se guardar√° el archivo de eventos\n",
        "det_csv_path = DIR_OUT/\"detections.csv\"                            # Ruta esperada del detections.csv\n",
        "\n",
        "# Par√°metros anti-parpadeo (ajustables)\n",
        "min_conf = 0.35                                                     # Umbral m√≠nimo de confianza para considerar detecci√≥n\n",
        "gap_frames = 2                                                      # Permite ‚Äúhuecos‚Äù de hasta N frames dentro de un mismo evento\n",
        "min_len_frames = 3                                                  # Evento m√≠nimo: requiere al menos N frames para existir\n",
        "\n",
        "# Intenta obtener FPS del video para convertir frames a segundos (si falla, usa 1.0)\n",
        "video_path = next((p for p in DIR_IN.iterdir() if p.suffix.lower() in [\".mp4\", \".mov\", \".avi\", \".mkv\"]), None)  # Busca video en /content/in\n",
        "\n",
        "def get_video_fps_safe(path):                                       # Funci√≥n segura para obtener fps del video\n",
        "    try:\n",
        "        import json                                                 # Importa json para parsear ffprobe\n",
        "        cmd = f'ffprobe -v error -select_streams v:0 -show_entries stream=r_frame_rate -of json \"{path}\"'  # Comando ffprobe\n",
        "        r = subprocess.run(cmd, shell=True, capture_output=True, text=True)  # Ejecuta ffprobe\n",
        "        data = json.loads(r.stdout)                                 # Parsea JSON\n",
        "        rate = data[\"streams\"][0][\"r_frame_rate\"]                   # Lee r_frame_rate (ej: \"30000/1001\")\n",
        "        num, den = rate.split(\"/\")                                  # Separa numerador/denominador\n",
        "        return float(num) / float(den)                              # Devuelve fps real\n",
        "    except Exception:\n",
        "        return 1.0                                                  # Fallback si falla\n",
        "\n",
        "fps = get_video_fps_safe(video_path) if video_path else 1.0         # Calcula fps si hay video; si no, usa 1.0\n",
        "print(\"‚úÖ FPS usado para convertir frames‚Üísegundos:\", fps)            # Confirma fps usado\n",
        "\n",
        "# Si no existe detections.csv, avisa y termina sin romper el notebook\n",
        "if not det_csv_path.exists():                                       # Verifica si existe detections.csv\n",
        "    print(\"‚ö†Ô∏è No existe detections.csv en:\", det_csv_path)          # Aviso\n",
        "    print(\"‚ÑπÔ∏è Corre el Bloque 15 (detections.csv) antes de este bloque.\")  # Gu√≠a\n",
        "else:\n",
        "    # Carga detections.csv (si est√° vac√≠o o corrupto, avisa sin romper)\n",
        "    try:\n",
        "        det_df = pd.read_csv(det_csv_path)                          # Lee el CSV de detecciones\n",
        "        print(\"‚úÖ detections.csv cargado | filas:\", len(det_df))     # Confirma carga\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è No pude leer detections.csv por un error:\")       # Aviso\n",
        "        print(\"   \", str(e)[:300])                                   # Muestra parte del error\n",
        "        det_df = pd.DataFrame()                                     # Deja DF vac√≠o para no romper\n",
        "\n",
        "    # Si no hay datos, avisa y termina\n",
        "    if det_df.empty:                                                # Revisa si el DataFrame qued√≥ vac√≠o\n",
        "        print(\"‚ö†Ô∏è detections.csv est√° vac√≠o; no puedo generar events.csv.\")  # Aviso\n",
        "        print(\"‚ÑπÔ∏è Esto puede pasar si el modelo no detect√≥ nada en el video.\")  # Gu√≠a\n",
        "    else:\n",
        "        # Asegura columnas necesarias (si falta alguna, avisa y termina)\n",
        "        needed = {\"frame\", \"class_name\", \"conf\"}                    # Columnas m√≠nimas requeridas\n",
        "        if not needed.issubset(set(det_df.columns)):                # Verifica columnas\n",
        "            print(\"‚ö†Ô∏è detections.csv no tiene las columnas m√≠nimas:\", needed)  # Aviso\n",
        "            print(\"‚ÑπÔ∏è Revisa que el Bloque 15 haya generado frame/class_name/conf.\")  # Gu√≠a\n",
        "        else:\n",
        "            events_rows = []                                        # Lista donde guardaremos eventos (intervalos)\n",
        "\n",
        "            # Recorre cada clase y crea intervalos de frames consecutivos (con tolerancia de gap)\n",
        "            for cname in sorted(det_df[\"class_name\"].dropna().unique()):  # Recorre clases detectadas\n",
        "                sub = det_df[(det_df[\"class_name\"] == cname)]       # Filtra por clase\n",
        "                sub = sub[sub[\"conf\"].fillna(0) >= min_conf]        # Filtra por confianza m√≠nima (maneja NaN)\n",
        "\n",
        "                frames = sorted(sub[\"frame\"].dropna().astype(int).unique())  # Lista frames √∫nicos ordenados\n",
        "                if len(frames) == 0:                                # Si no hay frames para esta clase\n",
        "                    continue                                        # Pasa a la siguiente clase\n",
        "\n",
        "                start = frames[0]                                   # Inicio del evento actual\n",
        "                prev = frames[0]                                    # √öltimo frame visto del evento actual\n",
        "\n",
        "                for fr in frames[1:]:                               # Recorre frames siguientes\n",
        "                    if fr <= prev + 1 + gap_frames:                 # Si est√° cerca (con tolerancia de huecos)\n",
        "                        prev = fr                                   # Extiende el evento actual\n",
        "                    else:\n",
        "                        # Cierra evento anterior si cumple largo m√≠nimo\n",
        "                        if (prev - start + 1) >= min_len_frames:    # Verifica largo m√≠nimo del evento\n",
        "                            events_rows.append([cname, start, prev])  # Guarda evento (clase, inicio, fin)\n",
        "                        start = fr                                  # Abre nuevo evento\n",
        "                        prev = fr                                   # Reinicia √∫ltimo frame\n",
        "\n",
        "                # Cierra el √∫ltimo evento\n",
        "                if (prev - start + 1) >= min_len_frames:            # Verifica largo m√≠nimo final\n",
        "                    events_rows.append([cname, start, prev])         # Guarda √∫ltimo evento\n",
        "\n",
        "            # Si no hubo eventos (por filtros), avisa y termina sin romper\n",
        "            if len(events_rows) == 0:                               # Revisa si se gener√≥ algo\n",
        "                print(\"‚ö†Ô∏è No se generaron eventos con los par√°metros actuales.\")  # Aviso\n",
        "                print(\"‚ÑπÔ∏è Prueba bajar min_conf o min_len_frames si te est√° quedando vac√≠o.\")  # Gu√≠a\n",
        "            else:\n",
        "                # Convierte eventos a DataFrame y calcula tiempos\n",
        "                ev_df = pd.DataFrame(events_rows, columns=[\"class_name\", \"start_frame\", \"end_frame\"])  # Crea tabla de eventos\n",
        "                ev_df[\"start_s\"] = ev_df[\"start_frame\"] / fps       # Convierte inicio a segundos\n",
        "                ev_df[\"end_s\"] = ev_df[\"end_frame\"] / fps           # Convierte fin a segundos\n",
        "                ev_df[\"duration_s\"] = (ev_df[\"end_s\"] - ev_df[\"start_s\"]).clip(lower=0)  # Calcula duraci√≥n no negativa\n",
        "\n",
        "                # Ordena eventos por tiempo de inicio\n",
        "                ev_df = ev_df.sort_values([\"start_s\", \"class_name\"])  # Ordena cronol√≥gicamente\n",
        "\n",
        "                # Guarda events.csv\n",
        "                ev_df.to_csv(events_csv_path, index=False, encoding=\"utf-8\")  # Guarda el CSV final\n",
        "\n",
        "                # Prints de confirmaci√≥n + resumen\n",
        "                print(\"‚úÖ events.csv creado en:\", events_csv_path)   # Confirma salida\n",
        "                print(\"‚úÖ Eventos:\", len(ev_df), \"| Clases:\", ev_df[\"class_name\"].nunique())  # Resumen\n",
        "                print(\"‚úÖ Ejemplo de 10 eventos:\")                   # T√≠tulo ejemplo\n",
        "                print(ev_df.head(10).to_string(index=False))         # Muestra 10 filas\n",
        "\n",
        "                # Guarda los par√°metros usados para trazabilidad\n",
        "                params_path = DIR_OUT/\"events_params.txt\"            # Archivo para guardar par√°metros\n",
        "                params_text = (                                     # Texto de par√°metros\n",
        "                    f\"min_conf={min_conf}\\n\"\n",
        "                    f\"gap_frames={gap_frames}\\n\"\n",
        "                    f\"min_len_frames={min_len_frames}\\n\"\n",
        "                    f\"fps_used={fps}\\n\"\n",
        "                )\n",
        "                params_path.write_text(params_text, encoding=\"utf-8\")  # Escribe par√°metros\n",
        "                print(\"‚úÖ Par√°metros guardados en:\", params_path)     # Confirma guardado\n"
      ],
      "metadata": {
        "id": "EoW-Zt51zkFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "$$\\textbf{Bloques auxiliares}$$"
      ],
      "metadata": {
        "id": "KY4q8VSoB8io"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 3 ‚Äî Subida de archivos (cvat zip, videos, best.pt):} \\\n",
        "\\\\\\ \\text{Permite subir archivos desde tu computador a Colab y los deja guardados en content in para usarlos en el flujo.}$$"
      ],
      "metadata": {
        "id": "0mw1_dD2rcUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Habilita el bot√≥n de subir archivos desde tu PC a Colab\n",
        "from google.colab import files  # Herramienta de Colab para subir archivos manualmente\n",
        "\n",
        "# Abre el selector para subir: video.mp4 o images.zip o cvat_yolo_export.zip\n",
        "uploaded = files.upload()  # Te deja elegir archivos desde tu computador\n",
        "\n",
        "# Mueve cada archivo subido a la carpeta est√°ndar /content/in\n",
        "for fname in uploaded.keys():              # Recorre los nombres de lo que subiste\n",
        "    src = Path(\"/content\")/fname           # Colab lo deja primero en /content\n",
        "    dst = DIR_IN/fname                     # Destino final en /content/in\n",
        "    if src.exists():                       # Confirma que el archivo est√°\n",
        "        shutil.move(str(src), str(dst))    # Lo mueve a /content/in\n",
        "\n",
        "# Muestra lo que qued√≥ en /content/in para confirmar que est√° OK\n",
        "print(\"‚úÖ Archivos guardados en /content/in:\")  # Mensaje de confirmaci√≥n\n",
        "items = list(DIR_IN.iterdir())                 # Lee el contenido de /content/in\n",
        "if items:                                      # Si hay archivos\n",
        "    for p in items:                            # Recorre cada archivo\n",
        "        print(\" -\", p.name, f\"({p.stat().st_size/1e6:.2f} MB)\")  # Nombre y tama√±o\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Carpeta vac√≠a: no se subi√≥ nada a√∫n.\")             # Aviso si no hay archivos\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "ffn9I0vYriUw",
        "outputId": "cab0b3bb-881e-4c7d-d27c-e472714c5241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-468e1b01-bc9e-4be5-be69-b0f203921705\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-468e1b01-bc9e-4be5-be69-b0f203921705\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 6 ‚Äî Video ‚Üí Frames:} \\\n",
        "\\\\\\ \\text{Si hay un video, extrae im√°genes (frames) a una frecuencia definida (fps) y las guarda en #/content/work/frames para etiquetarlas despu√©s.}$$\n"
      ],
      "metadata": {
        "id": "Cqn_85R1t49f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Busca un video por extensi√≥n com√∫n (si existe)\n",
        "video = next((p for p in in_files if p.suffix.lower() in [\".mp4\", \".mov\", \".avi\", \".mkv\"]), None)  # Encuentra el primer video\n",
        "\n",
        "# Extrae frames desde el video detectado (si no hay video, no falla: solo avisa)\n",
        "fps_extract = 1.0                                              # Define cu√°ntas im√°genes por segundo extraer (ej: 1.0 = 1 frame/seg)\n",
        "img_ext = \"jpg\"                                                # Define el formato de imagen de salida (jpg o png)\n",
        "\n",
        "# Si no hay video, no hacemos nada y seguimos\n",
        "if video is None:                                              # Revisa si se detect√≥ un video en /content/in\n",
        "    print(\"‚ö†Ô∏è No hay video detectado en /content/in, as√≠ que no se extraen frames todav√≠a.\")  # Aviso sin romper el flujo\n",
        "else:\n",
        "    # Limpia frames anteriores para no mezclar corridas\n",
        "    old_frames = list(FRAMES_DIR.glob(f\"*.{img_ext}\"))          # Busca frames antiguos en la carpeta de frames\n",
        "    for f in old_frames:                                        # Recorre frames antiguos\n",
        "        f.unlink()                                              # Borra cada frame antiguo\n",
        "\n",
        "    # Define el n√∫mero inicial desde el cual deseas comenzar la numeraci√≥n\n",
        "    start_number = 886  # Puedes poner el n√∫mero que desees\n",
        "\n",
        "    # Define el patr√≥n de nombres con el n√∫mero de inicio\n",
        "    out_pattern = str(FRAMES_DIR / f\"%06d.{img_ext}\")\n",
        "\n",
        "    # Construye y ejecuta el comando ffmpeg para extraer frames\n",
        "    cmd = [\n",
        "    \"ffmpeg\", \"-y\",\n",
        "    \"-i\", str(video),\n",
        "    \"-vf\", f\"fps={fps_extract}\",\n",
        "    \"-start_number\", str(start_number), # <--- ESTO indica d√≥nde empezar\n",
        "    out_pattern]\n",
        "\n",
        "    print(\"‚úÖ Ejecutando FFmpeg para extraer frames:\")          # Mensaje de inicio\n",
        "    print(\"   \", \" \".join(cmd))                                 # Muestra el comando para trazabilidad\n",
        "    subprocess.run(cmd, check=False)                            # Ejecuta sin romper el notebook si ffmpeg devuelve error\n",
        "\n",
        "    # Cuenta y muestra resultados\n",
        "    frames = sorted(FRAMES_DIR.glob(f\"*.{img_ext}\"))            # Busca los frames generados\n",
        "    if len(frames) == 0:                                        # Si no se gener√≥ ning√∫n frame\n",
        "        print(\"‚ö†Ô∏è No se generaron frames (revisa si el video est√° OK o si fps_extract es muy bajo).\")  # Aviso\n",
        "    else:\n",
        "        print(f\"‚úÖ Frames listos: {len(frames)} en {FRAMES_DIR}\")  # Confirma cu√°ntos frames se crearon\n",
        "        print(\"   Ejemplo primero/√∫ltimo:\", frames[0].name, \"|\", frames[-1].name)  # Muestra nombres de ejemplo\n",
        "\n",
        "# Comprime los frames en un ZIP descargable (si no hay frames, no falla: solo avisa)\n",
        "zip_frames_path = DIR_OUT/\"frames.zip\"                         # Define d√≥nde quedar√° el zip final\n",
        "\n",
        "# Busca frames existentes en la carpeta de frames\n",
        "frame_files = sorted(list(FRAMES_DIR.glob(\"*.jpg\")) + list(FRAMES_DIR.glob(\"*.png\")))  # Re√∫ne frames jpg/png\n",
        "\n",
        "# Si no hay frames a√∫n, avisa y termina sin error\n",
        "if len(frame_files) == 0:                                      # Revisa si hay frames para comprimir\n",
        "    print(\"‚ö†Ô∏è No hay frames en /content/work/frames, as√≠ que no se puede crear frames.zip todav√≠a.\")  # Aviso\n",
        "else:\n",
        "    # Si ya exist√≠a un zip antiguo, lo borra para evitar confusiones\n",
        "    if zip_frames_path.exists():                               # Verifica si el zip ya existe\n",
        "        zip_frames_path.unlink()                               # Borra el zip anterior\n",
        "\n",
        "    # Crea el zip con todos los frames\n",
        "    with zipfile.ZipFile(zip_frames_path, \"w\", zipfile.ZIP_DEFLATED) as z:  # Abre un zip en modo escritura\n",
        "        for f in frame_files:                                  # Recorre cada frame\n",
        "            z.write(f, arcname=f.name)                         # Agrega el archivo al zip con su nombre\n",
        "\n",
        "    # Confirma que el zip se cre√≥ correctamente\n",
        "    print(\"‚úÖ ZIP creado para CVAT:\", zip_frames_path)          # Muestra la ruta del zip creado\n",
        "    print(f\"‚úÖ Incluye {len(frame_files)} im√°genes.\")          # Indica cu√°ntas im√°genes quedaron dentro\n",
        "\n",
        "    # Opci√≥n de descarga directa (si quieres)\n",
        "    try:\n",
        "        from google.colab import files                         # Importa herramienta de descarga de Colab\n",
        "        files.download(str(zip_frames_path))                   # Descarga el zip a tu PC\n",
        "        print(\"‚úÖ Descarga iniciada (si tu navegador lo permite).\")  # Confirmaci√≥n\n",
        "    except Exception:\n",
        "        print(\"‚ö†Ô∏è No pude iniciar descarga autom√°tica, pero el zip qued√≥ en /content/out para descargarlo manualmente.\")  # Aviso\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "V_neNeMBuqXH",
        "outputId": "6ca386ac-346e-4d72-e51b-5543e03b9edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Ejecutando FFmpeg para extraer frames:\n",
            "    ffmpeg -y -i /content/in/TRAMO 3 - PARTE 2.mp4 -vf fps=1.0 -start_number 590 /content/work/frames/%06d.jpg\n",
            "‚úÖ Frames listos: 296 en /content/work/frames\n",
            "   Ejemplo primero/√∫ltimo: 000590.jpg | 000885.jpg\n",
            "‚úÖ ZIP creado para CVAT: /content/out/frames.zip\n",
            "‚úÖ Incluye 296 im√°genes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5fde5128-9425-47b5-9a0a-df7539cedd53\", \"frames.zip\", 9302360)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Descarga iniciada (si tu navegador lo permite).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "$$\\textbf{Bloque 19 ‚Äî Interfaz simple (modo ‚Äúusuario final‚Äù):} \\\n",
        "\\\\\\ \\text{Permite subir un modelo best.pt y un video, ejecuta la predicci√≥n y genera final\\_report.zip (video anotado + CSVs) en #/content/out.}$$\n"
      ],
      "metadata": {
        "id": "eClX8PwF0_13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Interfaz m√≠nima: subes best.pt + video y el notebook te genera el zip final (si falta algo, no falla: avisa)\n",
        "from google.colab import files                                  # Herramienta de Colab para subir/descargar archivos\n",
        "\n",
        "# Define nombres est√°ndar de trabajo\n",
        "UI_MODEL_NAME = \"best.pt\"                                       # Nombre esperado para el modelo subido\n",
        "UI_VIDEO_NAME = None                                            # Nombre del video subido (lo detectamos por extensi√≥n)\n",
        "\n",
        "# Crea carpetas por si no existen (por seguridad)\n",
        "for d in [DIR_IN, DIR_RUNS, DIR_OUT]:                           # Asegura carpetas clave\n",
        "    d.mkdir(parents=True, exist_ok=True)                        # Crea si falta\n",
        "\n",
        "print(\"‚úÖ Interfaz simple: sube best.pt y un video (mp4/mov/avi/mkv).\")  # Instrucci√≥n amigable\n",
        "\n",
        "# Subida de archivos (el usuario elige desde su PC)\n",
        "uploaded = files.upload()                                       # Abre selector para subir archivos\n",
        "\n",
        "# Mueve lo subido a /content/in para mantener el est√°ndar\n",
        "for fname in uploaded.keys():                                   # Recorre nombres de archivos subidos\n",
        "    src = Path(\"/content\")/fname                                # Ruta temporal donde Colab deja los archivos\n",
        "    dst = DIR_IN/fname                                          # Ruta final en /content/in\n",
        "    if src.exists():                                            # Verifica existencia\n",
        "        shutil.move(str(src), str(dst))                         # Mueve a /content/in\n",
        "\n",
        "# Detecta best.pt y video dentro de /content/in\n",
        "model_path = DIR_IN/UI_MODEL_NAME                               # Ruta esperada del modelo (best.pt)\n",
        "video_path = next((p for p in DIR_IN.iterdir() if p.suffix.lower() in [\".mp4\",\".mov\",\".avi\",\".mkv\"]), None)  # Busca video\n",
        "\n",
        "# Valida inputs sin romper\n",
        "if not model_path.exists():                                     # Si no existe el modelo subido\n",
        "    print(\"‚ö†Ô∏è No encontr√© best.pt en /content/in.\")             # Aviso\n",
        "    print(\"‚ÑπÔ∏è Sube un archivo llamado exactamente 'best.pt'.\")  # Gu√≠a\n",
        "elif video_path is None:                                        # Si no se detect√≥ video\n",
        "    print(\"‚ö†Ô∏è No encontr√© un video en /content/in.\")            # Aviso\n",
        "    print(\"‚ÑπÔ∏è Sube un video .mp4/.mov/.avi/.mkv junto al best.pt.\")  # Gu√≠a\n",
        "else:\n",
        "    # Define carpeta de salida para esta predicci√≥n\n",
        "    pred_video_name = \"predict_video_ui\"                        # Nombre del run de predicci√≥n para interfaz\n",
        "    out_dir = DIR_RUNS/pred_video_name                          # Carpeta donde YOLO guardar√° resultados\n",
        "    labels_dir = out_dir/\"labels\"                               # Carpeta donde quedar√°n txt por frame\n",
        "\n",
        "    # Ejecuta predicci√≥n en video y guarda video + txt + conf\n",
        "    try:\n",
        "        print(\"‚úÖ Ejecutando predicci√≥n (interfaz):\")            # Mensaje de inicio\n",
        "        print(\" - Modelo:\", model_path)                          # Muestra modelo\n",
        "        print(\" - Video:\", video_path.name)                      # Muestra video\n",
        "        print(\" - Salida:\", out_dir)                             # Muestra salida\n",
        "\n",
        "        model = YOLO(str(model_path))                            # Carga el modelo subido\n",
        "        model.predict(                                           # Ejecuta predicci√≥n\n",
        "            source=str(video_path),                               # Video de entrada\n",
        "            save=True,                                            # Guarda salida visual\n",
        "            save_txt=True,                                        # Guarda txt por frame\n",
        "            save_conf=True,                                       # Guarda confidence\n",
        "            project=str(DIR_RUNS),                                # Carpeta base\n",
        "            name=pred_video_name,                                 # Nombre del run\n",
        "            exist_ok=True                                         # Reutiliza si existe\n",
        "        )\n",
        "\n",
        "        print(\"‚úÖ Predicci√≥n terminada.\")                         # Confirmaci√≥n\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è Fall√≥ la predicci√≥n por un error:\")            # Aviso de error\n",
        "        print(\"   \", str(e)[:400])                               # Muestra parte del error\n",
        "        print(\"‚ÑπÔ∏è Revisa que best.pt sea compatible con tu dataset/clases.\")  # Gu√≠a\n",
        "\n",
        "    # Construye detections.csv si existen labels\n",
        "    det_csv_path = DIR_OUT/\"detections.csv\"                      # Ruta detections final\n",
        "    events_csv_path = DIR_OUT/\"events.csv\"                       # Ruta events final\n",
        "\n",
        "    if not labels_dir.exists():                                  # Si no existe labels/\n",
        "        print(\"‚ö†Ô∏è No existe labels/ en la salida, as√≠ que no puedo construir CSVs.\")  # Aviso\n",
        "    else:\n",
        "        # Obtiene fps real para time_s (si falla, usa 1.0)\n",
        "        def get_video_fps_safe(path):                            # Funci√≥n segura para fps\n",
        "            try:\n",
        "                import json                                      # Para parsear JSON\n",
        "                cmd = f'ffprobe -v error -select_streams v:0 -show_entries stream=r_frame_rate -of json \"{path}\"'  # ffprobe\n",
        "                r = subprocess.run(cmd, shell=True, capture_output=True, text=True)  # Ejecuta\n",
        "                data = json.loads(r.stdout)                      # Parsea\n",
        "                rate = data[\"streams\"][0][\"r_frame_rate\"]        # Lee rate\n",
        "                num, den = rate.split(\"/\")                       # Separa\n",
        "                return float(num)/float(den)                     # Calcula fps\n",
        "            except Exception:\n",
        "                return 1.0                                       # Fallback\n",
        "\n",
        "        fps = get_video_fps_safe(video_path)                     # FPS para convertir frames a segundos\n",
        "        print(\"‚úÖ FPS usado:\", fps)                               # Confirma fps\n",
        "\n",
        "        # Lee txt y arma detections.csv\n",
        "        txt_files = sorted(labels_dir.glob(\"*.txt\"))             # Lista txt por frame\n",
        "        rows = []                                                # Filas para detections\n",
        "\n",
        "        for lf in txt_files:                                     # Recorre cada txt\n",
        "            digits = re.sub(r\"\\D\", \"\", lf.stem)                  # Extrae frame desde el nombre\n",
        "            if digits == \"\":                                     # Si no hay n√∫mero\n",
        "                continue                                         # Salta\n",
        "            frame_idx = int(digits)                              # Frame\n",
        "            time_s = frame_idx / fps                             # Tiempo en segundos (aprox)\n",
        "            content = lf.read_text(encoding=\"utf-8\").strip()     # Lee contenido\n",
        "            if content == \"\":                                    # Si vac√≠o\n",
        "                continue                                         # Salta\n",
        "\n",
        "            for line in content.splitlines():                    # Recorre detecciones\n",
        "                parts = line.split()                             # Separa\n",
        "                if len(parts) < 5:                               # Si no cumple m√≠nimo\n",
        "                    continue                                     # Salta\n",
        "                cls_id = int(parts[0])                           # Clase id\n",
        "                x, y, w, h = map(float, parts[1:5])              # Caja\n",
        "                conf = float(parts[5]) if len(parts) >= 6 else None  # Conf si existe\n",
        "                rows.append({\"frame\": frame_idx, \"time_s\": time_s, \"class_id\": cls_id, \"conf\": conf,\n",
        "                             \"x\": x, \"y\": y, \"w\": w, \"h\": h})    # Agrega fila\n",
        "\n",
        "        det_df = pd.DataFrame(rows)                              # Crea DataFrame\n",
        "        if det_df.empty:                                         # Si no hay detecciones\n",
        "            print(\"‚ö†Ô∏è No hubo detecciones, detections.csv quedar√° vac√≠o/no se generar√° events.csv.\")  # Aviso\n",
        "        else:\n",
        "            det_df = det_df.sort_values([\"frame\",\"conf\"], ascending=[True, False])  # Ordena\n",
        "            det_df.to_csv(det_csv_path, index=False, encoding=\"utf-8\")              # Guarda CSV\n",
        "            print(\"‚úÖ detections.csv listo en:\", det_csv_path)    # Confirma\n",
        "\n",
        "            # Genera events.csv agrupando por class_id (interfaz simple, sin nombres)\n",
        "            min_conf = 0.35                                      # Umbral conf\n",
        "            gap_frames = 2                                       # Huecos tolerados\n",
        "            min_len_frames = 3                                   # Largo m√≠nimo\n",
        "\n",
        "            events_rows = []                                     # Lista eventos\n",
        "            for cid in sorted(det_df[\"class_id\"].unique()):      # Recorre clases\n",
        "                sub = det_df[(det_df[\"class_id\"] == cid) & (det_df[\"conf\"].fillna(0) >= min_conf)]  # Filtra\n",
        "                frames = sorted(sub[\"frame\"].unique())           # Frames\n",
        "                if not frames:                                   # Si vac√≠o\n",
        "                    continue                                     # Salta\n",
        "                start = frames[0]; prev = frames[0]              # Inicializa evento\n",
        "                for fr in frames[1:]:                            # Recorre frames\n",
        "                    if fr <= prev + 1 + gap_frames:              # Si cercano\n",
        "                        prev = fr                                # Extiende\n",
        "                    else:\n",
        "                        if (prev - start + 1) >= min_len_frames: # Si cumple m√≠nimo\n",
        "                            events_rows.append([cid, start, prev])  # Guarda\n",
        "                        start = fr; prev = fr                    # Nuevo evento\n",
        "                if (prev - start + 1) >= min_len_frames:         # Cierra √∫ltimo\n",
        "                    events_rows.append([cid, start, prev])        # Guarda\n",
        "\n",
        "            ev_df = pd.DataFrame(events_rows, columns=[\"class_id\",\"start_frame\",\"end_frame\"])  # Tabla eventos\n",
        "            if ev_df.empty:                                      # Si no hay eventos\n",
        "                print(\"‚ö†Ô∏è No se generaron eventos con los par√°metros actuales.\")  # Aviso\n",
        "            else:\n",
        "                ev_df[\"start_s\"] = ev_df[\"start_frame\"]/fps      # Inicio s\n",
        "                ev_df[\"end_s\"] = ev_df[\"end_frame\"]/fps          # Fin s\n",
        "                ev_df[\"duration_s\"] = (ev_df[\"end_s\"]-ev_df[\"start_s\"]).clip(lower=0)  # Duraci√≥n\n",
        "                ev_df.to_csv(events_csv_path, index=False, encoding=\"utf-8\")            # Guarda CSV\n",
        "                print(\"‚úÖ events.csv listo en:\", events_csv_path)  # Confirma\n",
        "\n",
        "    # Copia video anotado (si existe) y arma zip final\n",
        "    final_zip_path = DIR_OUT/\"final_report.zip\"                  # Ruta zip final\n",
        "    to_zip = []                                                  # Lista archivos para zip\n",
        "\n",
        "    if model_path.exists():                                      # Si modelo existe\n",
        "        to_zip.append(model_path)                                # Agrega best.pt\n",
        "    if det_csv_path.exists():                                    # Si detections existe\n",
        "        to_zip.append(det_csv_path)                              # Agrega detections\n",
        "    if events_csv_path.exists():                                 # Si events existe\n",
        "        to_zip.append(events_csv_path)                           # Agrega events\n",
        "\n",
        "    # Busca un video anotado en la carpeta de salida y lo copia a /out\n",
        "    annotated_candidates = []                                    # Lista candidatos\n",
        "    for ext in [\".mp4\",\".mov\",\".avi\",\".mkv\"]:                    # Exts video\n",
        "        annotated_candidates += list(out_dir.glob(f\"*{ext}\"))     # Busca videos\n",
        "    if annotated_candidates:                                     # Si encontr√≥\n",
        "        shutil.copy2(annotated_candidates[0], DIR_OUT/\"annotated.mp4\")  # Copia a /out\n",
        "        to_zip.append(DIR_OUT/\"annotated.mp4\")                   # Agrega al zip\n",
        "        print(\"‚úÖ annotated.mp4 listo en /content/out.\")          # Confirma\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No encontr√© video anotado en la salida.\")       # Aviso\n",
        "\n",
        "    # Crea zip final si hay algo para comprimir\n",
        "    if len(to_zip) == 0:                                         # Si no hay nada\n",
        "        print(\"‚ö†Ô∏è No hay archivos para empaquetar todav√≠a.\")      # Aviso\n",
        "    else:\n",
        "        if final_zip_path.exists():                              # Si zip existe\n",
        "            final_zip_path.unlink()                              # Lo borra\n",
        "        with zipfile.ZipFile(final_zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:  # Crea zip\n",
        "            for p in to_zip:                                     # Recorre archivos\n",
        "                z.write(p, arcname=p.name)                       # Agrega al zip\n",
        "        print(\"‚úÖ final_report.zip creado en:\", final_zip_path)   # Confirma\n",
        "\n",
        "        # Descarga zip final\n",
        "        try:\n",
        "            files.download(str(final_zip_path))                  # Descarga zip\n",
        "            print(\"‚úÖ Descarga iniciada.\")                        # Confirmaci√≥n\n",
        "        except Exception:\n",
        "            print(\"‚ö†Ô∏è No pude iniciar descarga autom√°tica, pero qued√≥ en /content/out.\")  # Aviso\n"
      ],
      "metadata": {
        "id": "4r9ZXJCO1EqJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}