{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from pathlib import Path\n",
        "\n",
        "# --- CONTENEDOR PRINCIPAL ---\n",
        "main_container = widgets.VBox()\n",
        "out = widgets.Output()\n",
        "\n",
        "def iniciar_panel_daich():\n",
        "    # Variables globales para asegurar que los bloques se comuniquen\n",
        "    global PATHS\n",
        "\n",
        "    header = widgets.HTML(\"\"\"\n",
        "        <div style=\"background-color: #1a1a1a; padding: 20px; border-radius: 10px; border-left: 8px solid #007bff; color: white; margin-bottom: 20px;\">\n",
        "            <h1 style=\"margin: 0; color: #58a6ff; text-align: center;\">ü§ñ PANEL DE CONTROL DAICH</h1>\n",
        "        </div>\n",
        "    \"\"\")\n",
        "\n",
        "    # --- FUNCI√ìN PARA SUBIDA DIN√ÅMICA (BLOQUE 1.2) ---\n",
        "    def ejecutar_subida_1_2(contexto=\"GENERAL\"):\n",
        "        print(\"üìÇ Selecciona archivos para a√±adir (Video, SRT, CSVs o Modelo)\")     # Aviso de carga\n",
        "        subidos = files.upload()                                                   # Selector de archivos\n",
        "\n",
        "        for nombre_original in subidos.keys():                                     # Itera sobre los archivos subidos\n",
        "            nombre_min = nombre_original.lower()                                   # Normaliza a min√∫sculas para comparar\n",
        "\n",
        "            # --- L√ìGICA DE CLASIFICACI√ìN (Mantiene archivos existentes) ---\n",
        "            if \"losa\" in nombre_min and nombre_original.endswith('.csv'):          # Identifica CSV de fondo\n",
        "                ruta_destino = PATHS[\"in\"] / \"losa.csv\"                            # Renombra para el motor de fusi√≥n\n",
        "                print(f\"üéØ Identificado como LOSA: {nombre_original}\")\n",
        "\n",
        "            elif \"paramento\" in nombre_min and nombre_original.endswith('.csv'):   # Identifica CSV de muros\n",
        "                ruta_destino = PATHS[\"in\"] / \"paramento.csv\"                       # Renombra para el motor de fusi√≥n\n",
        "                print(f\"üéØ Identificado como PARAMENTO: {nombre_original}\")\n",
        "\n",
        "            elif nombre_original.endswith('.pt'):                                 # Identifica modelos YOLO\n",
        "                ruta_destino = PATHS[\"in\"] / \"best.pt\"                             # Estandariza nombre del modelo\n",
        "                print(f\"üß† Modelo cargado/actualizado: {nombre_original}\")\n",
        "\n",
        "            else:                                                                  # Video, SRT y otros\n",
        "                ruta_destino = PATHS[\"in\"] / nombre_original                       # Conserva nombre original\n",
        "                print(f\"üì¶ Archivo guardado: {nombre_original}\")\n",
        "\n",
        "            # --- GUARDADO EN DISCO ---\n",
        "            with open(ruta_destino, \"wb\") as f:                                    # Abre destino sin borrar el resto de /in\n",
        "                f.write(subidos[nombre_original])                                  # Escribe el nuevo contenido\n",
        "            # >>> FIN BLOQUE 1.2 <<<\n",
        "\n",
        "    def vista_principal():\n",
        "        # Botones con nombres representativos y cortos\n",
        "        btn_config    = widgets.Button(description=\"1. Configurar Sistema\", button_style='primary', layout={'width': '95%'})\n",
        "        btn_frames    = widgets.Button(description=\"2. Extraer Frames\", button_style='info', layout={'width': '95%'})\n",
        "        btn_train_val = widgets.Button(description=\"3. Entrenar / Validar\", button_style='warning', layout={'width': '95%'})\n",
        "        btn_inspeccion = widgets.Button(description=\"4. Generar Inspecci√≥n\", button_style='success', layout={'width': '95%'})\n",
        "\n",
        "        # --- BOT√ìN BLOQUE 1.1 ---\n",
        "        def f_config(b):\n",
        "            with out:\n",
        "                clear_output()\n",
        "                # >>> INICIO BLOQUE 1.1 <<<\n",
        "                import os, shutil, zipfile, subprocess, glob, re    # Librer√≠as para gesti√≥n de archivos, carpetas y procesos del sistema\n",
        "                from pathlib import Path                            # Herramienta para manipular rutas de archivos de forma intuitiva\n",
        "                import pandas as pd                                 # Librer√≠a principal para manipulaci√≥n y an√°lisis de datos (CSVs)\n",
        "                import numpy as np                                  # Librer√≠a para operaciones matem√°ticas y manejo de arreglos num√©ricos\n",
        "                import cv2                                          # OpenCV: Librer√≠a para procesamiento de im√°genes y video\n",
        "                import torch                                        # Framework de Deep Learning para ejecutar el modelo YOLO\n",
        "                from google.colab import files                      # Utilidad espec√≠fica de Colab para subir y descargar archivos\n",
        "                import random                                       # Permite generar n√∫meros aleatorios para mezclar datos antes del split\n",
        "\n",
        "                # Instalaciones de dependencias para el reporte y detecci√≥n\n",
        "                !pip -q install ultralytics fpdf\n",
        "                from ultralytics import YOLO\n",
        "                from fpdf import FPDF\n",
        "\n",
        "                # --- CONFIGURACI√ìN DE RUTAS MAESTRAS ---\n",
        "                BASE = Path(\"/content\")\n",
        "\n",
        "                # Definici√≥n de variables globales\n",
        "                DIR_IN = BASE/\"in\"\n",
        "                DIR_WORK = BASE/\"work\"\n",
        "                DIR_OUT = BASE/\"out\"\n",
        "                DIR_DATASET = BASE/\"dataset\"\n",
        "                DIR_RUNS = BASE/\"runs\"\n",
        "                DIR_FRAMES = DIR_WORK/\"frames\"\n",
        "                DIR_RAW = DIR_WORK/\"dataset_raw\"\n",
        "\n",
        "                # PATHS, para saber que carpetas debe utilizar el entorno\n",
        "                PATHS = {\n",
        "                    \"in\": DIR_IN,\n",
        "                    \"work\": DIR_WORK,\n",
        "                    \"out\": DIR_OUT,\n",
        "                    \"frames\": DIR_FRAMES,\n",
        "                    \"dataset\": DIR_DATASET\n",
        "                }\n",
        "\n",
        "                # Creaci√≥n f√≠sica de todo el √°rbol de directorios\n",
        "                for p in [DIR_IN, DIR_WORK, DIR_OUT, DIR_DATASET, DIR_RUNS, DIR_FRAMES, DIR_RAW]:\n",
        "                    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                print(f\"‚úÖ Entorno preparado. GPU disponible: {torch.cuda.is_available()}\")\n",
        "\n",
        "                # --- FUNCIONES DE CHEQUEO ---\n",
        "\n",
        "                def listar_carpeta(ruta, max_items=50):\n",
        "                    ruta = Path(ruta)\n",
        "                    print(\"\\nüìÅ\", ruta)\n",
        "                    if not ruta.exists():\n",
        "                        print(\"‚ö†Ô∏è No existe todav√≠a.\")\n",
        "                        return\n",
        "                    items = sorted(list(ruta.iterdir()), key=lambda p: (p.is_file(), p.name.lower()))\n",
        "                    if len(items) == 0:\n",
        "                        print(\"‚ö†Ô∏è Est√° vac√≠a.\")\n",
        "                        return\n",
        "                    for p in items[:max_items]:\n",
        "                        tipo = \"DIR \" if p.is_dir() else \"FILE\"\n",
        "                        print(f\" - {tipo} {p.name}\")\n",
        "\n",
        "                print(\"\\n‚úÖ Listado r√°pido de carpetas del proyecto:\")\n",
        "                listar_carpeta(BASE)\n",
        "                listar_carpeta(DIR_IN)\n",
        "\n",
        "                # Chequeo de espacio y peso\n",
        "                try:\n",
        "                    print(\"\\n‚úÖ Espacio en disco:\")\n",
        "                    subprocess.run([\"df\", \"-h\", \"/content\"], check=False)\n",
        "                except: pass\n",
        "\n",
        "                # --- DETECCI√ìN AUTOM√ÅTICA DE INPUTS ---\n",
        "                in_files = list(DIR_IN.iterdir())\n",
        "                video = next((p for p in in_files if p.suffix.lower() in [\".mp4\", \".mov\", \".avi\"]), None)\n",
        "                zip_cvat = next((p for p in in_files if p.suffix.lower() == \".zip\" and \"cvat\" in p.name.lower()), None)\n",
        "                zip_images = next((p for p in in_files if p.name.lower() == \"images.zip\"), None)\n",
        "\n",
        "                print(\"\\n‚úÖ Resumen de Entradas Detectadas:\")\n",
        "                print(\" - Video:\", video.name if video else \"‚ùå No detectado\")\n",
        "                print(\" - Zip CVAT:\", zip_cvat.name if zip_cvat else \"‚ùå No detectado\")\n",
        "                print(\" - images.zip:\", zip_images.name if zip_images else \"‚ùå No detectado\")\n",
        "\n",
        "                print(\"\\nüöÄ Rutas listas para el procesamiento t√©cnico.\")\n",
        "\n",
        "                # >>> FIN BLOQUE 1.1 <<<\n",
        "\n",
        "        # --- BOT√ìN 2: BLOQUE 2.1 ---\n",
        "        def f_frames(b):\n",
        "            # Busca un video por extensi√≥n com√∫n (si existe)\n",
        "            video = next((p for p in in_files if p.suffix.lower() in [\".mp4\", \".mov\", \".avi\", \".mkv\"]), None)  # Encuentra el primer video\n",
        "\n",
        "            # Extrae frames desde el video detectado (SELECCIONAR MANUALMENTE EN CASO DE VIDEOS M√ÅS GRANDES)\n",
        "            fps_extract = 1.0                                              # Define cu√°ntas im√°genes por segundo extraer (ej: 1.0 = 1 frame/seg)\n",
        "            img_ext = \"jpg\"                                                # Define el formato de imagen de salida (jpg o png)\n",
        "\n",
        "            # Si no hay video, no hacemos nada y seguimos\n",
        "            if video is None:                                              # Revisa si se detect√≥ un video en /content/in\n",
        "                print(\"‚ö†Ô∏è No hay video detectado en /content/in, as√≠ que no se extraen frames todav√≠a.\")  # Aviso sin romper el flujo\n",
        "            else:\n",
        "                # Limpia frames anteriores para no mezclar corridas\n",
        "                old_frames = list(DIR_FRAMES.glob(f\"*.{img_ext}\"))          # Busca frames antiguos en la carpeta de frames\n",
        "                for f in old_frames:                                        # Recorre frames antiguos\n",
        "                    f.unlink()                                              # Borra cada frame antiguo\n",
        "\n",
        "                # Define el n√∫mero inicial desde el cual deseas comenzar la numeraci√≥n\n",
        "                start_number = 1262  # Puedes poner el n√∫mero que desees\n",
        "\n",
        "                # Define el patr√≥n de nombres con el n√∫mero de inicio\n",
        "                out_pattern = str(DIR_FRAMES / f\"%06d.{img_ext}\")\n",
        "\n",
        "                # Construye y ejecuta el comando ffmpeg para extraer frames\n",
        "                cmd = [\n",
        "                \"ffmpeg\", \"-y\",\n",
        "                \"-i\", str(video),\n",
        "                \"-vf\", f\"fps={fps_extract}\",\n",
        "                \"-start_number\", str(start_number), # <--- ESTO indica d√≥nde empezar\n",
        "                out_pattern]\n",
        "\n",
        "                print(\"‚úÖ Ejecutando FFmpeg para extraer frames:\")          # Mensaje de inicio\n",
        "                print(\"   \", \" \".join(cmd))                                 # Muestra el comando para trazabilidad\n",
        "                subprocess.run(cmd, check=False)                            # Ejecuta sin romper el notebook si ffmpeg devuelve error\n",
        "\n",
        "                # Cuenta y muestra resultados\n",
        "                frames = sorted(DIR_FRAMES.glob(f\"*.{img_ext}\"))            # Busca los frames generados\n",
        "                if len(frames) == 0:                                        # Si no se gener√≥ ning√∫n frame\n",
        "                    print(\"‚ö†Ô∏è No se generaron frames (revisa si el video est√° OK o si fps_extract es muy bajo).\")  # Aviso\n",
        "                else:\n",
        "                    print(f\"‚úÖ Frames listos: {len(frames)} en {DIR_FRAMES}\")  # Confirma cu√°ntos frames se crearon\n",
        "                    print(\"   Ejemplo primero/√∫ltimo:\", frames[0].name, \"|\", frames[-1].name)  # Muestra nombres de ejemplo\n",
        "\n",
        "            # Comprime los frames en un ZIP descargable (si no hay frames, no falla: solo avisa)\n",
        "            zip_frames_path = DIR_OUT/\"frames.zip\"                         # Define d√≥nde quedar√° el zip final\n",
        "\n",
        "            # Busca frames existentes en la carpeta de frames\n",
        "            frame_files = sorted(list(DIR_FRAMES.glob(\"*.jpg\")) + list(DIR_FRAMES.glob(\"*.png\")))  # Re√∫ne frames jpg/png\n",
        "\n",
        "            # Si no hay frames a√∫n, avisa y termina sin error\n",
        "            if len(frame_files) == 0:                                      # Revisa si hay frames para comprimir\n",
        "                print(\"‚ö†Ô∏è No hay frames en /content/work/frames, as√≠ que no se puede crear frames.zip todav√≠a.\")  # Aviso\n",
        "            else:\n",
        "                # Si ya exist√≠a un zip antiguo, lo borra para evitar confusiones\n",
        "                if zip_frames_path.exists():                               # Verifica si el zip ya existe\n",
        "                    zip_frames_path.unlink()                               # Borra el zip anterior\n",
        "\n",
        "                # Crea el zip con todos los frames\n",
        "                with zipfile.ZipFile(zip_frames_path, \"w\", zipfile.ZIP_DEFLATED) as z:  # Abre un zip en modo escritura\n",
        "                    for f in frame_files:                                  # Recorre cada frame\n",
        "                        z.write(f, arcname=f.name)                         # Agrega el archivo al zip con su nombre\n",
        "\n",
        "                # Confirma que el zip se cre√≥ correctamente\n",
        "                print(\"‚úÖ ZIP creado para CVAT:\", zip_frames_path)          # Muestra la ruta del zip creado\n",
        "                print(f\"‚úÖ Incluye {len(frame_files)} im√°genes.\")          # Indica cu√°ntas im√°genes quedaron dentro\n",
        "\n",
        "                # Opci√≥n de descarga directa (si quieres)\n",
        "                try:\n",
        "                    from google.colab import files                         # Importa herramienta de descarga de Colab\n",
        "                    files.download(str(zip_frames_path))                   # Descarga el zip a tu PC\n",
        "                    print(\"‚úÖ Descarga iniciada (si tu navegador lo permite).\")  # Confirmaci√≥n\n",
        "                except Exception:\n",
        "                    print(\"‚ö†Ô∏è No pude iniciar descarga autom√°tica, pero el zip qued√≥ en /content/out para descargarlo manualmente.\")  # Aviso\n",
        "                    # >>> FIN BLOQUE 2.1 <<<\n",
        "\n",
        "        # --- BOT√ìN 3: BLOQUES 2.2, 2.3 Y 2.4 ---\n",
        "        def f_train_val(b):\n",
        "            # Descomprime el export de CVAT en /content/work/dataset_raw\n",
        "            # Nota: Este zip debe llamarse de forma que contenga \"cvat\" en el nombre\n",
        "\n",
        "            # Vuelve a buscar un zip que parezca de CVAT\n",
        "            in_files = list(DIR_IN.iterdir())                                              # Lee archivos en /content/in\n",
        "            zip_cvat = next((p for p in in_files if p.suffix.lower() == \".zip\" and \"cvat\" in p.name.lower()), None)  # Busca zip con \"cvat\" en el nombre\n",
        "\n",
        "            if zip_cvat is None:                                                           # Revisa si existe export de CVAT\n",
        "                print(\"‚ö†Ô∏è No detect√© ning√∫n .zip de CVAT en /content/in (debe tener 'cvat' en el nombre).\")           # Aviso\n",
        "                print(\"‚ÑπÔ∏è Cuando lo tengas, s√∫belo y vuelve a correr este bloque.\")         # Gu√≠a\n",
        "            else:\n",
        "                if DIR_RAW.exists():                                                       # Revisa si ya existe dataset_raw\n",
        "                    shutil.rmtree(DIR_RAW)                                                 # Borra dataset_raw anterior completo\n",
        "                DIR_RAW.mkdir(parents=True, exist_ok=True)                                 # Crea dataset_raw limpio\n",
        "\n",
        "                # Descomprime el zip de CVAT dentro de dataset_raw\n",
        "                with zipfile.ZipFile(zip_cvat, \"r\") as z:                                  # Abre el zip de CVAT\n",
        "                    z.extractall(DIR_RAW)                                                  # Extrae todo su contenido en DIR_RAW\n",
        "\n",
        "                # Lista contenido para confirmar que se extrajo algo\n",
        "                extracted_any = any(DIR_RAW.rglob(\"*\"))                                     # Verifica si hay archivos extra√≠dos\n",
        "                if not extracted_any:                                                      # Si no se extrajo nada\n",
        "                    print(\"‚ö†Ô∏è El zip se descomprimi√≥, pero no veo archivos dentro. Revisa si el zip est√° correcto.\")  # Aviso\n",
        "                else:\n",
        "                    print(\"‚úÖ Export CVAT descomprimido en:\", DIR_RAW)                      # Confirmaci√≥n\n",
        "                    # Muestra un vistazo r√°pido de archivos/carpetas extra√≠das\n",
        "                    top_items = sorted(list(DIR_RAW.iterdir()))                             # Lista el primer nivel de dataset_raw\n",
        "                    print(\"‚úÖ Primer nivel dentro de dataset_raw:\")                         # T√≠tulo del listado\n",
        "                    for p in top_items[:30]:                                                # Muestra hasta 30 √≠tems\n",
        "                        tag = \"DIR \" if p.is_dir() else \"FILE\"                              # Marca si es carpeta o archivo\n",
        "                        print(\" -\", tag, p.name)                                            # Imprime nombre\n",
        "                    if len(top_items) > 30:                                                 # Si hay muchos √≠tems\n",
        "                        print(f\" ... y {len(top_items)-30} m√°s\")                            # Indica que hay m√°s\n",
        "\n",
        "\n",
        "            # Detecta im√°genes/labels en dataset_raw y construye dataset YOLO final (train/val) creando .txt vac√≠os para negativos\n",
        "            import random\n",
        "\n",
        "            img_exts = {\".jpg\", \".jpeg\", \".png\"}                             # Extensiones v√°lidas de im√°genes\n",
        "            train_ratio = 0.8                                                # Proporci√≥n train/val\n",
        "            seed = 42                                                        # Semilla para split repetible\n",
        "\n",
        "            # Define rutas YOLO est√°ndar de salida\n",
        "            IMG_TRAIN = DIR_DATASET/\"images/train\"                           # Im√°genes train\n",
        "            IMG_VAL   = DIR_DATASET/\"images/val\"                             # Im√°genes val\n",
        "            LBL_TRAIN = DIR_DATASET/\"labels/train\"                           # Labels train\n",
        "            LBL_VAL   = DIR_DATASET/\"labels/val\"                             # Labels val\n",
        "\n",
        "            # Crea carpetas de salida\n",
        "            for d in [IMG_TRAIN, IMG_VAL, LBL_TRAIN, LBL_VAL]:               # Recorre carpetas YOLO\n",
        "                d.mkdir(parents=True, exist_ok=True)                         # Crea si falta\n",
        "\n",
        "            # Verifica que exista dataset_raw\n",
        "            if not DIR_RAW.exists():                                         # Si no existe dataset_raw\n",
        "                print(\"‚ö†Ô∏è No existe /content/work/dataset_raw todav√≠a. Corre el Bloque 8 (descomprimir CVAT) primero.\")  # Aviso\n",
        "            else:\n",
        "                # Busca im√°genes y txt dentro de dataset_raw (recursivo)\n",
        "                all_imgs = [p for p in DIR_RAW.rglob(\"*\") if p.suffix.lower() in img_exts]   # Todas las im√°genes\n",
        "                all_txt  = [p for p in DIR_RAW.rglob(\"*.txt\")]                               # Todos los txt\n",
        "\n",
        "                # Si falta algo, avisa pero no rompe\n",
        "                if len(all_imgs) == 0:\n",
        "                    print(\"‚ö†Ô∏è No encontr√© im√°genes dentro de dataset_raw. Revisa estructura del export (o tu zip).\")  # Aviso\n",
        "                if len(all_txt) == 0:\n",
        "                    print(\"‚ö†Ô∏è No encontr√© labels (.txt) dentro de dataset_raw. Ojo: CVAT solo exporta txt con anotaciones.\")  # Aviso\n",
        "\n",
        "                # Detecta carpeta con m√°s im√°genes y carpeta con m√°s txt (candidatas principales)\n",
        "                img_dir = None                                               # Carpeta candidata de im√°genes\n",
        "                lbl_dir = None                                               # Carpeta candidata de labels\n",
        "\n",
        "                if len(all_imgs) > 0:                                        # Si hay im√°genes\n",
        "                    counts_img_parent = {}                                   # Conteo por carpeta\n",
        "                    for p in all_imgs:                                       # Recorre im√°genes\n",
        "                        counts_img_parent[p.parent] = counts_img_parent.get(p.parent, 0) + 1  # Cuenta\n",
        "                    img_dir = max(counts_img_parent, key=counts_img_parent.get)              # Elige mayor\n",
        "\n",
        "                if len(all_txt) > 0:                                         # Si hay txt\n",
        "                    counts_lbl_parent = {}                                   # Conteo por carpeta\n",
        "                    for p in all_txt:                                        # Recorre txt\n",
        "                        counts_lbl_parent[p.parent] = counts_lbl_parent.get(p.parent, 0) + 1  # Cuenta\n",
        "                    lbl_dir = max(counts_lbl_parent, key=counts_lbl_parent.get)              # Elige mayor\n",
        "\n",
        "                print(\"\\n‚úÖ Rutas detectadas (candidatas principales):\")      # Imprime rutas\n",
        "                print(\" - img_dir:\", str(img_dir) if img_dir else \"No detectado\")  # Carpeta im√°genes\n",
        "                print(\" - lbl_dir:\", str(lbl_dir) if lbl_dir else \"No detectado\")  # Carpeta labels\n",
        "\n",
        "                # Si no se detectaron rutas, termina sin error\n",
        "                if (img_dir is None) or (lbl_dir is None):\n",
        "                    print(\"‚ö†Ô∏è No pude detectar img_dir y/o lbl_dir. Revisa qu√© hay dentro de dataset_raw (Bloque 4 listar carpetas).\")  # Aviso\n",
        "                else:\n",
        "                    # Crea mapas por stem para hacer match imagen <-> label\n",
        "                    img_map = {}                                             # stem -> ruta imagen\n",
        "                    for p in img_dir.iterdir():                              # Recorre archivos en img_dir\n",
        "                        if p.suffix.lower() in img_exts:                     # Si es imagen\n",
        "                            img_map[p.stem] = p                              # Guarda\n",
        "\n",
        "                    lbl_map = {}                                             # stem -> ruta label\n",
        "                    for p in lbl_dir.iterdir():                              # Recorre archivos en lbl_dir\n",
        "                        if p.suffix.lower() == \".txt\":                       # Si es txt\n",
        "                            lbl_map[p.stem] = p                              # Guarda\n",
        "\n",
        "                    # Diagn√≥stico de matching\n",
        "                    all_stems = sorted(img_map.keys())                       # Todas las im√°genes (incluye negativos)\n",
        "                    paired = sorted(set(img_map.keys()) & set(lbl_map.keys()))            # Con label\n",
        "                    missing_lbl = sorted(set(img_map.keys()) - set(lbl_map.keys()))      # Sin label (negativos)\n",
        "                    missing_img = sorted(set(lbl_map.keys()) - set(img_map.keys()))      # Txt sin imagen\n",
        "\n",
        "                    print(\"\\n‚úÖ Matching imagen + label (incluyendo negativos):\")  # Reporte matching\n",
        "                    print(\" - Total im√°genes:\", len(all_stems))              # Total\n",
        "                    print(\" - Con label (.txt):\", len(paired))               # Con txt\n",
        "                    print(\" - Sin label (se crear√° .txt vac√≠o):\", len(missing_lbl))  # Negativos\n",
        "\n",
        "                    # Si no hay im√°genes, no se puede construir dataset\n",
        "                    if len(all_stems) == 0:\n",
        "                        print(\"‚ö†Ô∏è No hay im√°genes v√°lidas para construir dataset. Revisa nombres/extensiones.\")  # Aviso\n",
        "                    else:\n",
        "                        # Limpia salidas anteriores\n",
        "                        for d in [IMG_TRAIN, IMG_VAL, LBL_TRAIN, LBL_VAL]:   # Recorre carpetas de salida\n",
        "                            for f in d.glob(\"*\"):                            # Recorre archivos dentro\n",
        "                                f.unlink()                                   # Borra\n",
        "\n",
        "            # ------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "            # Split train/val sobre TODAS las im√°genes\n",
        "\n",
        "                        random.seed(seed)                                    # Semilla\n",
        "                        random.shuffle(all_stems)                             # Mezcla\n",
        "                        cut = int(len(all_stems) * train_ratio)              # Corte\n",
        "                        train_ids = all_stems[:cut]                          # Train stems\n",
        "                        val_ids = all_stems[cut:]                            # Val stems\n",
        "\n",
        "                        # Copia imagen y label (o crea vac√≠o si falta)\n",
        "                        def copy_img_and_label(stem, img_dst, lbl_dst):      # Funci√≥n copiar + label\n",
        "                            img_src = img_map[stem]                          # Imagen fuente\n",
        "                            shutil.copy2(img_src, img_dst / img_src.name)    # Copia imagen\n",
        "\n",
        "                            lbl_out = lbl_dst / f\"{stem}.txt\"                # Label destino\n",
        "                            if stem in lbl_map:                              # Si existe label real\n",
        "                                shutil.copy2(lbl_map[stem], lbl_out)         # Copia label\n",
        "                            else:\n",
        "                                lbl_out.write_text(\"\", encoding=\"utf-8\")     # Crea label vac√≠o (negativo)\n",
        "\n",
        "                        # Copia a train\n",
        "                        for s in train_ids:                                  # Recorre train\n",
        "                            copy_img_and_label(s, IMG_TRAIN, LBL_TRAIN)      # Copia\n",
        "\n",
        "                        # Copia a val\n",
        "                        for s in val_ids:                                    # Recorre val\n",
        "                            copy_img_and_label(s, IMG_VAL, LBL_VAL)          # Copia\n",
        "\n",
        "                        # Resumen final\n",
        "                        n_train_img = len(list(IMG_TRAIN.glob(\"*\")))         # Cuenta imgs train\n",
        "                        n_train_lbl = len(list(LBL_TRAIN.glob(\"*.txt\")))     # Cuenta labels train\n",
        "                        n_val_img = len(list(IMG_VAL.glob(\"*\")))             # Cuenta imgs val\n",
        "                        n_val_lbl = len(list(LBL_VAL.glob(\"*.txt\")))         # Cuenta labels val\n",
        "\n",
        "                        print(\"\\n‚úÖ Dataset YOLO final creado en:\", DIR_DATASET)  # Confirma creaci√≥n\n",
        "                        print(\" - Train: imgs =\", n_train_img, \"| lbls =\", n_train_lbl)  # Resumen train\n",
        "                        print(\" - Val:   imgs =\", n_val_img,   \"| lbls =\", n_val_lbl)    # Resumen val\n",
        "\n",
        "                        # Chequeo 1 txt por imagen (ideal)\n",
        "                        if n_train_img != n_train_lbl:\n",
        "                            print(\"‚ö†Ô∏è Ojo: TRAIN imgs != txt (deber√≠an ser iguales).\")  # Aviso\n",
        "                        if n_val_img != n_val_lbl:\n",
        "                            print(\"‚ö†Ô∏è Ojo: VAL imgs != txt (deber√≠an ser iguales).\")    # Aviso\n",
        "\n",
        "            # ------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "            # Crea el archivo data.yaml para YOLO y DEFINE MANUALMENTE las clases\n",
        "\n",
        "            yaml_path = BASE/\"data.yaml\"                                    # Define la ruta donde se guardar√° el YAML\n",
        "\n",
        "            # Define aqu√≠ tus clases EXACTAS y en el MISMO orden que usaste en CVAT - OJO DEBE HACERSE MANUAL\n",
        "            classes = [\n",
        "                \"falla junta paramento izquierdo\",\n",
        "                \"falla junta paramento derecho\",\n",
        "                \"falla junta losa fondo\",\n",
        "                \"estr√≠a lado izquierdo\",\n",
        "                \"estr√≠a lado derecho\",\n",
        "                \"estr√≠a centro\",\n",
        "                \"da√±o paramento\",\n",
        "                \"da√±o losa fondo\",\n",
        "            ]                                                               # Lista de nombres de clases (ed√≠tala t√∫)\n",
        "\n",
        "            # Verifica que existan carpetas train/val para evitar un YAML apuntando a nada\n",
        "            train_dir_ok = (DIR_DATASET/\"images/train\").exists()            # Revisa si existe la carpeta de im√°genes train\n",
        "            val_dir_ok = (DIR_DATASET/\"images/val\").exists()                # Revisa si existe la carpeta de im√°genes val\n",
        "\n",
        "            # Si no hay estructura dataset, avisa y no rompe el notebook\n",
        "            if not (train_dir_ok and val_dir_ok):                           # Si faltan carpetas b√°sicas del dataset\n",
        "                print(\"‚ö†Ô∏è No detecto la estructura de dataset en /content/dataset/images/train y /val.\")  # Aviso\n",
        "                print(\"‚ÑπÔ∏è Corre el Bloque 10 (normalizaci√≥n + split) antes de crear el data.yaml.\")       # Gu√≠a\n",
        "            else:\n",
        "                # Si no definiste clases, avisa para que no entrenes con un YAML incompleto\n",
        "                if len(classes) == 0:                                       # Si la lista de clases est√° vac√≠a\n",
        "                    print(\"‚ö†Ô∏è La lista 'classes' est√° vac√≠a. Agrega tus clases en el orden de CVAT antes de entrenar.\")  # Aviso\n",
        "                    print(\"‚ÑπÔ∏è Igual crear√© el data.yaml, pero NO deber√≠as entrenar hasta completar 'classes'.\")          # Gu√≠a\n",
        "\n",
        "                # Construye el contenido del YAML que YOLO necesita\n",
        "                yaml_text = f\"\"\"path: {DIR_DATASET}\n",
        "            train: images/train\n",
        "            val: images/val\n",
        "            names:\n",
        "            \"\"\"                                                             # Texto base del YAML (path + rutas train/val)\n",
        "\n",
        "                # Agrega las clases con su √≠ndice (0,1,2...) en el orden correcto\n",
        "                for i, c in enumerate(classes):                              # Recorre clases con √≠ndice\n",
        "                    yaml_text += f\"  {i}: {c}\\n\"                              # Agrega cada clase al YAML\n",
        "\n",
        "                # Guarda el archivo data.yaml\n",
        "                yaml_path.write_text(yaml_text, encoding=\"utf-8\")            # Escribe el YAML en disco\n",
        "\n",
        "                # Prints de confirmaci√≥n + vista r√°pida del contenido\n",
        "                print(\"‚úÖ data.yaml creado en:\", yaml_path)                   # Confirma ruta del archivo creado\n",
        "                print(\"‚úÖ Contenido de data.yaml:\")                           # T√≠tulo del contenido\n",
        "                print(yaml_text)                                              # Muestra el texto completo\n",
        "                    # >>> FIN BLOQUE 2.2 <<<\n",
        "\n",
        "                    # >>> INICIO BLOQUE 2.3 TAL CUAL <<<\n",
        "                    from google.colab import files  # Necesario para la descarga autom√°tica\n",
        "\n",
        "                    # 1. Configuraci√≥n de par√°metros\n",
        "                    data_yaml = \"/content/data.yaml\"\n",
        "                    batch_size = 16\n",
        "                    epochs = 215\n",
        "                    img_size = 640\n",
        "                    output_dir = \"/content/runs\"\n",
        "                    best_pt_path = Path(\"/content/in/best.pt\") # Ruta de tu \"Partida Guardada\"\n",
        "\n",
        "                    # Asegurar que la carpeta /content/in existe\n",
        "                    best_pt_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                    # 2. L√≥gica de carga de modelo (Continuar Partida o Empezar de Cero)\n",
        "                    if best_pt_path.exists():\n",
        "                        print(f\"üéÆ 'Save Game' detectado. Cargando progreso desde: {best_pt_path}\")\n",
        "                        model = YOLO(str(best_pt_path))\n",
        "                        lr_inicial = 0.001 # Tasa m√°s baja para no arruinar lo ya aprendido\n",
        "                    else:\n",
        "                        print(\"üÜï No hay partida guardada. Iniciando entrenamiento desde cero (YOLOv8n).\")\n",
        "                        model = YOLO(\"yolov8n.pt\")\n",
        "                        lr_inicial = 0.01\n",
        "\n",
        "                    # 3. Entrenamiento\n",
        "                    print(f\"üöÄ Iniciando entrenamiento (M√°ximo {epochs} epochs)...\")\n",
        "                    results = model.train(\n",
        "                        data=data_yaml,\n",
        "                        epochs=epochs,\n",
        "                        imgsz=img_size,\n",
        "                        batch=batch_size,\n",
        "                        project=output_dir,\n",
        "                        name=\"train_experiment\",\n",
        "                        exist_ok=True,\n",
        "                        lr0=lr_inicial,\n",
        "                        patience=30,      # Si deja de mejorar por 30 epochs, se detiene\n",
        "                        save=True,\n",
        "                        pretrained=True\n",
        "                    )\n",
        "\n",
        "                    # 4. Gesti√≥n de archivos y Auto-Descarga (\"Guardado Final\")\n",
        "                    print(\"‚úÖ Entrenamiento finalizado.\")\n",
        "\n",
        "                    # Ruta donde YOLO acaba de guardar el mejor modelo de esta sesi√≥n\n",
        "                    new_best_path = Path(output_dir) / \"train_experiment\" / \"weights\" / \"best.pt\"\n",
        "\n",
        "                    if new_best_path.exists():\n",
        "                        # 4a. Sobreescribir el Save Game en /content/in (Para la pr√≥xima vez que corras el bloque)\n",
        "                        shutil.copy2(new_best_path, best_pt_path)\n",
        "                        print(f\"‚≠ê 'Save Game' actualizado localmente en: {best_pt_path}\")\n",
        "\n",
        "                        # 4b. Descargar el archivo al PC autom√°ticamente\n",
        "                        try:\n",
        "                            print(\"üì• Iniciando descarga del modelo 'best.pt' a tu ordenador...\")\n",
        "                            files.download(str(best_pt_path))\n",
        "                            print(\"‚úÖ Descarga iniciada. ¬°Guarda bien este archivo!\")\n",
        "                        except Exception as e:\n",
        "                            print(f\"‚ö†Ô∏è No se pudo iniciar la descarga autom√°tica: {e}\")\n",
        "                            print(\"‚ÑπÔ∏è Puedes descargarlo manualmente desde la carpeta /content/in en el panel izquierdo.\")\n",
        "                    else:\n",
        "                        print(\"‚ö†Ô∏è Error: No se encontr√≥ el archivo generado en esta sesi√≥n.\")\n",
        "                    # >>> FIN BLOQUE 2.3 <<<\n",
        "\n",
        "                    # >>> INICIO BLOQUE 2.4 TAL CUAL <<<\n",
        "                    # --- 1. CONFIGURACI√ìN DE RUTAS ---\n",
        "                    base_path = Path(\"/content\")\n",
        "                    dir_dataset = base_path / \"dataset\"\n",
        "                    dir_runs = base_path / \"runs\"\n",
        "                    dir_out = base_path / \"out\"\n",
        "                    dir_in = base_path / \"in\"\n",
        "\n",
        "                    # Ruta del modelo y de las im√°genes\n",
        "                    best_model_path = dir_in / \"best.pt\"\n",
        "                    val_images_path = dir_dataset / \"images/val\"\n",
        "\n",
        "                    # Carpeta de salida\n",
        "                    pred_name = \"predict_val\"\n",
        "                    final_pred_dir = dir_runs / pred_name\n",
        "\n",
        "                    # --- 2. VALIDACI√ìN ---\n",
        "                    if not best_model_path.exists():\n",
        "                        print(f\"‚ö†Ô∏è No se encuentra el modelo en {best_model_path}. Revisa el Bloque 12.\")\n",
        "                    elif not val_images_path.exists():\n",
        "                        print(f\"‚ö†Ô∏è No existe la carpeta de validaci√≥n en {val_images_path}\")\n",
        "                    else:\n",
        "                        try:\n",
        "                            print(f\"üöÄ Iniciando predicci√≥n visual con l√≠neas delgadas...\")\n",
        "                            model = YOLO(str(best_model_path))\n",
        "\n",
        "                            # Ejecutamos la predicci√≥n con ajustes visuales\n",
        "                            model.predict(\n",
        "                                source=str(val_images_path),\n",
        "                                save=True,\n",
        "                                project=str(dir_runs),\n",
        "                                name=pred_name,\n",
        "                                exist_ok=True,\n",
        "                                conf=0.25,         # Solo muestra lo que tenga > 25% certeza\n",
        "                                iou=0.3,          # Umbral de solapamiento (ajustar si hay cajas duplicadas)\n",
        "                                # --- AJUSTES PARA QUE NO SE TAPEN LAS FALLAS ---\n",
        "                                line_width=3,\n",
        "                                show_labels=True,  # Muestra el nombre de la falla\n",
        "                                show_conf=False,   # Quitamos el % de confianza para limpiar la imagen\n",
        "                                save_txt=False     # No necesitamos los .txt aqu√≠, solo las fotos\n",
        "                            )\n",
        "\n",
        "                            print(f\"‚úÖ Fotos guardadas en: {final_pred_dir}\")\n",
        "\n",
        "                            # --- 3. CREACI√ìN DE ZIP Y DESCARGA ---\n",
        "                            zip_file_path = dir_out / \"val_predictions_clean.zip\"\n",
        "                            dir_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                            # Empaquetamos solo las im√°genes resultantes\n",
        "                            with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "                                # Buscamos extensiones comunes de imagen\n",
        "                                for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
        "                                    for img_file in final_pred_dir.rglob(ext):\n",
        "                                        zipf.write(img_file, arcname=img_file.name)\n",
        "\n",
        "                            if zip_file_path.stat().st_size > 0:\n",
        "                                print(f\"üì¶ ZIP creado: {zip_file_path}\")\n",
        "                                files.download(str(zip_file_path))\n",
        "                                print(\"üì• Descarga iniciada.\")\n",
        "                            else:\n",
        "                                print(\"‚ö†Ô∏è El ZIP est√° vac√≠o. ¬øSeguro que hubo detecciones?\")\n",
        "\n",
        "                        except Exception as e:\n",
        "                            print(f\"‚ùå Error: {e}\")\n",
        "                    # >>> FIN BLOQUE 2.4 <<<\n",
        "\n",
        "        # --- BOT√ìN 4: BLOQUE 3 ---\n",
        "        def f_inspeccion(b):\n",
        "            # Verificaci√≥n archivos cr√≠ticos\n",
        "            video = list(PATHS[\"in\"].glob(\"*.mp4\"))\n",
        "            modelo = (PATHS[\"in\"] / \"best.pt\").exists()\n",
        "            csvs = (PATHS[\"in\"] / \"losa.csv\").exists() and (PATHS[\"in\"] / \"paramento.csv\").exists()\n",
        "            if not video or not modelo or not csvs:\n",
        "                ejecutar_subida_1_2(\"INSPECCI√ìN (VIDEO + MODELO + CSVs + SRT)\")\n",
        "            else:\n",
        "                with out:\n",
        "                    clear_output()\n",
        "                    # >>> INICIO BLOQUE 3<<<\n",
        "                    # --- VALIDACI√ìN PREVIA DE ARCHIVOS CR√çTICOS ---\n",
        "                    archivos_faltantes = []\n",
        "\n",
        "                    # 1. Verificar Video (.mp4)\n",
        "                    video_check = list(PATHS[\"in\"].glob(\"*.mp4\"))\n",
        "                    if not video_check: archivos_faltantes.append(\"Video (.mp4)\")\n",
        "                    else: print(f\"‚úÖ Video detectado: {video_check[0].name}\")\n",
        "\n",
        "                    # 2. Verificar Modelo (best.pt)\n",
        "                    modelo_path = PATHS[\"in\"] / \"best.pt\"\n",
        "                    if not modelo_path.exists(): archivos_faltantes.append(\"Modelo (best.pt)\")\n",
        "                    else: print(f\"‚úÖ Modelo detectado: best.pt\")\n",
        "\n",
        "                    # 3. Verificar Telemetr√≠a (.srt)\n",
        "                    srt_check = list(PATHS[\"in\"].glob(\"*.srt\"))\n",
        "                    if not srt_check: archivos_faltantes.append(\"Telemetr√≠a (.srt)\")\n",
        "                    else: print(f\"‚úÖ SRT detectado: {srt_check[0].name}\")\n",
        "\n",
        "                    # 4. Verificar CSV Losa\n",
        "                    losa_path = PATHS[\"in\"] / \"losa.csv\"\n",
        "                    if not losa_path.exists(): archivos_faltantes.append(\"CSV de Losa (losa.csv)\")\n",
        "                    else: print(f\"‚úÖ Datos de Losa detectados\")\n",
        "\n",
        "                    # 5. Verificar CSV Paramento\n",
        "                    paramento_path = PATHS[\"in\"] / \"paramento.csv\"\n",
        "                    if not paramento_path.exists(): archivos_faltantes.append(\"CSV de Paramento (paramento.csv)\")\n",
        "                    else: print(f\"‚úÖ Datos de Paramento detectados\")\n",
        "\n",
        "                    # --- CONTROL DE DETENCI√ìN\n",
        "                    if archivos_faltantes:\n",
        "                        print(\"\\n‚ùå ERROR: Faltan los siguientes archivos en la carpeta de entrada:\")\n",
        "                        for arch in archivos_faltantes:\n",
        "                            print(f\"   - {arch}\")\n",
        "                        raise SystemExit(\"Deteniendo ejecuci√≥n: Faltan requisitos para procesar el reporte.\")\n",
        "                    else:\n",
        "                        print(\"\\nüöÄ Todos los componentes listos. Iniciando procesamiento...\\n\" + \"-\"*50)\n",
        "\n",
        "                    # ----------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "                    # Analiza los archivos SRT para datos georeferenciales y CSVs para datos t√©cnicos\n",
        "\n",
        "                    def procesar_telemetria_srt(ruta_srt):\n",
        "                        print(f\"üìñ Leyendo archivo: {ruta_srt.name}\")\n",
        "                        with open(ruta_srt, 'r', encoding='utf-8-sig', errors='ignore') as f:\n",
        "                            contenido = f.read()\n",
        "\n",
        "                        # Captura tiempos como \"0:00:01\" o \"00:00:01,000\"\n",
        "                        patron_tiempo = r'(\\d{1,2}:\\d{1,2}:\\d{1,2}(?:[.,]\\d+)?) --> (\\d{1,2}:\\d{1,2}:\\d{1,2}(?:[.,]\\d+)?)'\n",
        "                        tiempos = re.findall(patron_tiempo, contenido)\n",
        "\n",
        "                        # 2. Dividimos el contenido por las marcas de tiempo para obtener los textos\n",
        "                        partes = re.split(patron_tiempo, contenido)\n",
        "                        # Tras el split, los textos quedan en las posiciones 3, 6, 9... (saltando los grupos de captura)\n",
        "                        textos = partes[3::3]\n",
        "\n",
        "                        mapeo = []\n",
        "\n",
        "                        for i, (inicio, fin) in enumerate(tiempos):\n",
        "                            try:\n",
        "                                # Procesar el tiempo de inicio a segundos totales\n",
        "                                partes_hms = inicio.replace(',', '.').split(':')\n",
        "                                h = int(partes_hms[0])\n",
        "                                m = int(partes_hms[1])\n",
        "                                s = float(partes_hms[2])\n",
        "                                seg_total = h * 3600 + m * 60 + s\n",
        "\n",
        "                                # Obtener el texto del bloque actual\n",
        "                                texto_bloque = textos[i] if i < len(textos) else \"\"\n",
        "\n",
        "                                # Limpiar etiquetas <i> y sacar el √∫ltimo n√∫mero (el metro)\n",
        "                                texto_limpio = re.sub(r'<.*?>', '', texto_bloque).strip()\n",
        "                                numeros = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", texto_limpio)\n",
        "\n",
        "                                if numeros:\n",
        "                                    # Tomamos el √∫ltimo n√∫mero porque tu SRT dice \"TRAMO 2 - Parte 2 - 1343 m\"\n",
        "                                    # El 1343 es el que nos interesa.\n",
        "                                    m_valor = float(numeros[-1])\n",
        "                                    mapeo.append({'s': seg_total, 'm': m_valor})\n",
        "                            except Exception as e:\n",
        "                                continue\n",
        "\n",
        "                        df_map = pd.DataFrame(mapeo)\n",
        "\n",
        "                    print(f\"‚úÖ SRT le√≠do correctamente\") # Confirmaci√≥n de lectura\n",
        "\n",
        "                    # --- CONFIGURACI√ìN DE UMBRAL DE DATOS T√âCNICOS (CSV) ---\n",
        "                    UMBRAL_DISTANCIA = 2.0                                              # L√≠mite de distancia para validar datos (+-2m)\n",
        "\n",
        "                    def cargar_datos_robot(ruta):                                       # Funci√≥n para leer CSVs del robot\n",
        "                        try:\n",
        "                            df = pd.read_csv(ruta, sep=';', decimal=',', encoding='latin-1') # Intenta lectura con codificaci√≥n Latin-1\n",
        "                        except:\n",
        "                            df = pd.read_csv(ruta, sep=';', decimal=',', encoding='cp1252') # Si falla, intenta con CP1252\n",
        "                        return df.loc[:, ~df.columns.str.contains('^Unnamed')]          # Elimina columnas vac√≠as residuales\n",
        "\n",
        "                    print(\"üß† Fusionando datos con regla de proximidad estricta (+-2m)...\")\n",
        "                    df_l = cargar_datos_robot(PATHS[\"in\"] / \"losa.csv\")                 # Carga base de datos de losa\n",
        "                    df_p = cargar_datos_robot(PATHS[\"in\"] / \"paramento.csv\")            # Carga base de datos de paramento\n",
        "                    print(f\"‚úÖ CSVs le√≠dos correctamente: losa ({len(df_l)} filas), paramento ({len(df_p)} filas)\") # Confirmaci√≥n de lectura\n",
        "\n",
        "                    datos_finales = []                                                  # Lista para almacenar resultados procesados\n",
        "\n",
        "                    # ----------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "                    # Analiza el video usando el Modelo DAICH y se ubica espacialmente usando el SRT\n",
        "\n",
        "                    # Modelo YOLO analiza video y detecta clases\n",
        "                    model = YOLO(PATHS[\"in\"] / \"best.pt\")\n",
        "                    video_path = next(PATHS[\"in\"].glob(\"*.mp4\"))\n",
        "                    df_telemetria = procesar_telemetria_srt(next(PATHS[\"in\"].glob(\"*.srt\")))\n",
        "\n",
        "                    if df_telemetria.empty:\n",
        "                        print(\"‚ùå ABORTANDO: El archivo SRT no tiene el formato correcto.\")\n",
        "                    else:\n",
        "                        cap = cv2.VideoCapture(str(video_path))\n",
        "                        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "                        hallazgos_crudos = []\n",
        "                        f_count = 0\n",
        "\n",
        "                        while cap.isOpened():\n",
        "                            ret, frame = cap.read()\n",
        "                            if not ret: break\n",
        "                            if f_count % int(fps) == 0:\n",
        "                                seg_act = f_count / fps\n",
        "                                m_act = np.interp(seg_act, df_telemetria['s'], df_telemetria['m'])\n",
        "                                preds = model.predict(frame, conf=0.25, verbose=False)\n",
        "                                for r in preds:\n",
        "                                    if len(r.boxes) > 0:\n",
        "                                        img_f = f\"evidencia_m_{m_act:.2f}.jpg\"\n",
        "                                        cv2.imwrite(str(PATHS[\"frames\"] / img_f), r.plot())\n",
        "                                        for b in r.boxes:\n",
        "                                            hallazgos_crudos.append({\n",
        "                                                'metro': m_act,\n",
        "                                                'seg_video': seg_act, # <--- GUARDAMOS EL SEGUNDO\n",
        "                                                'cls': model.names[int(b.cls)],\n",
        "                                                'img': img_f\n",
        "                                            })\n",
        "                                print(f\"üîç Escaneando Metro: {m_act:.2f} | Detecciones: {len(hallazgos_crudos)}\", end=\"\\r\")\n",
        "                            f_count += 1\n",
        "                        cap.release()\n",
        "                        df_vis = pd.DataFrame(hallazgos_crudos)\n",
        "                        print(f\"\\n‚úÖ An√°lisis visual terminado. Se encontraron {len(df_vis)} registros.\")\n",
        "\n",
        "                    # ----------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "                    # Relaciona las detecciones del video con los datos t√©cnicos disponibles (CSVs)\n",
        "\n",
        "                    for _, det in df_vis.iterrows():                                    # Itera por cada detecci√≥n de la IA\n",
        "                        clase_ia = det['cls'].lower()                                   # Convierte clase a min√∫sculas para comparar\n",
        "\n",
        "                        # Selecci√≥n de DB seg√∫n palabras clave en la clase detectada\n",
        "                        db, origen = (df_l, \"losa.csv\") if any(k in clase_ia for k in [\"estr√≠a\", \"losa\", \"fondo\"]) else (df_p, \"paramento.csv\")\n",
        "\n",
        "                        db['diff'] = (db['Metros'] - det['metro']).abs()                # Calcula distancia absoluta entre IA y Robot\n",
        "                        cercano = db.nsmallest(1, 'diff').iloc[0]                       # Encuentra el registro m√°s cercano (sin interpolar)\n",
        "                        distancia_minima = cercano['diff']                              # Guarda la distancia del punto m√°s pr√≥ximo\n",
        "\n",
        "                        res = {**det, 'csv_usado': origen}                              # Crea diccionario con datos base y origen CSV\n",
        "                        cols_tecnicas = ['Extensi√≥n (cm)', 'Alto (cm)', '√Årea (m2)', 'Volumen (m3)', 'Profundidad (cm)']\n",
        "\n",
        "                        if distancia_minima <= UMBRAL_DISTANCIA:                        # VALIDACI√ìN: Si est√° dentro del rango de 2 metros\n",
        "                            res['tiene_datos'] = True                                   # Marca como hallazgo validado t√©cnicamente\n",
        "                            for c in cols_tecnicas:\n",
        "                                res[c] = cercano.get(c, 0)                              # Asigna valores t√©cnicos del robot\n",
        "                            res['Magnitud'] = cercano.get('Magnitud', 'N/A')            # Captura magnitud de da√±o\n",
        "                        else:                                                           # Si est√° fuera de rango (ej. 1343 vs 1336)\n",
        "                            res['tiene_datos'] = False                                  # Marca para omitir datos en el PDF\n",
        "                            for c in cols_tecnicas: res[c] = 0                          # Setea valores t√©cnicos en cero\n",
        "                            res['Magnitud'] = \"N/A\"                                     # Magnitud no disponible\n",
        "\n",
        "                        datos_finales.append(res)                                       # Agrega el resultado a la lista final\n",
        "\n",
        "                    df_temp = pd.DataFrame(datos_finales)                               # Convierte resultados a DataFrame temporal\n",
        "                    df_temp['metro_redondo'] = df_temp['metro'].round(1)                # Redondea metro a 10cm para agrupar c√°maras\n",
        "                    # Elimina duplicados si coinciden metro y clase (limpieza de doble c√°mara)\n",
        "                    df_reporte = df_temp.drop_duplicates(subset=['metro_redondo', 'cls'], keep='first').copy()\n",
        "\n",
        "                    print(f\"üìä Fusi√≥n lista. Detecciones totales a reportar: {len(df_reporte)}\") # Resumen final del proceso\n",
        "\n",
        "                    # ----------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "                    # Construye el documento PDF con las evidencias capturadas y los datos t√©cnicos\n",
        "\n",
        "                    print(\"üìÑ Generando reporte final...\")\n",
        "                    pdf = FPDF()\n",
        "                    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "\n",
        "                    def clean(val):\n",
        "                        try:\n",
        "                            f = float(val)\n",
        "                            return ('%.4f' % f).rstrip('0').rstrip('.')\n",
        "                        except: return str(val)\n",
        "\n",
        "                    for idx, f in df_reporte.iterrows():\n",
        "                        pdf.add_page()\n",
        "\n",
        "                        # --- T√çTULO: CLASE\n",
        "                        pdf.set_font(\"Arial\", 'B', 14)\n",
        "\n",
        "                        clase_nombre = f['cls'].upper()\n",
        "                        # L√≥gica de g√©nero para el sufijo\n",
        "                        sufijo = \"DETECTADO/A\"\n",
        "\n",
        "                        # Redondeo de la cifra original a 2 decimales\n",
        "                        metro_tit = f\"{round(f['metro'], 2):.2f}\"\n",
        "\n",
        "                        # Construcci√≥n del t√≠tulo en may√∫sculas\n",
        "                        titulo_final = f\"{clase_nombre} {sufijo} EN KM {metro_tit}\"\n",
        "                        pdf.cell(200, 10, titulo_final, ln=True, align='C')\n",
        "\n",
        "                        # Imagen de la IA\n",
        "                        pdf.image(str(PATHS[\"frames\"]/f['img']), x=10, y=30, w=180)\n",
        "\n",
        "                        # --- SUBT√çTULO: Solo Tiempo y Origen ---\n",
        "                        pdf.set_y(155)\n",
        "                        pdf.set_font(\"Arial\", 'B', 10)\n",
        "                        pdf.set_fill_color(230, 230, 230)\n",
        "\n",
        "                        m, s = divmod(int(f['seg_video']), 60)\n",
        "                        info_sub = f\" TIEMPO VIDEO: {m}m {s}s | ORIGEN DATOS: {f['csv_usado']}\"\n",
        "                        pdf.cell(190, 10, info_sub, ln=True, fill=True)\n",
        "\n",
        "                        pdf.set_font(\"Arial\", '', 10)\n",
        "\n",
        "                        if f['tiene_datos']:\n",
        "                            # Fila 1: Extensi√≥n y Ancho\n",
        "                            pdf.cell(95, 8, f\" Extensi√≥n: {clean(f.get('Extensi√≥n (cm)', 0))} cm\", border=1)\n",
        "                            pdf.cell(95, 8, f\" Ancho: {clean(f.get('Alto (cm)', 0))} cm\", border=1, ln=True)\n",
        "\n",
        "                            # Fila 2: √Årea m¬≤ y Volumen m¬≥\n",
        "                            area = f.get('√Årea (m2)', f.get('Area (m2)', 0))\n",
        "                            pdf.cell(95, 8, f\" √Årea: {clean(area)} m¬≤\", border=1)\n",
        "                            pdf.cell(95, 8, f\" Volumen: {clean(f.get('Volumen (m3)', 0))} m¬≥\", border=1, ln=True)\n",
        "\n",
        "                            # Fila 3: Profundidad y Magnitud\n",
        "                            pdf.cell(95, 8, f\" Profundidad: {clean(f.get('Profundidad (cm)', 0))} cm\", border=1)\n",
        "                            pdf.cell(95, 8, f\" Magnitud de da√±o: {f.get('Magnitud', 'N/A')}\", border=1, ln=True)\n",
        "                        else:\n",
        "                            # Nota roja\n",
        "                            pdf.set_text_color(200, 0, 0)\n",
        "                            pdf.set_font(\"Arial\", 'B', 10)\n",
        "                            msj = \"\\nAVISO: ESTE HALLAZGO DETECTADO POR EL MODELO NO TIENE COINCIDENCIA T√âCNICA EN LA NUBE DE PUNTOS DEL ROBOT (+-2M).\"\n",
        "                            pdf.multi_cell(190, 8, msj, border=1, align='C')\n",
        "                            pdf.set_text_color(0, 0, 0)\n",
        "\n",
        "                    report_name = \"Reporte_Inspeccion_Final.pdf\"\n",
        "                    pdf.output(report_name)\n",
        "                    files.download(report_name)\n",
        "                    # >>> FIN BLOQUE 3 <<<\n",
        "\n",
        "        # Asignar eventos\n",
        "        btn_config.on_click(f_config)\n",
        "        btn_frames.on_click(f_frames)\n",
        "        btn_train_val.on_click(f_train_val)\n",
        "        btn_inspeccion.on_click(f_inspeccion)\n",
        "\n",
        "        return widgets.VBox([\n",
        "            btn_config, btn_frames, btn_train_val, btn_inspeccion\n",
        "        ], layout={'align_items': 'center', 'width': '100%'})\n",
        "\n",
        "    # Iniciar\n",
        "    main_container.children = [header, vista_principal(), out]\n",
        "    display(main_container)\n",
        "\n",
        "iniciar_panel_daich()"
      ],
      "metadata": {
        "id": "yb0ie44dVyQH",
        "outputId": "c1269eef-dc10-4f8c-df89-bf3924588b01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (ipython-input-1014467051.py, line 440)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1014467051.py\"\u001b[0;36m, line \u001b[0;32m440\u001b[0m\n\u001b[0;31m    from google.colab import files  # Necesario para la descarga autom√°tica\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    }
  ]
}